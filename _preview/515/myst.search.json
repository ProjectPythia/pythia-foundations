{"version":"1","records":[{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide"},"type":"lvl1","url":"/how-to-contribute","position":0},{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide"},"content":"Note\n\nThis content is under construction!\n\nGeneral information on how to contribute to any Project Pythia repository\nmay be found \n\nhere.\n\nThis page will eventually contain a full guide to contributing to Project Pythia. As GitHub Pull Requests are an important part of contributing to Pythia, this guide will cross-reference tutorials on GitHub and Pull Requests.\n\nIf you need to comment on anything in Pythia Foundations you feel needs work, you can use the “open issue” or “suggest edit” buttons at the top of any Pythia Foundations page. These buttons appear when you hover over the GitHub Octocat logo. Clicking on these buttons will take you to the relevant page on GitHub, where the entirety of the Pythia Foundations material is hosted. In order to actually suggest changes, you must have a free GitHub account, as listed in the GitHub section of Pythia Foundations. This contributor’s guide is strictly for Pythia Foundations; for general Project Pythia contribution guidelines, see the main \n\nProject Pythia Contributor’s Guide.\n\nTo quickly provide feedback about minor issues without the use of GitHub, you can also use this \n\nGoogle Form.","type":"content","url":"/how-to-contribute","position":1},{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide","lvl2":"Contributing a new Jupyter Notebook"},"type":"lvl2","url":"/how-to-contribute#contributing-a-new-jupyter-notebook","position":2},{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide","lvl2":"Contributing a new Jupyter Notebook"},"content":"If you’d like to contribute a Jupyter Notebook to these materials, please reference our \n\nProject Pythia Notebook Template viewable on the next page. This template is available to you in appendix/template.ipynb if you’ve cloned the \n\nsource repository, or available as a download \n\ndirectly from GitHub.","type":"content","url":"/how-to-contribute#contributing-a-new-jupyter-notebook","position":3},{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide","lvl2":"Building the site"},"type":"lvl2","url":"/how-to-contribute#building-the-site","position":4},{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide","lvl2":"Building the site"},"content":"","type":"content","url":"/how-to-contribute#building-the-site","position":5},{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide","lvl3":"Create a conda environment","lvl2":"Building the site"},"type":"lvl3","url":"/how-to-contribute#create-a-conda-environment","position":6},{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide","lvl3":"Create a conda environment","lvl2":"Building the site"},"content":"The first time you check out this repository, run:conda env update -f environment.yml\n\nThis will create or update the dev environment (pythia-book-dev).","type":"content","url":"/how-to-contribute#create-a-conda-environment","position":7},{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide","lvl3":"Install pre-commit hooks","lvl2":"Building the site"},"type":"lvl3","url":"/how-to-contribute#install-pre-commit-hooks","position":8},{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide","lvl3":"Install pre-commit hooks","lvl2":"Building the site"},"content":"This repository includes pre-commit hooks (defined in .pre-commit-config.yaml). To activate/install these pre-commit hooks, run:conda activate pythia-book-dev\npre-commit install\n\nThis is also a one-time step.\n\nNOTE: The pre-commit package is already installed via the pythia-book-dev conda environment.","type":"content","url":"/how-to-contribute#install-pre-commit-hooks","position":9},{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide","lvl3":"Building the book locally","lvl2":"Building the site"},"type":"lvl3","url":"/how-to-contribute#building-the-book-locally","position":10},{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide","lvl3":"Building the book locally","lvl2":"Building the site"},"content":"To build the book locally, run the following:conda activate pythia-book-dev\njupyter-book build .\n\nFinally, you can view the book by opening the file _build/html/index.html with your favorite web browser. On most platforms you can simply run:open _build/html/index.html","type":"content","url":"/how-to-contribute#building-the-book-locally","position":11},{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide","lvl3":"Keeping your dev environment up to date","lvl2":"Building the site"},"type":"lvl3","url":"/how-to-contribute#keeping-your-dev-environment-up-to-date","position":12},{"hierarchy":{"lvl1":"Pythia Foundations Contributor’s Guide","lvl3":"Keeping your dev environment up to date","lvl2":"Building the site"},"content":"It’s good practice to update the packages in your pythia-book-dev conda environment frequently to their latest versions, especially if it’s been a while since you used it. If the jupyter-book build . command above generates error messages, that is a good indication that your conda environment may be out of date.\n\nTo update all packages in the currently activated environment to their latest versions, do this:conda update --all","type":"content","url":"/how-to-contribute#keeping-your-dev-environment-up-to-date","position":13},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"type":"lvl1","url":"/template","position":0},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"content":"","type":"content","url":"/template","position":1},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"How to Use This Page"},"type":"lvl2","url":"/template#how-to-use-this-page","position":2},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"How to Use This Page"},"content":"This page is designed as a template. As such, each section contains instructions for the content added to the equivalent section of a new notebook, with the exception of this section, and the Setting Up a New Notebook section. Because this is not a tutorial, the overall structure of the page does not need to be cohesive.","type":"content","url":"/template#how-to-use-this-page","position":3},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Setting Up a New Notebook"},"type":"lvl2","url":"/template#setting-up-a-new-notebook","position":4},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Setting Up a New Notebook"},"content":"This section lists the first steps for configuring a Jupyter Notebook for inclusion in Pythia Foundations. First, if you have an image relevant to your notebook, such as a \n\nlogo, link to this image at the top of the notebook. The following Markdown example illustrates the correct technique for linking such an image:\n\n![<image title>](http://link.com/to/image.png \"image alt text\")\n\nYou can also use an img tag in raw HTML to embed your logo or other image. Second, make sure to add an HTML alt tag to any image in your notebook. This includes any type of image, including logos, wherever and however they appear in your notebook. Adding this tag improves accessibility and allows more people to properly access your notebook.\n\n\n\n","type":"content","url":"/template#setting-up-a-new-notebook","position":5},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Project Pythia Notebook Template"},"type":"lvl2","url":"/template#project-pythia-notebook-template","position":6},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Project Pythia Notebook Template"},"content":"Each notebook must be properly titled with a top level Markdown header, i.e., a header title prefixed by a single # mark. Nowhere else in the notebook should you use a top level header. This header will be automatically used by the Pythia book-building process to generate the page title, which will then be added to the navbar, table of contents, etc. As such, the header needs to be short, concise, and descriptive. After the header line, add a separate Jupyter Notebook cell with the text ---. This adds a separating line used to separate the title from the overview and prerequisites. This technique will also be used later to separate other sections.\n\n\n\n","type":"content","url":"/template#project-pythia-notebook-template","position":7},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"type":"lvl2","url":"/template#overview","position":8},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"content":"If your notebook contains an introductory paragraph, include the paragraph at the start of this section. Such paragraphs must be short, and relevant to the content of the notebook. After the introductory paragraph, it is required to list the notebook topics, in the format shown below:\n\nThis is a numbered list of the specific topics\n\nThese should map approximately to your main sections of content\n\nOr each second-level, ##, header in your notebook\n\nKeep the size and scope of your notebook in check\n\nAnd be sure to let the reader know up front the important concepts they’ll be leaving with\n\n","type":"content","url":"/template#overview","position":9},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"type":"lvl2","url":"/template#prerequisites","position":10},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"content":"This part of the Pythia Notebook Template was inspired by another template; in this case, \n\nthe template for the Jupyter Book known as \n\nThe Turing Way.\n\nFollowing the overview section, the prerequisites section must enumerate a list of concepts and Python packages. These concepts and packages must comprise the knowledge that readers of your notebook must know and understand in order to successfully learn the notebook material. Each concept or package listed must link to a Pythia Foundations tutorial, or to a relevant external resource. To build the prerequisite table, first copy the following Markdown table into your notebook. You must then edit the table to contain your notebook prerequisites. Each row must contain the name of the concept, along with a link to the tutorial, either on Pythia Foundations or a relevant external resource. It must also be noted whether the concept is helpful or necessary.\n\nConcepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nNecessary\n\n\n\nUnderstanding of NetCDF\n\nHelpful\n\nFamiliarity with metadata structure\n\nProject management\n\nHelpful\n\n\n\nTime to learn: You must provide an estimate of the total time to learn the listed concepts. The general rule is to estimate 5 minutes for each subsection in each concept, or 10 minutes for especially lengthy subsections. Add the estimates for each subsection to obtain the time to learn. Also, please note that overestimates are better than underestimates.\n\nSystem requirements:\n\nIf there are any system, version, or non-Python software requirements for the material in your notebook, these must be listed in a system requirement list.\n\nIf your notebook has no extra requirements, the System Requirements section should be completely removed.\n\nNote that Python packages do not count as system requirements; these should be listed in the Imports section.\n\n\n\n","type":"content","url":"/template#prerequisites","position":11},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"type":"lvl2","url":"/template#imports","position":12},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"content":"Before beginning this section, add a Markdown cell with a --- divider. This section should list import statements for any Python packages required for your notebook content. Optionally, you can include a description above the code cell as well.\n\nimport sys\n\n","type":"content","url":"/template#imports","position":13},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"type":"lvl2","url":"/template#your-first-content-section","position":14},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"content":"\n\nReplace this template section with your first section of tutorial material; all tutorial material should roughly match up with the objectives stated in the Overview section. Your notebook sections should be laid out as a narrative, each containing interspersed Markdown text, images, code cells, and other content as necessary.\n\n# Code cells like this are an essential part of your notebook\nprint(\"Hello world!\")\n\n","type":"content","url":"/template#your-first-content-section","position":15},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/template#a-content-subsection","position":16},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"content":"To provide more detail about concepts in content sections, it is recommended to create content subsections. As shown in this template section, subsections are added through lower-level Markdown headers, and automatically populate navbars, both when viewing the notebook in JupyterLab and when viewing the notebook as a Pythia Foundations tutorial page.\n\n# some subsection code\nnew = \"helpful information\"\n\n","type":"content","url":"/template#a-content-subsection","position":17},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/template#another-content-subsection","position":18},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"content":"This subsection was created in the same way as the previous subsection. Subsections often contain detailed information relevant to the material. An example relevant to this template is “Try to avoid using code comments as narrative; instead, let them only exist for brief clarification as needed.”\n\n","type":"content","url":"/template#another-content-subsection","position":19},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"type":"lvl2","url":"/template#your-second-content-section","position":20},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"content":"The second content section should roughly match up with the second learning objective of your notebook. For this template, the objective in question is to learn levels of Markdown headers. Below is a demonstration of Markdown header levels; however, be aware that each new header is incorporated into the navbars.\n\n","type":"content","url":"/template#your-second-content-section","position":21},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"This example is","lvl2":"Your second content section"},"type":"lvl3","url":"/template#this-example-is","position":22},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"This example is","lvl2":"Your second content section"},"content":"","type":"content","url":"/template#this-example-is","position":23},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"This example is","lvl2":"Your second content section"},"type":"lvl4","url":"/template#a-quick-demonstration","position":24},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"This example is","lvl2":"Your second content section"},"content":"","type":"content","url":"/template#a-quick-demonstration","position":25},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"This example is","lvl2":"Your second content section"},"type":"lvl5","url":"/template#of-further-and-further","position":26},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"This example is","lvl2":"Your second content section"},"content":"","type":"content","url":"/template#of-further-and-further","position":27},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"This example is","lvl2":"Your second content section"},"type":"lvl6","url":"/template#header-levels","position":28},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"This example is","lvl2":"Your second content section"},"content":"\n\nEach section in your notebook can also contain \\LaTeX equations, enabled through MathJax. In the following example, we illustrate some sample MathJax equations. (Rendering instructions, as well as detailed information about MathJax, can be found in \n\nthis documentation.)\\begin{align}\n\\dot{x} & = \\sigma(y-x) \\\\\n\\dot{y} & = \\rho x - y - xz \\\\\n\\dot{z} & = -\\beta z + xy\n\\end{align}\n\nThere are many helpful resources for learning Markdown and customizing Jupyter Markdown cells listed on \n\nthis useful guide. In addition, there is information on formatting relevant specifically to Jupyter on this \n\nJupyter documentation page. Finally, perfectionism is encouraged in Pythia Foundations, and there are many available resources for formatting notebooks in a perfectionistic manner.\n\n","type":"content","url":"/template#header-levels","position":29},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"type":"lvl2","url":"/template#last-section","position":30},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"content":"It is possible to embed raw HTML into Jupyter Markdown cells, as shown above with the Project Pythia logo. This allows for many forms of additional content; the most used form in Pythia is message boxes, as illustrated below. (If you are viewing this page as a Jupyter Notebook, you can also edit the following Markdown cell to view the underlying code.)\n\nInfoThis is an info box. Info boxes contain additional information about tutorial concepts.\n\nMaking a notebook for Pythia inevitably requires some trial and error for formatting, among other things. If you feel the formatting is lacking in some way, feel free to adjust it in different ways until it is up to your standards. Copying and editing Markdown cells is a good way to try different formatting options.\n\nIn addition, there are other types of boxes, known as admonitions, that can be inserted into a tutorial page:\n\nSuccessThis is a success box. Success boxes are usually placed at the end of a set of examples, and usually show a message relating to the final state of the examples.\n\nWarningThis is a warning box. Warning boxes are usually used to indicate a situation where making a mistake, such as a typo, can cause issues with the tutorial content.\n\nDangerThis is a danger box. Danger boxes are usually used to indicate a situation where making a mistake, such as a typo, can cause more serious issues such as loss of data.\n\nIn addition, it is helpful and highly recommended to add cell tags to your Jupyter cells. These tags allow for \n\ncustomization of content display, especially for code cells. In addition, cell tags provide a means for \n\ndemonstrating errors without breaking any production environments. If you are unfamiliar with cell tags, you can review this \n\nbrief demonstration provided by Jupyter Book; this demonstration covers cell tags in Jupyter Notebook and Jupyter Lab, as well as fully manual cell tags.\n\n\n\n","type":"content","url":"/template#last-section","position":31},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"type":"lvl2","url":"/template#summary","position":32},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"content":"Before adding a summary, you must first add another Markdown cell containing ---, which marks the end of the content body. A good Summary section contains a brief single paragraph that summarizes the tutorial content. The key content elements and their relation to the tutorial objectives should also be covered. Finally, the most important concepts should be listed again in detail.","type":"content","url":"/template#summary","position":33},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/template#whats-next","position":34},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What’s next?","lvl2":"Summary"},"content":"This section should briefly describe the content in the page following your tutorial sequentially. You can find the page sequentially following yours using the Next link at the bottom of the page, or using the sidebar; Jupyter Book should pre-populate this. In addition, if your tutorial leads into other Pythia Foundations content, or tutorials found outside Pythia Foundations, these other tutorials can be linked to as well.\n\n","type":"content","url":"/template#whats-next","position":35},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"type":"lvl2","url":"/template#resources-and-references","position":36},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"content":"In this section, you must provide detailed citations and references to any external content used in your tutorial. Many types of external content are designed in as much detail as Pythia Foundations pages, and crediting the author is essential. In addition, this section can contain links to additional external content, such as reading, documentation, etc. Once this section is complete, your notebook is finished. After giving your new notebook a quick review, you can request the addition of the notebook to Pythia Foundations by sending the team a GitHub Pull Request. Here are a few final notes pertaining to working with Jupyter and Pythia:\n\nIn order to confirm that your notebook runs from start to finish without errors, hangs, etc., go to the Kernel menu in Jupyter Lab and select Restart Kernel and Run All Cells.\n\nIn order to prepare your notebook to be committed to Pythia Foundations, go to the Kernel menu in Jupyter Lab and select Restart Kernel and Clear All Outputs. After the notebook is committed, the Jupyter cells will be run and optimized for Pythia automatically.\n\nIf you wish to take credit for your notebook, you can add contact information in this section; this is completely optional.\n\nIt is very important that any code, information, images, etc. referenced in the above sections of your notebook contains appropriate attribution of authorship in this section.\n\nFinally, it is imperative that you must have a legal right to use any content included in your notebook. Do not commit copyright infringement or plagiarism.\n\nThe Project Pythia team thanks you greatly for contributing to Pythia Foundations.","type":"content","url":"/template#resources-and-references","position":37},{"hierarchy":{"lvl1":"Cartopy"},"type":"lvl1","url":"/cartopy","position":0},{"hierarchy":{"lvl1":"Cartopy"},"content":"This section contains tutorials on plotting maps with \n\nCartopy; it is cross-referenced with tutorials on \n\nXarray and \n\nMatplotlib.\n\nFrom the \n\nCartopy website:\n\nCartopy is a Python package designed for geospatial data processing in order to\nproduce maps and other geospatial data analyses.\n\nCartopy makes use of the powerful PROJ.4, NumPy and Shapely libraries and includes a programmatic interface\nbuilt on top of Matplotlib for the creation of publication quality maps.\n\nKey features of Cartopy are its object-oriented \n\nprojection definitions,\nand its ability to transform points, lines, vectors, polygons and images between those projections.\n\nBefore working through the Cartopy notebooks in this section of Pythia Foundations, you should first have a basic knowledge of \n\nMatplotlib.\n\nIn addition, please note that the geographic-features library used by Cartopy makes use of shapefiles directly served by \n\nNatural Earth.","type":"content","url":"/cartopy","position":1},{"hierarchy":{"lvl1":"Introduction to Cartopy"},"type":"lvl1","url":"/cartopy-1","position":0},{"hierarchy":{"lvl1":"Introduction to Cartopy"},"content":"\n\n","type":"content","url":"/cartopy-1","position":1},{"hierarchy":{"lvl1":"Introduction to Cartopy"},"type":"lvl1","url":"/cartopy-1#introduction-to-cartopy","position":2},{"hierarchy":{"lvl1":"Introduction to Cartopy"},"content":"\n\n\n\n","type":"content","url":"/cartopy-1#introduction-to-cartopy","position":3},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Overview"},"type":"lvl2","url":"/cartopy-1#overview","position":4},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Overview"},"content":"The concepts covered in this section include:\n\nLearning core Cartopy concepts: map projections and GeoAxes\n\nExploring some of Cartopy’s map projections\n\nCreating regional maps\n\nThis tutorial will lead you through some basics of creating maps with specified projections using Cartopy, and adding geographical features (like coastlines and borders) to those maps.\n\nPlotting data on map projections will be covered in later tutorials.\n\n","type":"content","url":"/cartopy-1#overview","position":5},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Prerequisites"},"type":"lvl2","url":"/cartopy-1#prerequisites","position":6},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nMatplotlib\n\nNecessary\n\n\n\nTime to learn: 30 minutes\n\n\n\n","type":"content","url":"/cartopy-1#prerequisites","position":7},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Imports"},"type":"lvl2","url":"/cartopy-1#imports","position":8},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Imports"},"content":"Here, we import the main libraries of Cartopy: crs and feature.  In addition, we import numpy, as well as matplotlib’s pyplot interface. Finally, we import a library called warnings, and use it to remove extraneous warnings that Cartopy produces in later examples.\n\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom cartopy import crs as ccrs, feature as cfeature\n\n#  Suppress warnings issued by Cartopy when downloading data files\nwarnings.filterwarnings('ignore')\n\n\n\n","type":"content","url":"/cartopy-1#imports","position":9},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Basic concepts: map projections and GeoAxes"},"type":"lvl2","url":"/cartopy-1#basic-concepts-map-projections-and-geoaxes","position":10},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Basic concepts: map projections and GeoAxes"},"content":"\n\n","type":"content","url":"/cartopy-1#basic-concepts-map-projections-and-geoaxes","position":11},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Extend Matplotlib’s axes into georeferenced GeoAxes","lvl2":"Basic concepts: map projections and GeoAxes"},"type":"lvl3","url":"/cartopy-1#extend-matplotlibs-axes-into-georeferenced-geoaxes","position":12},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Extend Matplotlib’s axes into georeferenced GeoAxes","lvl2":"Basic concepts: map projections and GeoAxes"},"content":"\n\nRecall from earlier tutorials that a figure in Matplotlib has two elements: a Figure object, and a list of one or more Axes objects (subplots).\n\nSince we imported cartopy.crs, we now have access to Cartopy’s Coordinate Reference System, which contains many geographical projections. We can specify one of these projections for an Axes object to convert it into a GeoAxes object. This will effectively georeference the subplot. Examples of converting Axes objects into GeoAxes objects can be found later in this section.\n\n","type":"content","url":"/cartopy-1#extend-matplotlibs-axes-into-georeferenced-geoaxes","position":13},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Create a map with a specified projection","lvl2":"Basic concepts: map projections and GeoAxes"},"type":"lvl3","url":"/cartopy-1#create-a-map-with-a-specified-projection","position":14},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Create a map with a specified projection","lvl2":"Basic concepts: map projections and GeoAxes"},"content":"In this example, we’ll create a GeoAxes object that uses the PlateCarree projection.  PlateCarree is a global lat-lon map projection in which each point is evenly spaced in terms of degrees.  The name “Plate Carree” is French for “flat square”.\n\nfig = plt.figure(figsize=(11, 8.5))\nax = plt.subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=-75))\nax.set_title(\"A Geo-referenced subplot, Plate Carree projection\");\n\nAlthough the figure seems empty, it has, in fact, been georeferenced using a map projection; this projection is provided by Cartopy’s crs (coordinate reference system) class. We can now add in cartographic features, in the form of shapefiles, to our subplot. One such cartographic feature is coastlines, which can be added to our subplot using the callable GeoAxes method simply called coastlines.\n\nax.coastlines()\n\nInfoTo get the figure to display again with the features that we've added since the original display, just type the name of the Figure object in its own cell.\n\nfig\n\n","type":"content","url":"/cartopy-1#create-a-map-with-a-specified-projection","position":15},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Add cartographic features to the map","lvl2":"Basic concepts: map projections and GeoAxes"},"type":"lvl3","url":"/cartopy-1#add-cartographic-features-to-the-map","position":16},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Add cartographic features to the map","lvl2":"Basic concepts: map projections and GeoAxes"},"content":"\n\nCartopy provides other cartographic features via its features class, which was imported at the beginning of this page, under the name cfeature. These cartographic features are laid out as data in shapefiles.  The shapefiles are downloaded when their cartographic features are used for the first time in a script or notebook, and they are downloaded from \n\nhttps://​www​.naturalearthdata​.com/. Once downloaded, they “live” in your ~/.local/share/cartopy directory (note the ~ represents your home directory).\n\nWe can add these features to our subplot via the add_feature method; this method allows the definition of attributes using arguments, similar to Matplotlib’s plot method. A list of the various Natural Earth shapefiles can be found at \n\nhttps://​scitools​.org​.uk​/cartopy​/docs​/latest​/matplotlib​/feature​_interface​.html. In this example, we add borders and U. S. state lines to our subplot:\n\nax.add_feature(cfeature.BORDERS, linewidth=0.5, edgecolor='black')\nax.add_feature(cfeature.STATES, linewidth=0.3, edgecolor='brown')\n\nOnce again, referencing the Figure object will re-render the figure in the notebook, now including the two features.\n\nfig\n\n","type":"content","url":"/cartopy-1#add-cartographic-features-to-the-map","position":17},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Explore some of Cartopy’s map projections"},"type":"lvl2","url":"/cartopy-1#explore-some-of-cartopys-map-projections","position":18},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Explore some of Cartopy’s map projections"},"content":"\n\nInfoYou can find a list of supported projections in Cartopy, with examples, at \n\nhttps://​scitools​.org​.uk​/cartopy​/docs​/latest​/reference​/crs​.html\n\n","type":"content","url":"/cartopy-1#explore-some-of-cartopys-map-projections","position":19},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Mollweide Projection (often used with global satellite mosaics)","lvl2":"Explore some of Cartopy’s map projections"},"type":"lvl3","url":"/cartopy-1#mollweide-projection-often-used-with-global-satellite-mosaics","position":20},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Mollweide Projection (often used with global satellite mosaics)","lvl2":"Explore some of Cartopy’s map projections"},"content":"To save typing later, we can define a projection object to store the definition of the map projection.  We can then use this object in the projection kwarg of the subplot method when creating a GeoAxes object.  This allows us to use this exact projection in later scripts or Jupyter Notebook cells using simply the object name, instead of repeating the same call to ccrs.\n\nfig = plt.figure(figsize=(11, 8.5))\nprojMoll = ccrs.Mollweide(central_longitude=0)\nax = plt.subplot(1, 1, 1, projection=projMoll)\nax.set_title(\"Mollweide Projection\")\n\n","type":"content","url":"/cartopy-1#mollweide-projection-often-used-with-global-satellite-mosaics","position":21},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl4":"Add in the cartographic shapefiles","lvl3":"Mollweide Projection (often used with global satellite mosaics)","lvl2":"Explore some of Cartopy’s map projections"},"type":"lvl4","url":"/cartopy-1#add-in-the-cartographic-shapefiles","position":22},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl4":"Add in the cartographic shapefiles","lvl3":"Mollweide Projection (often used with global satellite mosaics)","lvl2":"Explore some of Cartopy’s map projections"},"content":"This example shows how to add cartographic features to the Mollweide projection defined earlier:\n\nax.coastlines()\nax.add_feature(cfeature.BORDERS, linewidth=0.5, edgecolor='blue')\nfig\n\n","type":"content","url":"/cartopy-1#add-in-the-cartographic-shapefiles","position":23},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl4":"Add a fancy background image to the map.","lvl3":"Mollweide Projection (often used with global satellite mosaics)","lvl2":"Explore some of Cartopy’s map projections"},"type":"lvl4","url":"/cartopy-1#add-a-fancy-background-image-to-the-map","position":24},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl4":"Add a fancy background image to the map.","lvl3":"Mollweide Projection (often used with global satellite mosaics)","lvl2":"Explore some of Cartopy’s map projections"},"content":"We can also use the stock_img method to add a pre-created background to a Mollweide-projection plot:\n\nax.stock_img()\nfig\n\n","type":"content","url":"/cartopy-1#add-a-fancy-background-image-to-the-map","position":25},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Lambert Azimuthal Equal Area Projection","lvl2":"Explore some of Cartopy’s map projections"},"type":"lvl3","url":"/cartopy-1#lambert-azimuthal-equal-area-projection","position":26},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Lambert Azimuthal Equal Area Projection","lvl2":"Explore some of Cartopy’s map projections"},"content":"This example is similar to the above example set, except it uses a Lambert azimuthal equal-area projection instead:\n\nfig = plt.figure(figsize=(11, 8.5))\nprojLae = ccrs.LambertAzimuthalEqualArea(central_longitude=0.0, central_latitude=0.0)\nax = plt.subplot(1, 1, 1, projection=projLae)\nax.set_title(\"Lambert Azimuthal Equal Area Projection\")\nax.coastlines()\nax.add_feature(cfeature.BORDERS, linewidth=0.5, edgecolor='blue');\n\n","type":"content","url":"/cartopy-1#lambert-azimuthal-equal-area-projection","position":27},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Create regional maps"},"type":"lvl2","url":"/cartopy-1#create-regional-maps","position":28},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Create regional maps"},"content":"\n\n","type":"content","url":"/cartopy-1#create-regional-maps","position":29},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Cartopy’s set_extent method","lvl2":"Create regional maps"},"type":"lvl3","url":"/cartopy-1#cartopys-set-extent-method","position":30},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Cartopy’s set_extent method","lvl2":"Create regional maps"},"content":"For this example, let’s create another PlateCarree projection, but this time, we’ll use Cartopy’s set_extent method to restrict the map coverage to a North American view. Let’s also choose a lower resolution for coastlines, just to illustrate how one can specify that. In addition, let’s also plot the latitude and longitude lines.\n\nNatural Earth defines three resolutions for cartographic features, specified as the strings “10m”, “50m”, and “110m”.  Only one resolution can be used at a time, and the higher the number, the less detailed the feature becomes.  You can view the documentation for this functionality at the following reference link: \n\nhttps://​www​.naturalearthdata​.com​/downloads/\n\nprojPC = ccrs.PlateCarree()\nlonW = -140\nlonE = -40\nlatS = 15\nlatN = 65\ncLat = (latN + latS) / 2\ncLon = (lonW + lonE) / 2\nres = '110m'\n\nfig = plt.figure(figsize=(11, 8.5))\nax = plt.subplot(1, 1, 1, projection=projPC)\nax.set_title('Plate Carree')\ngl = ax.gridlines(\n    draw_labels=True, linewidth=2, color='gray', alpha=0.5, linestyle='--'\n)\nax.set_extent([lonW, lonE, latS, latN], crs=projPC)\nax.coastlines(resolution=res, color='black')\nax.add_feature(cfeature.STATES, linewidth=0.3, edgecolor='brown')\nax.add_feature(cfeature.BORDERS, linewidth=0.5, edgecolor='blue');\n\nInfoPlease note, even though the calls to the `subplot` method use different projections, the calls to `set_extent` use PlateCarree. This ensures that the values we passed into `set_extent` will be transformed from degrees into the values appropriate for the projection we use for the map.\n\nThe PlateCarree projection exaggerates the spatial extent of regions closer to the poles. In the following examples, we use set_extent with stereographic and Lambert-conformal projections, which display polar regions more accurately.\n\nprojStr = ccrs.Stereographic(central_longitude=cLon, central_latitude=cLat)\nfig = plt.figure(figsize=(11, 8.5))\nax = plt.subplot(1, 1, 1, projection=projStr)\nax.set_title('Stereographic')\ngl = ax.gridlines(\n    draw_labels=True, linewidth=2, color='gray', alpha=0.5, linestyle='--'\n)\nax.set_extent([lonW, lonE, latS, latN], crs=projPC)\nax.coastlines(resolution=res, color='black')\nax.add_feature(cfeature.STATES, linewidth=0.3, edgecolor='brown')\nax.add_feature(cfeature.BORDERS, linewidth=0.5, edgecolor='blue');\n\nprojLcc = ccrs.LambertConformal(central_longitude=cLon, central_latitude=cLat)\nfig = plt.figure(figsize=(11, 8.5))\nax = plt.subplot(1, 1, 1, projection=projLcc)\nax.set_title('Lambert Conformal')\ngl = ax.gridlines(\n    draw_labels=True, linewidth=2, color='gray', alpha=0.5, linestyle='--'\n)\nax.set_extent([lonW, lonE, latS, latN], crs=projPC)\nax.coastlines(resolution='110m', color='black')\nax.add_feature(cfeature.STATES, linewidth=0.3, edgecolor='brown')\n# End last line with a semicolon to suppress text output to the screen\nax.add_feature(cfeature.BORDERS, linewidth=0.5, edgecolor='blue');\n\nInfoLat/lon labeling for projections other than Mercator and PlateCarree is a recent addition to Cartopy. As you can see, work still needs to be done to improve the placement of labels.\n\n","type":"content","url":"/cartopy-1#cartopys-set-extent-method","position":31},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Create a regional map centered over New York State","lvl2":"Create regional maps"},"type":"lvl3","url":"/cartopy-1#create-a-regional-map-centered-over-new-york-state","position":32},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Create a regional map centered over New York State","lvl2":"Create regional maps"},"content":"\n\nHere we set the domain, which defines the geographical region to be plotted.  (This is used in the next section in a set_extent call.) Since these coordinates are expressed in degrees, they correspond to a PlateCarree projection, even though the map projection is set to LambertConformal.\n\nWarningBe patient; when plotting a small geographical area, the high-resolution \"10m\" shapefiles are used by default. As a result, these plots take longer to create, especially if the shapefiles are not yet downloaded from Natural Earth. Similar issues can occur whenever a `GeoAxes` object is transformed from one coordinate system to another. (This will be covered in more detail in a subsequent page.)\n\nlatN = 45.2\nlatS = 40.2\nlonW = -80.0\nlonE = -71.5\ncLat = (latN + latS) / 2\ncLon = (lonW + lonE) / 2\nprojLccNY = ccrs.LambertConformal(central_longitude=cLon, central_latitude=cLat)\n\n","type":"content","url":"/cartopy-1#create-a-regional-map-centered-over-new-york-state","position":33},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Add some predefined features","lvl2":"Create regional maps"},"type":"lvl3","url":"/cartopy-1#add-some-predefined-features","position":34},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Add some predefined features","lvl2":"Create regional maps"},"content":"Some cartographical features are predefined as constants in the cartopy.feature package. The resolution of these features depends on the amount of geographical area in your map, specified by set_extent.\n\nfig = plt.figure(figsize=(15, 10))\nax = plt.subplot(1, 1, 1, projection=projLccNY)\nax.set_extent([lonW, lonE, latS, latN], crs=projPC)\nax.set_facecolor(cfeature.COLORS['water'])\nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.COASTLINE)\nax.add_feature(cfeature.BORDERS, linestyle='--')\nax.add_feature(cfeature.LAKES, alpha=0.5)\nax.add_feature(cfeature.STATES)\nax.add_feature(cfeature.RIVERS)\nax.set_title('New York and Vicinity');\n\nNote:For high-resolution Natural Earth shapefiles such as this, while we could add Cartopy's OCEAN feature, it currently takes much longer to render on the plot. You can create your own version of this example, with the OCEAN feature added, to see for yourself how much more rendering time is added. Instead, we take the strategy of first setting the facecolor of the entire subplot to match that of water bodies in Cartopy. When we then layer on the LAND feature, pixels that are not part of the LAND shapefile remain in the water facecolor, which is the same color as the OCEAN.\n\n","type":"content","url":"/cartopy-1#add-some-predefined-features","position":35},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Use lower-resolution shapefiles from Natural Earth","lvl2":"Create regional maps"},"type":"lvl3","url":"/cartopy-1#use-lower-resolution-shapefiles-from-natural-earth","position":36},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"Use lower-resolution shapefiles from Natural Earth","lvl2":"Create regional maps"},"content":"In this example, we create a new map.  This map uses lower-resolution shapefiles from Natural Earth, and also eliminates the plotting of country borders.\n\nThis example requires much more code than previous examples on this page.  First, we must create new objects associated with lower-resolution shapefiles.  This is performed by the NaturalEarthFeature method, which is part of the Cartopy feature class.  Second, we call add_feature to add the new objects to our new map.\n\nfig = plt.figure(figsize=(15, 10))\nax = plt.subplot(1, 1, 1, projection=projLccNY)\nax.set_extent((lonW, lonE, latS, latN), crs=projPC)\n\n# The features with names such as cfeature.LAND, cfeature.OCEAN, are higher-resolution (10m)\n# shapefiles from the Naturalearth repository.  Lower resolution shapefiles (50m, 110m) can be\n# used by using the cfeature.NaturalEarthFeature method as illustrated below.\n\nresolution = '110m'\n\nland_mask = cfeature.NaturalEarthFeature(\n    'physical',\n    'land',\n    scale=resolution,\n    edgecolor='face',\n    facecolor=cfeature.COLORS['land'],\n)\nsea_mask = cfeature.NaturalEarthFeature(\n    'physical',\n    'ocean',\n    scale=resolution,\n    edgecolor='face',\n    facecolor=cfeature.COLORS['water'],\n)\nlake_mask = cfeature.NaturalEarthFeature(\n    'physical',\n    'lakes',\n    scale=resolution,\n    edgecolor='face',\n    facecolor=cfeature.COLORS['water'],\n)\nstate_borders = cfeature.NaturalEarthFeature(\n    category='cultural',\n    name='admin_1_states_provinces_lakes',\n    scale=resolution,\n    facecolor='none',\n)\n\nax.add_feature(land_mask)\nax.add_feature(sea_mask)\nax.add_feature(lake_mask)\nax.add_feature(state_borders, linestyle='solid', edgecolor='black')\nax.set_title('New York and Vicinity; lower resolution');\n\n","type":"content","url":"/cartopy-1#use-lower-resolution-shapefiles-from-natural-earth","position":37},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"A figure with two different regional maps","lvl2":"Create regional maps"},"type":"lvl3","url":"/cartopy-1#a-figure-with-two-different-regional-maps","position":38},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl3":"A figure with two different regional maps","lvl2":"Create regional maps"},"content":"Finally, let’s create a figure with two subplots. On the first subplot, we’ll repeat the high-resolution New York State map created earlier; on the second, we’ll plot over a different part of the world.\n\n# Create the figure object\nfig = plt.figure(\n    figsize=(30, 24)\n)  # Notice we need a bigger \"canvas\" so these two maps will be of a decent size\n\n# First subplot\nax = plt.subplot(2, 1, 1, projection=projLccNY)\nax.set_extent([lonW, lonE, latS, latN], crs=projPC)\nax.set_facecolor(cfeature.COLORS['water'])\nax.add_feature(cfeature.LAND)\nax.add_feature(cfeature.COASTLINE)\nax.add_feature(cfeature.BORDERS, linestyle='--')\nax.add_feature(cfeature.LAKES, alpha=0.5)\nax.add_feature(cfeature.STATES)\nax.set_title('New York and Vicinity')\n\n# Set the domain for defining the second plot region.\nlatN = 70\nlatS = 30.2\nlonW = -10\nlonE = 50\ncLat = (latN + latS) / 2\ncLon = (lonW + lonE) / 2\n\nprojLccEur = ccrs.LambertConformal(central_longitude=cLon, central_latitude=cLat)\n\n# Second subplot\nax2 = plt.subplot(2, 1, 2, projection=projLccEur)\nax2.set_extent([lonW, lonE, latS, latN], crs=projPC)\nax2.set_facecolor(cfeature.COLORS['water'])\nax2.add_feature(cfeature.LAND)\nax2.add_feature(cfeature.COASTLINE)\nax2.add_feature(cfeature.BORDERS, linestyle='--')\nax2.add_feature(cfeature.LAKES, alpha=0.5)\nax2.add_feature(cfeature.STATES)\nax2.set_title('Europe');\n\n","type":"content","url":"/cartopy-1#a-figure-with-two-different-regional-maps","position":39},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"An example of plotting data"},"type":"lvl2","url":"/cartopy-1#an-example-of-plotting-data","position":40},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"An example of plotting data"},"content":"First, we’ll create a lat-lon grid and define some data on it.\n\nlon, lat = np.mgrid[-180:181, -90:91]\ndata = 2 * np.sin(3 * np.deg2rad(lon)) + 3 * np.cos(4 * np.deg2rad(lat))\nplt.contourf(lon, lat, data)\nplt.colorbar();\n\nPlotting data on a Cartesian grid is equivalent to plotting data in the PlateCarree projection, where meridians and parallels are all straight lines with constant spacing. As a result of this simplicity, the global datasets we use often begin in the PlateCarree projection.\n\nOnce we create our map again, we can plot these data values as a contour map. We must also specify the transform keyword argument. This is an argument to a contour-plotting method that specifies the projection type currently used by our data.  The projection type specified by this argument will be transformed into the projection type specified in the subplot method. Let’s plot our data in the Mollweide projection to see how shapes change under a transformation.\n\nfig = plt.figure(figsize=(11, 8.5))\nax = plt.subplot(1, 1, 1, projection=projMoll)\nax.coastlines()\ndataplot = ax.contourf(lon, lat, data, transform=ccrs.PlateCarree())\nplt.colorbar(dataplot, orientation='horizontal');\n\n\n\n","type":"content","url":"/cartopy-1#an-example-of-plotting-data","position":41},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Summary"},"type":"lvl2","url":"/cartopy-1#summary","position":42},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Summary"},"content":"\n\nCartopy allows for the georeferencing of Matplotlib Axes objects.\n\nCartopy’s crs class supports a variety of map projections.\n\nCartopy’s feature class allows for a variety of cartographic features to be overlaid on a georeferenced plot or subplot.\n\n\n\n","type":"content","url":"/cartopy-1#summary","position":43},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"What’s Next?"},"type":"lvl2","url":"/cartopy-1#whats-next","position":44},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"What’s Next?"},"content":"\n\nIn the next notebook, we will delve further into how one can transform data that is defined in one coordinate reference system (crs) so it displays properly on a map that uses a different crs.\n\n","type":"content","url":"/cartopy-1#whats-next","position":45},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Resources and References"},"type":"lvl2","url":"/cartopy-1#resources-and-references","position":46},{"hierarchy":{"lvl1":"Introduction to Cartopy","lvl2":"Resources and References"},"content":"Cartopy Documentation\n\nFull list of projections in Cartopy\n\nMaps with Cartopy (Ryan Abernathey)\n\nMap Projections (GeoCAT)\n\nNCAR xdev Cartopy Tutorial Video","type":"content","url":"/cartopy-1#resources-and-references","position":47},{"hierarchy":{"lvl1":"Data Formats"},"type":"lvl1","url":"/data-formats","position":0},{"hierarchy":{"lvl1":"Data Formats"},"content":"Note\n\nThis content is under construction!\n\nThere are many data file formats used commonly in the geosciences, such as NetCDF and GRIB. This section contains tutorials on how to interact with these files in Python.","type":"content","url":"/data-formats","position":1},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics"},"type":"lvl1","url":"/netcdf-cf","position":0},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics"},"content":"\n\n","type":"content","url":"/netcdf-cf","position":1},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics"},"type":"lvl1","url":"/netcdf-cf#netcdf-and-cf-the-basics","position":2},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics"},"content":"\n\n","type":"content","url":"/netcdf-cf#netcdf-and-cf-the-basics","position":3},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Overview"},"type":"lvl2","url":"/netcdf-cf#overview","position":4},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Overview"},"content":"This tutorial will begin with an introduction to netCDF. The CF data model will then be covered, and finally, important implementation details for netCDF.  The structure of the tutorial is as follows:\n\nDemonstrating gridded data\n\nDemonstrating observational data\n\n","type":"content","url":"/netcdf-cf#overview","position":5},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Prerequisites"},"type":"lvl2","url":"/netcdf-cf#prerequisites","position":6},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nNumpy Basics\n\nNecessary\n\n\n\nDatetime\n\nNecessary\n\n\n\nTime to learn: 50 minutes\n\n\n\n","type":"content","url":"/netcdf-cf#prerequisites","position":7},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Imports"},"type":"lvl2","url":"/netcdf-cf#imports","position":8},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Imports"},"content":"Some of these imports will be familiar from previous tutorials.  However, some of them likely look foreign; these will be covered in detail later in this tutorial.\n\nfrom datetime import datetime, timedelta\n\nimport numpy as np\nfrom cftime import date2num\nfrom netCDF4 import Dataset\nfrom pyproj import Proj\n\n","type":"content","url":"/netcdf-cf#imports","position":9},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Gridded Data"},"type":"lvl2","url":"/netcdf-cf#gridded-data","position":10},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Gridded Data"},"content":"\n\nLet’s say we’re working with some numerical weather forecast model output. First, we need to store the data in the netCDF format. Second, we need to ensure that the metadata follows the Climate and Forecasting conventions.  These steps ensure that a dataset is available to as many scientific data tools as is possible. The examples in this section illustrate these steps in detail.\n\nTo start, let’s assume the following about our data:\n\nThere are three spatial dimensions (x, y, and press) and one temporal dimension (times).\n\nThe native coordinate system of the model is on a regular 3km x 3km grid (x and y) that represents the Earth on a Lambert conformal projection.\n\nThe vertical dimension (press) consists of several discrete pressure levels in units of hPa.\n\nThe time dimension consists of twelve consecutive hours (times), beginning at 2200 UTC on the current day.\n\nThe following code generates the dimensional arrays just discussed:\n\nstart = datetime.utcnow().replace(hour=22, minute=0, second=0, microsecond=0)\ntimes = np.array([start + timedelta(hours=h) for h in range(13)])\n\nx = np.arange(-150, 153, 3)\ny = np.arange(-100, 100, 3)\n\npress = np.array([1000, 925, 850, 700, 500, 300, 250])\n\nIn addition to dimensional arrays, we also need a variable of interest, which holds the data values at each unique dimensional index. In these examples, this variable is called temps, and holds temperature data. Note that the dimensions correspond to the ones we just created above.\n\ntemps = np.random.randn(times.size, press.size, y.size, x.size)\n\n","type":"content","url":"/netcdf-cf#gridded-data","position":11},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Creating the file and dimensions","lvl2":"Gridded Data"},"type":"lvl3","url":"/netcdf-cf#creating-the-file-and-dimensions","position":12},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Creating the file and dimensions","lvl2":"Gridded Data"},"content":"The first step in setting up a new netCDF file is to create a new file in netCDF format and set up the shared dimensions we’ll be using in the file. We’ll be using the netCDF4 library to do all of the requisite netCDF API calls.\n\nnc = Dataset('forecast_model.nc', 'w', format='NETCDF4_CLASSIC', diskless=True)\n\nInfo\n\nThe netCDF file created in the above example resides in memory, not disk, due to the diskless=True argument. In order to create this file on disk, you must either remove this argument, or add the persist=True argument.\n\nDanger\n\nIf you open an existing file with 'w' as the second argument, any data already in the file will be overwritten. If you would like to edit the file, or add to it, open it using 'a' as the second argument.\n\nWe start the setup of this new netCDF file by creating and adding global attribute metadata.  These particular metadata elements are not required, but are recommended by the CF standard.  In addition, adding these elements to the file is simple, and helps users keep track of the data. Therefore, it is helpful to add these metadata elements, as shown below:\n\nnc.Conventions = 'CF-1.7'\nnc.title = 'Forecast model run'\nnc.institution = 'Unidata'\nnc.source = 'WRF-1.5'\nnc.history = str(datetime.utcnow()) + ' Python'\nnc.references = ''\nnc.comment = ''\n\nThis next example shows a plain-text representation of our netCDF file as it exists currently:netcdf forecast_model {\n  attributes:\n    :Conventions = \"CF-1.7\" ;\n    :title = \"Forecast model run\" ;\n    :institution = \"Unidata\" ;\n    :source = \"WRF-1.5\" ;\n    :history = \"2019-07-16 02:21:52.005718 Python\" ;\n    :references = \"\" ;\n    :comment = \"\" ;\n}\n\nInfoThis plain-text representation is known as netCDF Common Data Format Language, or CDL.\n\nVariables are an important part of every netCDF file; they are used to define data fields. However, before we can add any variables to our file, we must first define the dimensions of the data. In this example, we create dimensions called x, y, and pressure, and set the size of each dimension to the size of the corresponding data array. We then create an additional dimension, forecast_time, and set the size as None.  This defines the dimension as “unlimited”, meaning that if additional data values are added later, the netCDF file grows along this dimension.\n\nnc.createDimension('forecast_time', None)\nnc.createDimension('x', x.size)\nnc.createDimension('y', y.size)\nnc.createDimension('pressure', press.size)\nnc\n\nWhen we view our file’s CDL representation now, we can verify that the dimensions were successfully added to the netCDF file:netcdf forecast_model {\n  dimensions:\n    forecast_time = UNLIMITED (currently 13) ;\n    x = 101 ;\n    y = 67 ;\n    pressure = 7 ;\n  attributes:\n    :Conventions = \"CF-1.7\" ;\n    :title = \"Forecast model run\" ;\n    :institution = \"Unidata\" ;\n    :source = \"WRF-1.5\" ;\n    :history = \"2019-07-16 02:21:52.005718 Python\" ;\n    :references = \"\" ;\n    :comment = \"\" ;\n}\n\n","type":"content","url":"/netcdf-cf#creating-the-file-and-dimensions","position":13},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Creating and filling a variable","lvl2":"Gridded Data"},"type":"lvl3","url":"/netcdf-cf#creating-and-filling-a-variable","position":14},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Creating and filling a variable","lvl2":"Gridded Data"},"content":"\n\nThus far, we have only added basic information to this netCDF dataset; namely, the dataset dimensions and some broad metadata. As described briefly above, variables are used to define data fields in netCDF files. Here, we create a netCDF4 variable to hold a data field; in this case, the forecast air temperature. In order to create this netCDF4 variable, we must specify the data type of the values in the data field. We also must specify which dimensions contained in the netCDF file are relevant to this data field. Finally, we can specify whether or not to compress the data using a form of zlib.\n\ntemps_var = nc.createVariable(\n    'Temperature',\n    datatype=np.float32,\n    dimensions=('forecast_time', 'pressure', 'y', 'x'),\n    zlib=True,\n)\n\nWe have now created a netCDF4 variable, but it does not yet define a data field. In this example, we use Python to associate our temperature data with the new variable:\n\ntemps_var[:] = temps\ntemps_var\n\nYou can also associate data with a variable sporadically. This example illustrates how to only associate one value per time step with the variable created earlier:\n\nnext_slice = 0\nfor temp_slice in temps:\n    temps_var[next_slice] = temp_slice\n    next_slice += 1\n\nAt this point, this is the CDL representation of our dataset:netcdf forecast_model {\n  dimensions:\n    forecast_time = UNLIMITED (currently 13) ;\n    x = 101 ;\n    y = 67 ;\n    pressure = 7 ;\n  variables:\n    float Temperature(forecast_time, pressure, y, x) ;\n  attributes:\n    :Conventions = \"CF-1.7\" ;\n    :title = \"Forecast model run\" ;\n    :institution = \"Unidata\" ;\n    :source = \"WRF-1.5\" ;\n    :history = \"2019-07-16 02:21:52.005718 Python\" ;\n    :references = \"\" ;\n    :comment = \"\" ;\n}\n\nWe can also define metadata for this variable in the form of attributes; some specific attributes are required by the CF conventions. For example, the CF conventions require a units attribute to be set for all variables that represent a dimensional quantity. In addition, the value of this attribute must be parsable by the \n\nUDUNITS library. In this example, the temperatures are in Kelvin, so we set the units attribute to 'Kelvin'. Next, we set the long_name and standard_name attributes, which are recommended for most datasets, but optional. The long_name attribute contains a longer and more detailed description of a variable. On the other hand, the standard_name attribute names a variable using descriptive words from a predefined word list contained in the CF conventions. Defining these attributes allows users of your datasets to understand what each variable in a dataset represents. Sometimes, data fields do not have valid data values at every dimension point. In this case, the standard is to use a filler value for these missing data values, and to set the missing_value attribute to this filler value. In this case, however, there are no missing values, so the missing_value attribute can be set to any unused value, or not set at all.\n\nThere are many different sets of recommendations for attributes on netCDF variables. For example, here is NASA’s set of recommended attributes:\n\nNASA Dataset Interoperability Recommendations:\n\nSection 2.2 - Include Basic CF Attributes\n\nInclude where applicable: units, long_name, standard_name, valid_min / valid_max, scale_factor / add_offset and others.\n\ntemps_var.units = 'Kelvin'\ntemps_var.standard_name = 'air_temperature'\ntemps_var.long_name = 'Forecast air temperature'\ntemps_var.missing_value = -9999\ntemps_var\n\nHere is the variable section of our dataset’s CDL, with the new attributes added:  variables:\n    float Temperature(forecast_time, pressure, y, x) ;\n      Temperature:units = \"Kelvin\" ;\n      Temperature:standard_name = \"air_temperature\" ;\n      Temperature:long_name = \"Forecast air temperature\" ;\n      Temperature:missing_value = -9999.0 ;\n\n","type":"content","url":"/netcdf-cf#creating-and-filling-a-variable","position":15},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Coordinate variables","lvl2":"Gridded Data"},"type":"lvl3","url":"/netcdf-cf#coordinate-variables","position":16},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Coordinate variables","lvl2":"Gridded Data"},"content":"\n\nDimensions in a netCDF file only define size and alignment metadata. In order to properly orient data in time and space, it is necessary to create “coordinate variables”, which define data values along each dimension. A coordinate variable is typically created as a one-dimensional variable, and has the same name as the corresponding dimension.\n\nTo start, we define variables which define our x and y coordinate values. It is recommended to include certain attributes for each coordinate variable. First, you should include a standard_name, which allows for associating the variable with projections, among other things. (Projections will be covered in detail later in this page.) Second, you can include an axis attribute, which clearly defines the spatial or temporal direction referred to by the coordinate variable. This next example demonstrates how to set up these attributes:\n\nx_var = nc.createVariable('x', np.float32, ('x',))\nx_var[:] = x\nx_var.units = 'km'\nx_var.axis = 'X'  # Optional\nx_var.standard_name = 'projection_x_coordinate'\nx_var.long_name = 'x-coordinate in projected coordinate system'\n\ny_var = nc.createVariable('y', np.float32, ('y',))\ny_var[:] = y\ny_var.units = 'km'\ny_var.axis = 'Y'  # Optional\ny_var.standard_name = 'projection_y_coordinate'\ny_var.long_name = 'y-coordinate in projected coordinate system'\n\nOur dataset contains vertical data of air pressure as well, so we must define a coordinate variable for this axis; we can simply call this new variable pressure. Since this axis represents air pressure data, we can set a standard_name of 'air_pressure'.  With this standard_name attribute set, it should be obvious to users of this dataset that this variable represents a vertical axis, but for extra clarification, we also set the axis attribute as 'Z'. We can also specify one more attribute, called positive.  This attribute indicates whether the variable values increase or decrease as the dimension values increase.  Setting this attribute is optional for some data; air pressure is one example.  However, we still set the attribute here, for the sake of completeness.\n\npress_var = nc.createVariable('pressure', np.float32, ('pressure',))\npress_var[:] = press\npress_var.units = 'hPa'\npress_var.axis = 'Z'  # Optional\npress_var.standard_name = 'air_pressure'\npress_var.positive = 'down'  # Optional\n\nTime coordinates must contain a units attribute; this attribute is a string value, and must have a form similar to the string'seconds since 2019-01-06 12:00:00.00'. ‘seconds’, ‘minutes’, ‘hours’, and ‘days’ are the most commonly used time intervals in these strings. It is not recommended to use ‘months’ or ‘years’ in time strings, as the length of these time intervals can vary.\n\nBefore we can write data, we need to first convert our list of Python datetime objects to numeric values usable in time strings. We can perform this conversion by setting a time string in the format described above, then using the date2num method from the cftime library.  An example of this is shown below:\n\ntime_units = f'hours since {times[0]:%Y-%m-%d 00:00}'\ntime_vals = date2num(times, time_units)\ntime_vals\n\nNow that the time string is set up, we have all of the necessary information to set up the attributes for a forecast_time coordinate variable.  The creation of this variable is shown in the following example:\n\ntime_var = nc.createVariable('forecast_time', np.int32, ('forecast_time',))\ntime_var[:] = time_vals\ntime_var.units = time_units\ntime_var.axis = 'T'  # Optional\ntime_var.standard_name = 'time'  # Optional\ntime_var.long_name = 'time'\n\nThis next example shows the CDL representation of the netCDF file’s variables at this point. It is clear that much more information is now contained in this representation:  dimensions:\n    forecast_time = UNLIMITED (currently 13) ;\n    x = 101 ;\n    y = 67 ;\n    pressure = 7 ;\n  variables:\n    float x(x) ;\n      x:units = \"km\" ;\n      x:axis = \"X\" ;\n      x:standard_name = \"projection_x_coordinate\" ;\n      x:long_name = \"x-coordinate in projected coordinate system\" ;\n    float y(y) ;\n      y:units = \"km\" ;\n      y:axis = \"Y\" ;\n      y:standard_name = \"projection_y_coordinate\" ;\n      y:long_name = \"y-coordinate in projected coordinate system\" ;\n    float pressure(pressure) ;\n      pressure:units = \"hPa\" ;\n      pressure:axis = \"Z\" ;\n      pressure:standard_name = \"air_pressure\" ;\n      pressure:positive = \"down\" ;\n    float forecast_time(forecast_time) ;\n      forecast_time:units = \"hours since 2019-07-16 00:00\" ;\n      forecast_time:axis = \"T\" ;\n      forecast_time:standard_name = \"time\" ;\n      forecast_time:long_name = \"time\" ;\n    float Temperature(forecast_time, pressure, y, x) ;\n      Temperature:units = \"Kelvin\" ;\n      Temperature:standard_name = \"air_temperature\" ;\n      Temperature:long_name = \"Forecast air temperature\" ;\n      Temperature:missing_value = -9999.0 ;\n\n","type":"content","url":"/netcdf-cf#coordinate-variables","position":17},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Auxiliary Coordinates","lvl2":"Gridded Data"},"type":"lvl3","url":"/netcdf-cf#auxiliary-coordinates","position":18},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Auxiliary Coordinates","lvl2":"Gridded Data"},"content":"\n\nOur data are still not CF-compliant, because they do not contain latitude and longitude information, which is needed to properly locate the data. In order to add location data to a netCDF file, we must create so-called “auxiliary coordinate variables” for latitude and longitude. (In this case, the word “auxiliary” means that the variables are not simple one-dimensional variables.)\n\nIn this next example, we use the Proj function, found in the pyproj library, to create projections of our coordinates. We can then use these projections to generate latitude and longitude values for our data.\n\nX, Y = np.meshgrid(x, y)\nlcc = Proj({'proj': 'lcc', 'lon_0': -105, 'lat_0': 40, 'a': 6371000.0, 'lat_1': 25})\nlon, lat = lcc(X * 1000, Y * 1000, inverse=True)\n\nNow that we have latitude and longitude values, we can create variables for those values. Both of these variables are two-dimensional; the dimensions in question are y and x. In order to convey that it contains the longitude information, we must set up the longitude variable with a units attribute of 'degrees_east'. In addition, we can provide further clarity by setting a standard_name attribute of 'longitude'. The case is the same for latitude, except the units are 'degrees_north' and the standard_name is 'latitude'.\n\nlon_var = nc.createVariable('lon', np.float64, ('y', 'x'))\nlon_var[:] = lon\nlon_var.units = 'degrees_east'\nlon_var.standard_name = 'longitude'  # Optional\nlon_var.long_name = 'longitude coordinate'\n\nlat_var = nc.createVariable('lat', np.float64, ('y', 'x'))\nlat_var[:] = lat\nlat_var.units = 'degrees_north'\nlat_var.standard_name = 'latitude'  # Optional\nlat_var.long_name = 'latitude coordinate'\n\nNow that the auxiliary coordinate variables are created, we must identify them as coordinates for the Temperature variable. In order to identify the variables in this way, we set the coordinates attribute of the Temperature variable to a space-separated list of variables to identify, as shown below:\n\ntemps_var.coordinates = 'lon lat'\n\nThe portion of the CDL showing the new latitude and longitude variables, as well as the updated Temperature variable, is listed below:  double lon(y, x);\n    lon:units = \"degrees_east\";\n    lon:long_name = \"longitude coordinate\";\n    lon:standard_name = \"longitude\";\n  double lat(y, x);\n    lat:units = \"degrees_north\";\n    lat:long_name = \"latitude coordinate\";\n    lat:standard_name = \"latitude\";\n  float Temperature(time, y, x);\n    Temperature:units = \"Kelvin\" ;\n    Temperature:standard_name = \"air_temperature\" ;\n    Temperature:long_name = \"Forecast air temperature\" ;\n    Temperature:missing_value = -9999.0 ;\n    Temperature:coordinates = \"lon lat\";\n\n","type":"content","url":"/netcdf-cf#auxiliary-coordinates","position":19},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Coordinate System Information","lvl2":"Gridded Data"},"type":"lvl3","url":"/netcdf-cf#coordinate-system-information","position":20},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Coordinate System Information","lvl2":"Gridded Data"},"content":"\n\nSince the grid containing our data uses a Lambert conformal projection, adding this information to the dataset’s metadata can clear up some possible confusion. We can most easily add this metadata information by making use of a “grid mapping” variable. A grid mapping variable is a “placeholder” variable containing all required grid-mapping information. Other variables that need to access this information can then reference this placeholder variable in their grid_mapping attribute.\n\nIn this example, we create a grid-mapping variable; this new variable is then set up for a Lambert-conformal conic projection on a spherical globe. By setting this variable’s grid_mapping_name attribute, we can indicate which CF-supported grid mapping this variable refers to. There are additional attributes that can also be set; however, the available options depend on the specific mapping.\n\nproj_var = nc.createVariable('lambert_projection', np.int32, ())\nproj_var.grid_mapping_name = 'lambert_conformal_conic'\nproj_var.standard_parallel = 25.0\nproj_var.latitude_of_projection_origin = 40.0\nproj_var.longitude_of_central_meridian = -105.0\nproj_var.semi_major_axis = 6371000.0\nproj_var\n\nNow that we have created a grid-mapping variable, we can specify the grid mapping by setting the grid_mapping attribute to the variable name. In this example, we set the grid_mapping attribute on the Temperature variable:\n\ntemps_var.grid_mapping = 'lambert_projection'  # or proj_var.name\n\nHere is the portion of the CDL containing the modified Temperature variable, as well as the new grid-mapping lambert_projection variable:  variables:\n    int lambert_projection ;\n      lambert_projection:grid_mapping_name = \"lambert_conformal_conic ;\n      lambert_projection:standard_parallel = 25.0 ;\n      lambert_projection:latitude_of_projection_origin = 40.0 ;\n      lambert_projection:longitude_of_central_meridian = -105.0 ;\n      lambert_projection:semi_major_axis = 6371000.0 ;\n    float Temperature(forecast_time, pressure, y, x) ;\n      Temperature:units = \"Kelvin\" ;\n      Temperature:standard_name = \"air_temperature\" ;\n      Temperature:long_name = \"Forecast air temperature\" ;\n      Temperature:missing_value = -9999.0 ;\n      Temperature:coordinates = \"lon lat\" ;\n      Temperature:grid_mapping = \"lambert_projection\" ;\n\n","type":"content","url":"/netcdf-cf#coordinate-system-information","position":21},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Cell Bounds","lvl2":"Gridded Data"},"type":"lvl3","url":"/netcdf-cf#cell-bounds","position":22},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Cell Bounds","lvl2":"Gridded Data"},"content":"The use of “bounds” attributes is not required, but highly recommended. Here is a relevant excerpt from the NASA Dataset Interoperability Recommendations:\n\nNASA Dataset Interoperability Recommendations:\n\nSection 2.3 - Use CF “bounds” attributes\n\nCF conventions state: “When gridded data does not represent the point values of a field but instead represents some characteristic of the field within cells of finite ‘volume,’ a complete description of the variable should include metadata that describes the domain or extent of each cell, and the characteristic of the field that the cell values represent.”\n\nIn this set of examples, consider a rain gauge which is read every three hours, but only dumped every six hours. The netCDF file for this gauge’s data readings might look like this:netcdf precip_bucket_bounds {\n  dimensions:\n      lat = 12 ;\n      lon = 19 ;\n      time = 8 ;\n      tbv = 2;\n  variables:\n      float lat(lat) ;\n      float lon(lon) ;\n      float time(time) ;\n        time:units = \"hours since 2019-07-12 00:00:00.00\";\n        time:bounds = \"time_bounds\" ;\n      float time_bounds(time,tbv)\n      float precip(time, lat, lon) ;\n        precip:units = \"inches\" ;\n  data:\n    time = 3, 6, 9, 12, 15, 18, 21, 24;\n    time_bounds = 0, 3, 0, 6, 6, 9, 6, 12, 12, 15, 12, 18, 18, 21, 18, 24;\n}\n\nConsidering the coordinate variable for time, and the bounds attribute set for this variable, the below graph illustrates the times of the gauge’s data readings:|---X\n|-------X\n        |---X\n        |-------X\n                |---X\n                |-------X\n                        |---X\n                        |-------X\n0   3   6   9  12  15  18  21  24\n\n","type":"content","url":"/netcdf-cf#cell-bounds","position":23},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Observational Data"},"type":"lvl2","url":"/netcdf-cf#observational-data","position":24},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Observational Data"},"content":"Thus far, we have only worked with data arranged on grids. One common type of data, called “in-situ” or “observational” data, is usually arranged in other ways. The CF conventions for this type of data are called Conventions for DSG (Discrete Sampling Geometries).\n\nFor data that are regularly sampled (e.g., from a vertical profiler site), this is straightforward. For these examples, we will be using vertical profile data from three hypothetical profilers, located in Boulder, Norman, and Albany. These hypothetical profilers report data for every 10 m of altitude, from altitudes of 10 m up to (but not including) 1000 m. This first example illustrates how to set up latitude, longitude, altitude, and other necessary data for these profilers:\n\nlons = np.array([-97.1, -105, -73.8])\nlats = np.array([35.25, 40, 42.75])\nheights = np.linspace(10, 1000, 10)\ntemps = np.random.randn(lats.size, heights.size)\nstids = ['KBOU', 'KOUN', 'KALB']\n\n","type":"content","url":"/netcdf-cf#observational-data","position":25},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Creation and basic setup","lvl2":"Observational Data"},"type":"lvl3","url":"/netcdf-cf#creation-and-basic-setup","position":26},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Creation and basic setup","lvl2":"Observational Data"},"content":"First, we create a new netCDF file, and define dimensions for it, corresponding to altitude and latitude. Since we are working with observational profile data, we define these dimensions as heights and station. We then set the global featureType attribute to 'profile', which defines the file as holding profile data. In these examples, the term “profile data” is defined as “an ordered set of data points along a vertical line at a fixed horizontal position and fixed time”. In addition, we define a placeholder dimension called str_len, which helps with storing station IDs as strings.\n\nnc.close()\nnc = Dataset('obs_data.nc', 'w', format='NETCDF4_CLASSIC', diskless=True)\nnc.createDimension('station', lats.size)\nnc.createDimension('heights', heights.size)\nnc.createDimension('str_len', 4)\nnc.Conventions = 'CF-1.7'\nnc.featureType = 'profile'\nnc\n\nAfter this initial setup, the current state of our netCDF file is described in the following CDL:netcdf obs_data {\n  dimensions:\n    station = 3 ;\n    heights = 10 ;\n    str_len = 4 ;\n  attributes:\n    :Conventions = \"CF-1.7\" ;\n    :featureType = \"profile\" ;\n}\n\nThis example illustrates the setup of coordinate variables for latitude and longitude:\n\nlon_var = nc.createVariable('lon', np.float64, ('station',))\nlon_var.units = 'degrees_east'\nlon_var.standard_name = 'longitude'\n\nlat_var = nc.createVariable('lat', np.float64, ('station',))\nlat_var.units = 'degrees_north'\nlat_var.standard_name = 'latitude'\n\nWhen a coordinate variable refers to an instance of a feature, netCDF standards refer to it as an “instance variable”. The latitude and longitude coordinate variables declared above are examples of instance variables. In this next example, we create an instance variable for altitude, referred to here as heights:\n\nheights_var = nc.createVariable('heights', np.float32, ('heights',))\nheights_var.units = 'meters'\nheights_var.standard_name = 'altitude'\nheights_var.positive = 'up'\nheights_var[:] = heights\n\n","type":"content","url":"/netcdf-cf#creation-and-basic-setup","position":27},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Station IDs","lvl2":"Observational Data"},"type":"lvl3","url":"/netcdf-cf#station-ids","position":28},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Station IDs","lvl2":"Observational Data"},"content":"Using the placeholder dimension defined earlier, we can write the station IDs of our profilers to a variable as well. The variable used to store these station IDs is two-dimensional; however, one of these dimensions only holds metadata designed to aid in converting strings to character arrays. We can also assign the attribute cf_role to this variable, with a value of 'profile_id'.  If certain software programs read this netCDF file, this attribute assists in identifying individual profiles.\n\nstid_var = nc.createVariable('stid', 'c', ('station', 'str_len'))\nstid_var.cf_role = 'profile_id'\nstid_var.long_name = 'Station identifier'\nstid_var[:] = stids\n\nAfter adding station ID information, our file’s updated CDL should resemble this example:netcdf obs_data {\n  dimensions:\n    station = 3 ;\n    heights = 10 ;\n    str_len = 4 ;\n  variables:\n    double lon(station) ;\n      lon:units = \"degrees_east\" ;\n      lon:standard_name = \"longitude\" ;\n    double lat(station) ;\n      lat:units = \"degrees_north\" ;\n      lat:standard_name = \"latitude\" ;\n    float heights(heights) ;\n      heights:units = \"meters\" ;\n      heights:standard_name = \"altitude\";\n      heights:positive = \"up\" ;\n    char stid(station, str_len) ;\n      stid:cf_role = \"profile_id\" ;\n      stid:long_name = \"Station identifier\" ;\n  attributes:\n    :Conventions = \"CF-1.7\" ;\n    :featureType = \"profile\" ;\n}\n\n","type":"content","url":"/netcdf-cf#station-ids","position":29},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Writing the field","lvl2":"Observational Data"},"type":"lvl3","url":"/netcdf-cf#writing-the-field","position":30},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"Writing the field","lvl2":"Observational Data"},"content":"The final setup step for this netCDF file is to write our actual profile data to the file. In addition, we add an additional scalar variable, which holds the time of data capture for each profile:\n\ntime_var = nc.createVariable('time', np.float32, ())\ntime_var.units = 'minutes since 2019-07-16 17:00'\ntime_var.standard_name = 'time'\ntime_var[:] = [5.0]\n\ntemp_var = nc.createVariable('temperature', np.float32, ('station', 'heights'))\ntemp_var.units = 'celsius'\ntemp_var.standard_name = 'air_temperature'\ntemp_var.coordinates = 'lon lat heights time'\n\nThe auxiliary coordinate variables in this netCDF file are not proper coordinate variables, and are all associated with the station dimension. Therefore, the names of these variables must be listed in an attribute called coordinates. The final CDL of the variables, including the coordinates attribute, is shown below:  variables:\n    double lon(station) ;\n      lon:units = \"degrees_east\" ;\n      lon:standard_name = \"longitude\" ;\n    double lat(station) ;\n      lat:units = \"degrees_north\" ;\n      lat:standard_name = \"latitude\" ;\n    float heights(heights) ;\n      heights:units = \"meters\" ;\n      heights:standard_name = \"altitude\";\n      heights:positive = \"up\" ;\n    char stid(station, str_len) ;\n      stid:cf_role = \"profile_id\" ;\n      stid:long_name = \"Station identifier\" ;\n    float time ;\n      time:units = \"minutes since 2019-07-16 17:00\" ;\n      time:standard_name = \"time\" ;\n    float temperature(station, heights) ;\n      temperature:units = \"celsius\" ;\n      temperature:standard_name = \"air_temperature\" ;\n      temperature:coordinates = \"lon lat heights time\" ;\n\nThese standards for storing DSG data in netCDF files can be used for profiler data, as shown in these examples, as well as timeseries and trajectory data, and any combination of these types of data models. You can also use these standards for datasets with differing amounts of data in each feature, using so-called “ragged” arrays. For more information on ragged arrays, or other elements of the CF DSG standards, see the \n\nmain documentation page, or try some of the \n\nannotated DSG examples.\n\n\n\n","type":"content","url":"/netcdf-cf#writing-the-field","position":31},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Summary"},"type":"lvl2","url":"/netcdf-cf#summary","position":32},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Summary"},"content":"We have created examples of and discussed the structure of netCDF Datasets, both gridded and in-situ. In addition, we covered the Climate and Forecasting (CF) Conventions, and the setup of netCDF files that follow these conventions. netCDF Datasets are self-describing; in other words, their attributes, or metadata, are included. Other libraries in the Python scientific software ecosystem, such as xarray and MetPy, are therefore easily able to read in, write to, and analyze these Datasets.","type":"content","url":"/netcdf-cf#summary","position":33},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/netcdf-cf#whats-next","position":34},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl3":"What’s Next?","lvl2":"Summary"},"content":"In subsequent notebooks, we will work with netCDF Datasets built from actual, non-example data sources, both model and in-situ.\n\n","type":"content","url":"/netcdf-cf#whats-next","position":35},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Resources and References"},"type":"lvl2","url":"/netcdf-cf#resources-and-references","position":36},{"hierarchy":{"lvl1":"NetCDF and CF: The Basics","lvl2":"Resources and References"},"content":"CF Conventions doc (1.7)\n\nJonathan Gregory’s old CF presentation\n\nCF Data Model (cfdm) python package tutorial\n\nTim Whiteaker’s cfgeom python package (GitHub repo) and \n\n(tutorial)\n\nnetCDF4 Documentation","type":"content","url":"/netcdf-cf#resources-and-references","position":37},{"hierarchy":{"lvl1":"Datetime"},"type":"lvl1","url":"/datetime","position":0},{"hierarchy":{"lvl1":"Datetime"},"content":"Note\n\nThis content is under construction!\n\nThis section contains tutorials on dealing with times and calendars in scientific Python. The first and most basic of these tutorials covers the standard Python library known as \n\ndatetime.\n\nWhen this chapter is fully built out, it will include a comprehensive guide to different time libraries, where to use them, and when they might be useful. This set of time libraries includes these libraries, among others:\n\nNumpy datetime64 (for efficient vectorized date and time operations)\n\ncftime library (for dealing with dates and times in non-standard calendars)\n\nThese tutorials will be cross-referenced with other tutorials on time-related topics, such as dealing with timeseries data in \n\nPandas and \n\nXarray.","type":"content","url":"/datetime","position":1},{"hierarchy":{"lvl1":"Times and Dates in Python"},"type":"lvl1","url":"/datetime-1","position":0},{"hierarchy":{"lvl1":"Times and Dates in Python"},"content":"\n\n","type":"content","url":"/datetime-1","position":1},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Overview"},"type":"lvl2","url":"/datetime-1#overview","position":2},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Overview"},"content":"Time is an essential component of nearly all geoscience data. Timescales commonly used in science can have many different orders of magnitude, from mere microseconds to millions or even billions of years.  Some of these magnitudes are listed below:\n\nmicroseconds for lightning\n\nhours for a supercell thunderstorm\n\ndays for a global weather model\n\nmillennia and beyond for the earth’s climate\n\nTo properly analyze geoscience data, you must have a firm understanding of how to handle time in Python.\n\nIn this notebook, we will:\n\nIntroduce the \n\ntime and \n\ndatetime modules from the Python Standard Library\n\nLook at formatted input and output of dates and times\n\nSee how we can do simple arithmetic on date and time data, by making use of the timedelta object\n\nBriefly make use of the \n\npytz module to handle some thorny time zone issues in Python.\n\n","type":"content","url":"/datetime-1#overview","position":3},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Prerequisites"},"type":"lvl2","url":"/datetime-1#prerequisites","position":4},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nPython Quickstart\n\nNecessary\n\nUnderstanding strings\n\nBasic Python string formatting\n\nHelpful\n\nTry this \n\nReal Python string formatting tutorial\n\nTime to learn: 30 minutes\n\n\n\n","type":"content","url":"/datetime-1#prerequisites","position":5},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Imports"},"type":"lvl2","url":"/datetime-1#imports","position":6},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Imports"},"content":"For the examples on this page, we import three modules from the Python Standard Library, as well as one third-party module.  The import syntax used here, as well as a discussion on this syntax and an overview of these modules, can be found in the next section.\n\n# Python Standard Library packages\n# We'll discuss below WHY we alias the packages this way\nimport datetime as dt\nimport math\nimport time as tm\n\n# Third-party package for time zone handling, we'll discuss below!\nimport pytz\n\n","type":"content","url":"/datetime-1#imports","position":7},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Time Versus Datetime modules"},"type":"lvl2","url":"/datetime-1#time-versus-datetime-modules","position":8},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Time Versus Datetime modules"},"content":"","type":"content","url":"/datetime-1#time-versus-datetime-modules","position":9},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"Some core terminology","lvl2":"Time Versus Datetime modules"},"type":"lvl3","url":"/datetime-1#some-core-terminology","position":10},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"Some core terminology","lvl2":"Time Versus Datetime modules"},"content":"Every Python installation comes with a Standard Library, which includes many helpful modules; in these examples, we cover the \n\ntime and \n\ndatetime modules. Unfortunately, the use of dates and times in Python can be disorienting.  There are many different terms used in Python relating to dates and times, and many such terms apply to multiple scopes, such as modules, classes, and functions. For example:\n\ndatetime module has a datetime class\n\ndatetime module has a time class\n\ndatetime module has a date class\n\ntime module has a time function, which returns (almost always) \n\nUnix time\n\ndatetime class has a date method, which returns a date object\n\ndatetime class has a time method, which returns a time object\n\nThis confusion can be partially alleviated by aliasing our imported modules, we did above:import datetime as dt\nimport time as tm\n\nWe can now reference the datetime module (aliased to dt) and datetime class unambiguously.\n\npisecond = dt.datetime(2021, 3, 14, 15, 9, 26)\nprint(pisecond)\n\nOur variable pisecond now stores a particular date and time, which just happens to be π-day 2021 down to the nearest second (3.1415926...).\n\nnow = tm.time()\nprint(now)\n\nThe variable now holds the current time in seconds since January 1, 1970 00:00 UTC.  For more information on this important, but seemingly esoteric time format, see the section on this page called “\n\nWhat is Unix Time”. In addition, if you are not familiar with UTC, there is a section on this page called “\n\nWhat is UTC”.\n\n","type":"content","url":"/datetime-1#some-core-terminology","position":11},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"time module","lvl2":"Time Versus Datetime modules"},"type":"lvl3","url":"/datetime-1#time-module","position":12},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"time module","lvl2":"Time Versus Datetime modules"},"content":"The time module is well-suited for measuring \n\nUnix time. For example, when you are calculating how long it takes a Python function to run, you can employ the time() function, which can be found in the time module, to obtain Unix time before and after the function completes.  You can then take the difference of those two times to determine how long the function was running. (Measuring the runtime of a block of code this way is known as “benchmarking”.)\n\nstart = tm.time()\ntm.sleep(1)  # The sleep function will stop the program for n seconds\nend = tm.time()\ndiff = end - start\nprint(f\"The benchmark took {diff} seconds\")\n\nInfoYou can use the `timeit` module and the `timeit` Jupyter magic for more accurate benchmarking. Documentation on these can be found \n\nhere.\n\n","type":"content","url":"/datetime-1#time-module","position":13},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"What is Unix Time?","lvl2":"Time Versus Datetime modules"},"type":"lvl3","url":"/datetime-1#what-is-unix-time","position":14},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"What is Unix Time?","lvl2":"Time Versus Datetime modules"},"content":"Unix time is an example of system time, which is how a computer tracks the passage of time. Computers do not inherently know human representations of time; as such, they store time as a large binary number, indicating a number of time units after a set date and time.  This is much easier for a computer to keep track of.  In the case of Unix time, the time unit is seconds, and the set date and time is the epoch.  Therefore, Unix time is the number of seconds since the epoch.  The epoch is defined as January 1, 1970 00:00 \n\nUTC.  This is quite confusing for humans, but again, computers store time in a way that makes sense for them. It is represented “under the hood” as a \n\nfloating point number which is how computers represent real (ℝ) numbers.\n\n","type":"content","url":"/datetime-1#what-is-unix-time","position":15},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"datetime module","lvl2":"Time Versus Datetime modules"},"type":"lvl3","url":"/datetime-1#datetime-module","position":16},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"datetime module","lvl2":"Time Versus Datetime modules"},"content":"The datetime module handles time with the Gregorian calendar (the calendar we, as humans, are familiar with); it is independent of Unix time. The datetime module uses an \n\nobject-oriented approach; it contains the date, time, datetime, timedelta, and tzinfo classes.\n\ndate class represents the day, month, and year\n\ntime class represents the time of day\n\ndatetime class is a combination of the date and time classes\n\ntimedelta class represents a time duration\n\ntzinfo class represents time zones, and is an abstract class.\n\nThe datetime module is effective for:\n\nperforming date and time arithmetic and calculating time duration\n\nreading and writing date and time strings with various formats\n\nhandling time zones (with the help of third-party libraries)\n\nThe time and datetime modules overlap in functionality, but in your geoscientific work, you will probably be using the datetime module more than the time module.\n\nWe’ll delve into more details below, but here’s a quick example of writing out our pisecond datetime object as a formatted string. Suppose we wanted to write out just the date, and write it in the month/day/year format typically used in the US. We can do this using the strftime() method.  This method formats datetime objects using format specifiers.  An example of its usage is shown below:\n\nprint('Pi day occurred on:', pisecond.strftime(format='%m/%d/%Y'))\n\n","type":"content","url":"/datetime-1#datetime-module","position":17},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Reading and writing dates and times"},"type":"lvl2","url":"/datetime-1#reading-and-writing-dates-and-times","position":18},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Reading and writing dates and times"},"content":"","type":"content","url":"/datetime-1#reading-and-writing-dates-and-times","position":19},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"Parsing lightning data timestamps with the datetime.strptime method","lvl2":"Reading and writing dates and times"},"type":"lvl3","url":"/datetime-1#parsing-lightning-data-timestamps-with-the-datetime-strptime-method","position":20},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"Parsing lightning data timestamps with the datetime.strptime method","lvl2":"Reading and writing dates and times"},"content":"In this example, we are analyzing \n\nUS NLDN lightning data. Here is a sample row of data:06/27/07 16:18:21.898 18.739 -88.184 0.0 kA 0 1.0 0.4 2.5 8 1.2 13 G\n\nPart of the task involves parsing the 06/27/07 16:18:21.898 time string into a datetime object. (Although it is outside the scope of this page’s tutorial, a full description of this lightning data format can be found \n\nhere.) In order to parse this string or others that follow the same format, you will need to employ the \n\ndatetime.strptime() method from the datetime module. This method takes two arguments:\n\nthe date/time string you wish to parse\n\nthe format which describes exactly how the date and time are arranged.\n\nThe full range of formatting options for strftime() and strptime() is described in the Python documentation. In most cases, finding the correct formatting options inherently takes some degree of experimentation to get right. This is a situation where Python shines; you can use the IPython interpreter, or a Jupyter notebook, to quickly test numerous formatting options. Beyond the official documentation, Google and Stack Overflow are your friends in this process.\n\nAfter some trial and error (as described above), you can find that, in this example, the format string '%m/%d/%y %H:%M:%S.%f' will convert the date and time in the data to the correct format.\n\nstrike_time = dt.datetime.strptime('06/27/07 16:18:21.898', '%m/%d/%y %H:%M:%S.%f')\n# print strike_time to see if we have properly parsed our time\nprint(strike_time)\n\n","type":"content","url":"/datetime-1#parsing-lightning-data-timestamps-with-the-datetime-strptime-method","position":21},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"Example usage of the datetime object","lvl2":"Reading and writing dates and times"},"type":"lvl3","url":"/datetime-1#example-usage-of-the-datetime-object","position":22},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"Example usage of the datetime object","lvl2":"Reading and writing dates and times"},"content":"Why did we bother doing this? This is a deceptively simple example; it may appear that we only took the string 06/27/07 16:18:21.898 and reformatted it to 2007-06-27 16:18:21.898000.\n\nHowever, our new variable, strike_time, is in fact a datetime object that we can manipulate in many useful ways.\n\nHere are a few quick examples of the advantages of a datetime object:\n\n","type":"content","url":"/datetime-1#example-usage-of-the-datetime-object","position":23},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl4":"Controlling the output format with strftime()","lvl3":"Example usage of the datetime object","lvl2":"Reading and writing dates and times"},"type":"lvl4","url":"/datetime-1#controlling-the-output-format-with-strftime","position":24},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl4":"Controlling the output format with strftime()","lvl3":"Example usage of the datetime object","lvl2":"Reading and writing dates and times"},"content":"The following example shows how to write out the time only, without a date, in a particular format:16h 18m 21s\n\nWe can do this with the \n\ndatetime.strftime() method, which takes a format identical to the one we employed for strptime(). After some trial and error from the IPython interpreter, we arrive at '%Hh %Mm %Ss':\n\nprint(strike_time.strftime(format='%Hh %Mm %Ss'))\n\n","type":"content","url":"/datetime-1#controlling-the-output-format-with-strftime","position":25},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl4":"A simple query of just the year:","lvl3":"Example usage of the datetime object","lvl2":"Reading and writing dates and times"},"type":"lvl4","url":"/datetime-1#a-simple-query-of-just-the-year","position":26},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl4":"A simple query of just the year:","lvl3":"Example usage of the datetime object","lvl2":"Reading and writing dates and times"},"content":"Here’s a useful shortcut that doesn’t even need a format specifier:\n\nstrike_time.year\n\nThis works because the datetime object stores the data as individual attributes:\nyear, month, day, hour, minute, second, microsecond.\n\n","type":"content","url":"/datetime-1#a-simple-query-of-just-the-year","position":27},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl4":"See how many days have elapsed since the strike:","lvl3":"Example usage of the datetime object","lvl2":"Reading and writing dates and times"},"type":"lvl4","url":"/datetime-1#see-how-many-days-have-elapsed-since-the-strike","position":28},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl4":"See how many days have elapsed since the strike:","lvl3":"Example usage of the datetime object","lvl2":"Reading and writing dates and times"},"content":"This example shows how to find the number of days since an event; in this case, the lightning strike described earlier:\n\n(dt.datetime.now() - strike_time).days\n\nThe above example illustrates some simple arithmetic with datetime objects.  This commonly-used feature will be covered in more detail in the next section.\n\n","type":"content","url":"/datetime-1#see-how-many-days-have-elapsed-since-the-strike","position":29},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Calculating coastal tides with the timedelta class"},"type":"lvl2","url":"/datetime-1#calculating-coastal-tides-with-the-timedelta-class","position":30},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Calculating coastal tides with the timedelta class"},"content":"In these examples, we will look at current data pertaining to coastal tides during a \n\ntropical cyclone storm surge.\n\nThe \n\nlunar day is 24 hours and 50 minutes; there are two low tides and two high tides in that time duration. If we know the time of the current high tide, we can easily calculate the occurrence of the next low and high tides by using the \n\ntimedelta class. (In reality, the exact time of tides is influenced by local coastal effects, in addition to the laws of celestial mechanics, but we will ignore that fact for this exercise.)\n\nThe timedelta class is initialized by supplying time duration, usually supplied with \n\nkeyword arguments, to clearly express the length of time. The timedelta class allows you to perform arithmetic with dates and times using standard operators (i.e., +, -, *, /).  You can use these operators with a timedelta object, and either another timedelta object, a datetime object, or a numeric literal, to obtain objects representing new dates and times.\n\nThis convenient language feature is known as \n\noperator overloading, and is another example of Python offering built-in functionality to make programming easier. (In some other languages, such as Java, you would have to call a method to perform such operations, which significantly obfuscates the code.)\n\nIn addition, you can use these arithmetic operators with two datetime objects, as shown above with \n\nlightning-strike data, to create timedelta objects. Let’s examine all these features in the following code block.\n\nhigh_tide = dt.datetime(2016, 6, 1, 4, 38, 0)\nlunar_day = dt.timedelta(hours=24, minutes=50)\ntide_duration = lunar_day / 4  # Here we do some arithmetic on the timedelta object!\nnext_low_tide = (\n    high_tide + tide_duration\n)  # Here we add a timedelta object to a datetime object\nnext_high_tide = high_tide + (2 * tide_duration)  # and so on\ntide_length = next_high_tide - high_tide\nprint(f\"The time between high and low tide is {tide_duration}.\")\nprint(f\"The current high tide is {high_tide}.\")\nprint(f\"The next low tide is {next_low_tide}.\")\nprint(f\"The next high tide {next_high_tide}.\")\nprint(f\"The tide length is {tide_length}.\")\nprint(f\"The type of the 'tide_length' variable is {type(tide_length)}.\")\n\nTo illustrate that the difference of two times yields a timedelta object, we can use a built-in Python function called type(), which returns the type of its argument.  In the above example, we call type() in the last print statement, and it returns the type of timedelta.\n\n","type":"content","url":"/datetime-1#calculating-coastal-tides-with-the-timedelta-class","position":31},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Dealing with Time Zones"},"type":"lvl2","url":"/datetime-1#dealing-with-time-zones","position":32},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Dealing with Time Zones"},"content":"Time zones can be a source of confusion and frustration in geoscientific data and in computer programming in general. Core date and time libraries in various programming languages, including Python, inevitably have design flaws, relating to time zones, date and time formatting, and other inherently complex issues.  Third-party libraries are often created to fix the limitations of the core libraries, but this approach is frequently unsuccessful. To avoid time-zone-related issues, it is best to handle data in UTC; if data cannot be handled in UTC, efforts should be made to consistently use the same time zone for all data.  However, this is not always possible; events such as severe weather are expected to be reported in a local time zone, which is not always consistent.","type":"content","url":"/datetime-1#dealing-with-time-zones","position":33},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"What is UTC?","lvl2":"Dealing with Time Zones"},"type":"lvl3","url":"/datetime-1#what-is-utc","position":34},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"What is UTC?","lvl2":"Dealing with Time Zones"},"content":"“\n\nUTC” is a combination of the French and English abbreviations for Coordinated Universal Time.  It is, in practice, equivalent to Greenwich Mean Time (GMT), the time zone at 0 degrees longitude.  (The prime meridian, 0 degrees longitude, runs through Greenwich, a district of London, England.) In geoscientific data, times are often in UTC, although you should always verify that this is actually true to avoid time zone issues.","type":"content","url":"/datetime-1#what-is-utc","position":35},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"Time Zone Naive Versus Time Zone Aware datetime Objects","lvl2":"Dealing with Time Zones"},"type":"lvl3","url":"/datetime-1#time-zone-naive-versus-time-zone-aware-datetime-objects","position":36},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"Time Zone Naive Versus Time Zone Aware datetime Objects","lvl2":"Dealing with Time Zones"},"content":"When you create datetime objects in Python, they are “time zone naive”, or, if the subject of time zones is assumed, simply “naive”.  This means that they are unaware of the time zone of the date and time they represent; time zone naive is the opposite of time zone aware. In many situations, you can happily go forward without this detail getting in the way of your work. As the \n\nPython documentation states:\n\nNaive objects are easy to understand and to work with, at the cost of ignoring some aspects of reality.\n\nHowever, if you wish to convey time zone information, you will have to make your datetime objects time zone aware. The datetime library is able to easily convert the time zone to UTC, also converting the object to a time zone aware state, as shown below:\n\nnaive = dt.datetime.now()\naware = dt.datetime.now(dt.timezone.utc)\nprint(f\"I am time zone naive {naive}.\")\nprint(f\"I am time zone aware {aware}.\")\n\nNotice that aware has +00:00 appended at the end, indicating zero hours offset from UTC.\n\nOur naive object shows the local time on whatever computer was used to run this code. If you’re reading this online, chances are the code was executed on a cloud server that already uses UTC.  If this is the case, naive and aware will differ only at the microsecond level, due to round-off error.\n\nIn the code above, we used dt.timezone.utc to initialize the UTC timezone for our aware object. Unfortunately, at this time, the Python Standard Library does not fully support initializing datetime objects with arbitrary time zones; it also does not fully support conversions between time zones for datetime objects.  However, there exist third-party libraries that provide some of this functionality; one such library is covered below.\n\n","type":"content","url":"/datetime-1#time-zone-naive-versus-time-zone-aware-datetime-objects","position":37},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"Full time zone support with the pytz module","lvl2":"Dealing with Time Zones"},"type":"lvl3","url":"/datetime-1#full-time-zone-support-with-the-pytz-module","position":38},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"Full time zone support with the pytz module","lvl2":"Dealing with Time Zones"},"content":"For improved handling of time zones in Python, you will need the third-party \n\npytz module, whose classes build upon, or, in object-oriented programming terms, inherit from, classes from the datetime module.\n\nIn this next example, we repeat the above exercise, but this time, we use a method from the pytz module to initialize the aware object in a different time zone:\n\nnaive = dt.datetime.now()\naware = dt.datetime.now(pytz.timezone('US/Mountain'))\nprint(f\"I am time zone naive: {naive}.\")\nprint(f\"I am time zone aware: {aware}.\")\n\nThe pytz.timezone() method takes a time zone string; if this string is formatted correctly, the method returns a tzinfo object, which can be used when making a datetime object time zone aware.  This initializes the time zone for the newly aware object to a specific time zone matching the time zone string. The -06:00 indicates that we are now operating in a time zone six hours behind UTC.","type":"content","url":"/datetime-1#full-time-zone-support-with-the-pytz-module","position":39},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"Print Time with a Different Time Zone","lvl2":"Dealing with Time Zones"},"type":"lvl3","url":"/datetime-1#print-time-with-a-different-time-zone","position":40},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"Print Time with a Different Time Zone","lvl2":"Dealing with Time Zones"},"content":"If you have data that are in UTC, and wish to convert them to another time zone (in this example, US Mountain Time Zone), you will again need to make use of the pytz module.\n\nFirst, we will create a new datetime object with the \n\nutcnow() method.  Despite the name of this method, the newly created object is time zone naive.  Therefore, we must invoke the object’s \n\nreplace() method and specify UTC with a tzinfo object in order to make the object time zone aware. As described above, we can use the pytz module’s timezone() method to create a new tzinfo object, again using the time zone string ‘US/Mountain’ (US Mountain Time Zone). To convert the datetime object utc from UTC to Mountain Time, we can then run the \n\nastimezone() method.\n\nutc = dt.datetime.utcnow().replace(tzinfo=pytz.utc)\nprint(\"The UTC time is {}.\".format(utc.strftime('%B %d, %Y, %-I:%M%p')))\nmountaintz = pytz.timezone(\"US/Mountain\")\nny = utc.astimezone(mountaintz)\nprint(\"The 'US/Mountain' time is {}.\".format(ny.strftime('%B %d, %Y, %-I:%M%p')))\n\nIn the above example, we also use the strftime() method to format the date and time string in a human-friendly format.\n\n\n\n","type":"content","url":"/datetime-1#print-time-with-a-different-time-zone","position":41},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Summary"},"type":"lvl2","url":"/datetime-1#summary","position":42},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Summary"},"content":"The Python Standard Library contains several modules for dealing with date and time data. We saw how we can avoid some name ambiguities by aliasing the module names; this can be done with import statements like import datetime as dt and import time as tm. The tm.time() method just returns the current \n\nUnix time in seconds -- which can be useful for measuring elapsed time, but not all that useful for working with geophysical data.\n\nThe datetime module contains various classes for storing, converting, comparing, and formatting date and time data on the Gregorian calendar. We saw how we can parse data files with date and time strings into dt.datetime objects using the dt.datetime.strptime() method. We also saw how to perform arithmetic using date and time data; this uses the dt.timedelta class to represent intervals of time.\n\nFinally, we looked at using the third-party \n\npytz module to handle time zone awareness and conversions.","type":"content","url":"/datetime-1#summary","position":43},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/datetime-1#whats-next","position":44},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl3":"What’s Next?","lvl2":"Summary"},"content":"In subsequent tutorials, we will dig deeper into different time and date formats, and discuss how they are handled by important Python modules such as Numpy, Pandas, and Xarray.\n\n","type":"content","url":"/datetime-1#whats-next","position":45},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Resources and References"},"type":"lvl2","url":"/datetime-1#resources-and-references","position":46},{"hierarchy":{"lvl1":"Times and Dates in Python","lvl2":"Resources and References"},"content":"This page was based on and adapted from material in \n\nUnidata’s Python Training.\n\nFor further reading on these modules, take a look at the official documentation for:\n\ntime\n\ndatetime\n\npytz\n\nFor more information on Python string formatting, try:\n\nPython string documentation\n\nRealPython’s \n\nstring formatting tutorial (nicely written)","type":"content","url":"/datetime-1#resources-and-references","position":47},{"hierarchy":{"lvl1":"Matplotlib"},"type":"lvl1","url":"/matplotlib","position":0},{"hierarchy":{"lvl1":"Matplotlib"},"content":"","type":"content","url":"/matplotlib","position":1},{"hierarchy":{"lvl1":"Matplotlib"},"type":"lvl1","url":"/matplotlib#matplotlib","position":2},{"hierarchy":{"lvl1":"Matplotlib"},"content":"Matplotlib is the go-to library for plotting within Python. Numerous packages and libraries build off of Matplotlib, making it the de facto standard Python plotting package. If you were to learn a single plotting tool to keep in your toolbox, this is it.","type":"content","url":"/matplotlib#matplotlib","position":3},{"hierarchy":{"lvl1":"Matplotlib","lvl2":"Why Matplotlib?"},"type":"lvl2","url":"/matplotlib#why-matplotlib","position":4},{"hierarchy":{"lvl1":"Matplotlib","lvl2":"Why Matplotlib?"},"content":"Matplotlib is a plotting library for Python and is often the first plotting package Python learners encounter. You may be wondering, “Why learn Matplotlib? Why not \n\nSeaborn or another plotting library first?”\n\nThe simple answer to the much-asked question of “why Matplotlib?” is that it is extremely popular; in fact, Matplotlib is one of the most popular Python packages. Because of its history as Python’s “go-to” plotting package, most other open source plotting libraries, including Seaborn, are built on top of Matplotlib; thus, these more specialized plotting packages inherit some of Matplotlib’s capabilities, syntax, and limitations. Thus, you will find it useful to be familiar with Matplotlib when learning other plotting libraries.\n\nMatplotlib supports a variety of output formats, chart types, and interactive options, and runs well on most operating systems and graphic backends. The key features of Matplotlib are its extensibility and the \n\nextensive documentation available to the community. All of these things contribute to Matplotlib’s popularity, which is the answer to the question of “Why Matplotlib”, and the reason Matplotlib is the first plotting package we will introduce you to in this book.","type":"content","url":"/matplotlib#why-matplotlib","position":5},{"hierarchy":{"lvl1":"Matplotlib","lvl2":"In this section"},"type":"lvl2","url":"/matplotlib#in-this-section","position":6},{"hierarchy":{"lvl1":"Matplotlib","lvl2":"In this section"},"content":"In this section of Pythia Foundations, you will find tutorials on basic plotting with \n\nMatplotlib.\n\nFrom the \n\nMatplotlib documentation, “Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.”\n\nCurrently, Pythia Foundations provides a basic introduction to Matplotlib, as well as:\n\nHistograms\n\nPiecharts\n\nAnimations\n\nAnnotations\n\nColorbars\n\nContour plots\n\nCustomizing layouts","type":"content","url":"/matplotlib#in-this-section","position":7},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts"},"type":"lvl1","url":"/annotations-colorbars-layouts","position":0},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts"},"content":"\n\n","type":"content","url":"/annotations-colorbars-layouts","position":1},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts"},"type":"lvl1","url":"/annotations-colorbars-layouts#annotations-colorbars-and-advanced-layouts","position":2},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts"},"content":"","type":"content","url":"/annotations-colorbars-layouts#annotations-colorbars-and-advanced-layouts","position":3},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Overview"},"type":"lvl2","url":"/annotations-colorbars-layouts#overview","position":4},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Overview"},"content":"In this section we explore methods for customizing plots.  The following topics will be covered:\n\nAdding annotations\n\nRendering equations\n\nColormap overview\n\nBasic colorbars\n\nShared colorbars\n\nCustom colorbars\n\nMosaic subplots\n\n","type":"content","url":"/annotations-colorbars-layouts#overview","position":5},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Prerequisites"},"type":"lvl2","url":"/annotations-colorbars-layouts#prerequisites","position":6},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNumPy Basics\n\nNecessary\n\nMatplotlib Basics\n\nNecessary\n\nTime to learn: 30-40 minutes\n\n","type":"content","url":"/annotations-colorbars-layouts#prerequisites","position":7},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Imports"},"type":"lvl2","url":"/annotations-colorbars-layouts#imports","position":8},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Imports"},"content":"Here, we import the matplotlib.pyplot interface and numpy, in addition to the scipy statistics package (scipy.stats) for generating sample data.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats as stats\nfrom matplotlib.colors import LinearSegmentedColormap, ListedColormap, Normalize\n\n","type":"content","url":"/annotations-colorbars-layouts#imports","position":9},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Create Some Sample Data"},"type":"lvl2","url":"/annotations-colorbars-layouts#create-some-sample-data","position":10},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Create Some Sample Data"},"content":"By using scipy.stats, the Scipy statistics package described above, we can easily create a data array containing a normal distribution.  We can plot these data points to confirm that the correct distribution was generated. The generated sample data will then be used later in this section. The code and sample plot for this data generation are as follows:\n\nmu = 0\nvariance = 1\nsigma = np.sqrt(variance)\n\nx = np.linspace(mu - 3 * sigma, mu + 3 * sigma, 200)\npdf = stats.norm.pdf(x, mu, sigma)\n\nplt.plot(x, pdf);\n\n","type":"content","url":"/annotations-colorbars-layouts#create-some-sample-data","position":11},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Adding Annotations"},"type":"lvl2","url":"/annotations-colorbars-layouts#adding-annotations","position":12},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Adding Annotations"},"content":"A common part of many people’s workflows is adding annotations.  A rough definition of ‘annotation’ is ‘a note of explanation or comment added to text or a diagram’.\n\nWe can add an annotation to a plot using plt.text.  This method takes the x and y data coordinates at which to draw the annotation (as floating-point values), and the string containing the annotation text.\n\nplt.plot(x, pdf)\nplt.text(0, 0.05, 'here is some text!');\n\n","type":"content","url":"/annotations-colorbars-layouts#adding-annotations","position":13},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Rendering Equations"},"type":"lvl2","url":"/annotations-colorbars-layouts#rendering-equations","position":14},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Rendering Equations"},"content":"\n\nWe can also add annotations with equation formatting, by using LaTeX syntax.  The key is to use strings in the following format:r'$some_equation$'\n\nLet’s run an example that renders the following equation as an annotation:f(x) = \\frac{1}{\\mu\\sqrt{2\\pi}}  e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\n\nThe next code block and plot demonstrate rendering this equation as an annotation.\n\nIf you are interested in learning more about LaTeX syntax, check out \n\ntheir official documentation.\n\nFurthermore, if the code is being executed in a Jupyter notebook run interactively (e.g., on Binder), you can double-click on the cell to see the LaTeX source for the rendered equation.\n\nplt.plot(x, pdf)\n\nplt.text(\n    -1,\n    0.05,\n    r'$f(x) = \\frac{1}{\\mu\\sqrt{2\\pi}}  e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}$',\n);\n\nAs you can see, the equation was correctly rendered in the plot above. However, the equation appears quite small.  We can increase the size of the text using the fontsize keyword argument, and center the equation using the ha (horizontal alignment) keyword argument.\n\nThe following example illustrates the use of these keyword arguments, as well as creating a legend containing LaTeX notation:\n\nfstr = r'$f(x) = \\frac{1}{\\mu\\sqrt{2\\pi}}  e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}$'\n\nplt.plot(x, pdf, label=r'$\\mu=0, \\,\\, \\sigma^2 = 1$')\nplt.text(0, 0.05, fstr, fontsize=15, ha='center')\nplt.legend();\n\n","type":"content","url":"/annotations-colorbars-layouts#rendering-equations","position":15},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl3":"Add a Box Around the Text","lvl2":"Rendering Equations"},"type":"lvl3","url":"/annotations-colorbars-layouts#add-a-box-around-the-text","position":16},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl3":"Add a Box Around the Text","lvl2":"Rendering Equations"},"content":"\n\nTo improve readability, we can also add a box around the equation text.  This is done using bbox.\n\nbbox is a keyword argument in plt.text that creates a box around text.  It takes a dictionary that specifies options, behaving like additional keyword arguments inside of the bbox argument.  In this case, we use the following dictionary keys:\n\na rounded box style (boxstyle = 'round')\n\na light grey facecolor (fc = 'lightgrey')\n\na black edgecolor (ec = 'k')\n\nThis example demonstrates the correct use of bbox:\n\nfig = plt.figure(figsize=(10, 8))\nplt.plot(x, pdf)\n\nfstr = r'$f(x) = \\frac{1}{\\mu\\sqrt{2\\pi}}  e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}$'\nplt.text(\n    0,\n    0.05,\n    fstr,\n    fontsize=18,\n    ha='center',\n    bbox=dict(boxstyle='round', fc='lightgrey', ec='k'),\n)\n\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\n\nplt.title(\"Normal Distribution with SciPy\", fontsize=24);\n\n\n\n","type":"content","url":"/annotations-colorbars-layouts#add-a-box-around-the-text","position":17},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Colormap Overview"},"type":"lvl2","url":"/annotations-colorbars-layouts#colormap-overview","position":18},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Colormap Overview"},"content":"Colormaps are a visually appealing method of looking at visualized data in a new and different way. They associate specific values with hues, using color to ease rapid understanding of plotted data; for example, displaying hotter temperatures as red and colder temperatures as blue.\n\n","type":"content","url":"/annotations-colorbars-layouts#colormap-overview","position":19},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl3":"Classes of colormaps","lvl2":"Colormap Overview"},"type":"lvl3","url":"/annotations-colorbars-layouts#classes-of-colormaps","position":20},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl3":"Classes of colormaps","lvl2":"Colormap Overview"},"content":"There are four different classes of colormaps, and many individual maps are contained in each class.  To view some examples for each class, use the dropdown arrow next to the class name below.\n\n1. Sequential: These colormaps incrementally increase or decrease in lightness and/or saturation of color. In general, they work best for ordered data.     \n\n2. Diverging: These colormaps contain two colors that change in lightness and/or saturation in proportion to distance from the middle, and an unsaturated color in the middle. They are almost always used with data containing a natural zero point, such as sea level. \n\n3. Cyclic: These colormaps have two different colors that change in lightness and meet in the middle, and unsaturated colors at the beginning and end. They are usually best for data values that wrap around, such as longitude. \n\n4. Qualitative: These colormaps have no pattern, and are mostly bands of miscellaneous colors. You should only use these colormaps for unordered data without relationships.  \n\n","type":"content","url":"/annotations-colorbars-layouts#classes-of-colormaps","position":21},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl3":"Other considerations","lvl2":"Colormap Overview"},"type":"lvl3","url":"/annotations-colorbars-layouts#other-considerations","position":22},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl3":"Other considerations","lvl2":"Colormap Overview"},"content":"There is a lot of info about choosing colormaps that could be its own tutorial. Two important considerations:\n\nColor-blind friendly patterns: By using colormaps that do not contain both red and green, you can help people with the most common form of color blindness read your data plots more easily.  The GeoCAT examples gallery has a section about \n\npicking better colormaps that covers this issue in greater detail.\n\nGrayscale conversion: It is not too uncommon for a plot originally rendered in color to be converted to black-and-white (monochrome grayscale).  This reduces the usefulness of specific colormaps, as shown below.\n\nFor more information on these concerns, as well as colormap choices in general, see the documentation page \n\nChoosing Colormaps in Matplotlib.\n\n","type":"content","url":"/annotations-colorbars-layouts#other-considerations","position":23},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Basic Colorbars"},"type":"lvl2","url":"/annotations-colorbars-layouts#basic-colorbars","position":24},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Basic Colorbars"},"content":"\n\nBefore we look at a colorbar, let’s generate some fake X and Y data using numpy.random, and set a number of bins for a histogram:\n\nnpts = 1000\nnbins = 15\n\nx = np.random.normal(size=npts)\ny = np.random.normal(size=npts)\n\nNow we can use our fake data to plot a 2-D histogram with the number of bins set above.  We then add a colorbar to the plot, using the default colormap viridis.\n\nfig = plt.figure()\nax = plt.gca()\n\nplt.hist2d(x, y, bins=nbins, density=True)\nplt.colorbar();\n\nWe can change which colormap to use by setting the keyword argument cmap = 'colormap_name' in the plotting function call.  This sets the colormap not only for the plot, but for the colorbar as well.  In this case, we use the magma colormap:\n\nfig = plt.figure()\nax = plt.gca()\n\nplt.hist2d(x, y, bins=nbins, density=True, cmap='magma')\nplt.colorbar();\n\n","type":"content","url":"/annotations-colorbars-layouts#basic-colorbars","position":25},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Shared Colorbars"},"type":"lvl2","url":"/annotations-colorbars-layouts#shared-colorbars","position":26},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Shared Colorbars"},"content":"Oftentimes, you are plotting multiple subplots, or multiple Axes objects, simultaneously. In these scenarios, you can create colorbars that span multiple plots, as shown in the following example:\n\nfig, ax = plt.subplots(nrows=1, ncols=2, constrained_layout=True)\n\nhist1 = ax[0].hist2d(x, y, bins=15, density=True, vmax=0.18)\nhist2 = ax[1].hist2d(x, y, bins=30, density=True, vmax=0.18)\n\nfig.colorbar(hist1[3], ax=ax, location='bottom')\n\nYou may be wondering why the call to fig.colorbar uses the argument hist1[3]. The explanation is as follows: hist1 is a tuple returned by hist2d, and hist1[3] contains a matplotlib.collections.QuadMesh that points to the colormap for the first histogram. To make sure that both histograms are using the same colormap with the same range of values, vmax is set to 0.18 for both plots. This ensures that both histograms are using colormaps that represent values from 0 (the default for histograms) to 0.18. Because the same data values are used for both plots, it doesn’t matter whether we pass in hist1[3] or hist2[3] to fig.colorbar.\nYou can learn more about this topic by reviewing the \n\nmatplotlib.axes.Axes.hist2d documentation.\n\nIn addition, there are many other types of plots that can also share colorbars. An actual use case that is quite common is to use shared colorbars to compare data between filled contour plots. The vmin and vmax keyword arguments behave the same way for contourf as they do for hist2d. However, there is a potential downside to using the vmin and vmax kwargs. When plotting two different datasets, the dataset with the smaller range of values won’t show the full range of colors, even though the colormaps are the same. Thus, it can potentially matter which output from contourf is used to make a colorbar.  The following examples demonstrate general plotting technique for filled contour plots with shared colorbars, as well as best practices for dealing with some of these logistical issues:\n\nx2 = y2 = np.arange(-3, 3.01, 0.025)\nX2, Y2 = np.meshgrid(x2, y2)\nZ = np.sqrt(np.sin(X2) ** 2 + np.sin(Y2) ** 2)\nZ2 = np.sqrt(2 * np.cos(X2) ** 2 + 2 * np.cos(Y2) ** 2)\n\nfig, ax = plt.subplots(nrows=1, ncols=2, constrained_layout=True)\nc1 = ax[0].contourf(X2, Y2, Z, vmin=0, vmax=2)\nc2 = ax[1].contourf(X2, Y2, Z2, vmin=0, vmax=2)\nfig.colorbar(c1, ax=ax[0], location='bottom')\nfig.colorbar(c2, ax=ax[1], location='bottom')\n\nfig.suptitle('Shared colormaps on data with different ranges')\n\nfig, ax = plt.subplots(nrows=1, ncols=2, constrained_layout=True)\nc1 = ax[0].contourf(X2, Y2, Z, vmin=0, vmax=2)\nc2 = ax[1].contourf(X2, Y2, Z2, vmin=0, vmax=2)\nfig.colorbar(c2, ax=ax, location='bottom')\n\nfig.suptitle('Using the contourf output from the data with a wider range')\n\n","type":"content","url":"/annotations-colorbars-layouts#shared-colorbars","position":27},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Custom Colorbars"},"type":"lvl2","url":"/annotations-colorbars-layouts#custom-colorbars","position":28},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Custom Colorbars"},"content":"Despite the availability of a large number of premade colorbar styles, it can still occasionally be helpful to create your own colorbars.\n\nBelow are 2 similar examples of using custom colorbars.\n\nThe first example uses a very discrete list of colors, simply named colors, and creates a colormap from this list by using the call ListedColormap.\n\nThe second example uses the function LinearSegmentedColormap to create a new colormap, using interpolation and the colors list defined in the first example.\n\ncolors = [\n    'white',\n    'pink',\n    'red',\n    'orange',\n    'yellow',\n    'green',\n    'blue',\n    'purple',\n    'black',\n]\nccmap = ListedColormap(colors)\nnorm = Normalize(vmin=0, vmax=0.18)\n\nfig, ax = plt.subplots(nrows=1, ncols=2, constrained_layout=True)\n\nhist1 = ax[0].hist2d(x, y, bins=15, density=True, cmap=ccmap, norm=norm)\nhist2 = ax[1].hist2d(x, y, bins=30, density=True, cmap=ccmap, norm=norm)\n\ncbar = fig.colorbar(hist1[3], ax=ax, location='bottom')\n\ncbcmap = LinearSegmentedColormap.from_list(\"cbcmap\", colors)\n\nfig, ax = plt.subplots(nrows=1, ncols=2, constrained_layout=True)\n\nhist1 = ax[0].hist2d(x, y, bins=15, density=True, cmap=cbcmap, norm=norm)\nhist2 = ax[1].hist2d(x, y, bins=30, density=True, cmap=cbcmap, norm=norm)\n\ncbar = fig.colorbar(hist1[3], ax=ax, location='bottom')\n\n","type":"content","url":"/annotations-colorbars-layouts#custom-colorbars","position":29},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl3":"The Normalize Class","lvl2":"Custom Colorbars"},"type":"lvl3","url":"/annotations-colorbars-layouts#the-normalize-class","position":30},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl3":"The Normalize Class","lvl2":"Custom Colorbars"},"content":"Notice that both of these examples contain plotting functions that make use of the norm kwarg.  This keyword argument takes an object of the Normalize class.  A Normalize object is constructed with two numeric values, representing the start and end of the data.  It then linearly normalizes the data in that range into an interval of [0,1]. If this sounds familiar, it is because this functionality was used in a previous histogram example.  Feel free to review any previous examples if you need a refresher on particular topics. In this example, the values of the vmin and vmax kwargs used in hist2d are reused as arguments to the Normalize class constructor.  This sets the values of vmin and vmax as the starting and ending data values for our Normalize object, which is passed to the norm kwarg of hist2d to normalize the data. There are many different options for normalizing data, and it is important to explicitly specify how you want your data normalized, especially when making a custom colormap.\n\nFor information on nonlinear and other complex forms of normalization, review this \n\nColormap Normalization tutorial.\n\n","type":"content","url":"/annotations-colorbars-layouts#the-normalize-class","position":31},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Mosaic Subplots"},"type":"lvl2","url":"/annotations-colorbars-layouts#mosaic-subplots","position":32},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Mosaic Subplots"},"content":"One of the helpful features recently added to Matplotlib is the subplot_mosaic method.  This method allows you to specify the structure of your figure using specially formatted strings, and will generate subplots automatically based on that structure.\n\nFor example, if we wanted two plots on top, and one on the bottom, we can construct them by passing the following string to subplot_mosaic:\"\"\nAB\nCC\n\"\"\n\nThis creates three Axes objects corresponding to three subplots.  The subplots A and B are on top of the subplot C, and the C subplot spans the combined width of A and B.\n\nOnce we create the subplots, we can access them using the dictionary returned by subplot_mosaic.  You can specify an Axes object (in this example, your_axis) in the dictionary (in this example, axes_dict) by using the syntax axes_dict['your_axis']. A full example of subplot_mosaic is as follows:\n\naxdict = plt.figure(constrained_layout=True).subplot_mosaic(\n    \"\"\"\n    AB\n    CC\n    \"\"\"\n)\n\nhistA = axdict['A'].hist2d(x, y, bins=15, density=True, cmap=cbcmap, norm=norm)\nhistB = axdict['B'].hist2d(x, y, bins=10, density=True, cmap=cbcmap, norm=norm)\nhistC = axdict['C'].hist2d(x, y, bins=30, density=True, cmap=cbcmap, norm=norm)\n\nYou’ll notice there is not a colorbar plotted by default. When constructing the colorbar, we need to specify the following:\n\nWhich plot to use for the colormapping (ex. histA)\n\nWhich subplots (Axes objects) to merge colorbars across (ex. [histA, histB])\n\nWhere to place the colorbar (ex. bottom)\n\naxdict = plt.figure(constrained_layout=True).subplot_mosaic(\n    \"\"\"\n    AB\n    CC\n    \"\"\"\n)\n\nhistA = axdict['A'].hist2d(x, y, bins=15, density=True, cmap=cbcmap, norm=norm)\nhistB = axdict['B'].hist2d(x, y, bins=10, density=True, cmap=cbcmap, norm=norm)\nhistC = axdict['C'].hist2d(x, y, bins=30, density=True, cmap=cbcmap, norm=norm)\n\nfig.colorbar(histA[3], ax=[axdict['A'], axdict['B']], location='bottom')\nfig.colorbar(histC[3], ax=[axdict['C']], location='right');\n\n\n\n","type":"content","url":"/annotations-colorbars-layouts#mosaic-subplots","position":33},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Summary"},"type":"lvl2","url":"/annotations-colorbars-layouts#summary","position":34},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Summary"},"content":"You can use features in Matplotlib to add text annotations to your plots, including equations in mathematical notation\n\nThere are a number of considerations to take into account when choosing your colormap\n\nYou can create your own colormaps with Matplotlib\n\nVarious subplots and corresponding Axes objects in a figure can share colorbars","type":"content","url":"/annotations-colorbars-layouts#summary","position":35},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Resources and references"},"type":"lvl2","url":"/annotations-colorbars-layouts#resources-and-references","position":36},{"hierarchy":{"lvl1":"Annotations, Colorbars, and Advanced Layouts","lvl2":"Resources and references"},"content":"Matplotlib text documentation\n\nMatplotlib annotation documentation\n\nMatplotlib’s annotation examples\n\nWriting mathematical expressions in Matplotlib\n\nMathtext Examples\n\nDrawing fancy boxes with Matplotlib\n\nPlot Types Cheat Sheet\n\nChoosing Colormaps in Matplotlib\n\nMaking custom colormaps\n\nComplex figure and subplot composition","type":"content","url":"/annotations-colorbars-layouts#resources-and-references","position":37},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations"},"type":"lvl1","url":"/histograms-piecharts-animation","position":0},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations"},"content":"\n\n","type":"content","url":"/histograms-piecharts-animation","position":1},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations"},"type":"lvl1","url":"/histograms-piecharts-animation#histograms-pie-charts-and-animations","position":2},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations"},"content":"\n\n","type":"content","url":"/histograms-piecharts-animation#histograms-pie-charts-and-animations","position":3},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Overview"},"type":"lvl2","url":"/histograms-piecharts-animation#overview","position":4},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Overview"},"content":"In this section we’ll explore some more specialized plot types, including:\n\nHistograms\n\nPie Charts\n\nAnimations\n\n","type":"content","url":"/histograms-piecharts-animation#overview","position":5},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Prerequisites"},"type":"lvl2","url":"/histograms-piecharts-animation#prerequisites","position":6},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nNumPy Basics\n\nNecessary\n\n\n\nMatplotlib Basics\n\nNecessary\n\n\n\nTime to Learn: 30 minutes\n\n\n\n","type":"content","url":"/histograms-piecharts-animation#prerequisites","position":7},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Imports"},"type":"lvl2","url":"/histograms-piecharts-animation#imports","position":8},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Imports"},"content":"\n\nJust like in the previous tutorial, we are going to import Matplotlib’s pyplot interface as plt. We must also import numpy for working with data arrays.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n","type":"content","url":"/histograms-piecharts-animation#imports","position":9},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Histograms"},"type":"lvl2","url":"/histograms-piecharts-animation#histograms","position":10},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Histograms"},"content":"\n\nWe can plot a 1-D histogram using most 1-D data arrays.\n\nTo get the 1-D data array for this example, we generate example data using NumPy’s normal-distribution random-number generator. For demonstration purposes, we’ve specified the random seed for reproducibility. The code for this number generation is as follows:\n\nnpts = 2500\nnbins = 15\n\nnp.random.seed(0)\nx = np.random.normal(size=npts)\n\nNow that we have our data array, we can make a histogram using plt.hist.  In this case, we change the y-axis to represent probability, instead of count; this is performed by setting density=True.\n\nplt.hist(x, bins=nbins, density=True)\nplt.title('1D histogram')\nplt.xlabel('Data')\nplt.ylabel('Probability');\n\nSimilarly, we can make a 2-D histogram, by first generating a second 1-D array, and then calling plt.hist2d with both 1-D arrays as arguments:\n\ny = np.random.normal(size=npts)\n\nplt.hist2d(x, y, bins=nbins);\n\n","type":"content","url":"/histograms-piecharts-animation#histograms","position":11},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Pie Charts"},"type":"lvl2","url":"/histograms-piecharts-animation#pie-charts","position":12},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Pie Charts"},"content":"\n\nMatplotlib also has the capability to plot pie charts, by way of plt.pie. The most basic implementation uses a 1-D array of wedge ‘sizes’ (i.e., percent values), as shown below:\n\nx = np.array([25, 15, 20, 40])\nplt.pie(x);\n\nTypically, you’ll see examples where all of the values in the array x will sum to 100, but the data values provided to plt.pie do not necessarily have to add up to 100.  The sum of the numbers provided will be normalized to 1, and the individual values will thereby be converted to percentages, regardless of the actual sum of the values.  If this behavior is unwanted or unneeded, you can set normalize=False.\n\nIf you set normalize=False, and the sum of the values of x is less than 1, then a partial pie chart is plotted. If the values sum to larger than 1, a ValueError will be raised.\n\nx = np.array([0.25, 0.20, 0.40])\nplt.pie(x, normalize=False);\n\nLet’s do a more complicated example.\n\nHere we create a pie chart with various sizes associated with each color. Labels are derived by capitalizing each color in the array colors. Since colors can be specified by strings corresponding to named colors, this allows both the colors and the labels to be set from the same array, reducing code and effort.\n\nIf you want to offset one or more wedges for effect, you can use the explode keyword argument.  The value for this argument must be a list of floating-point numbers with the same length as the number of wedges.  The numbers indicate the percentage of offset for each wedge. In this example, each wedge is not offset except for the pink (3rd index).\n\ncolors = ['red', 'blue', 'yellow', 'pink', 'green']\nlabels = [c.capitalize() for c in colors]\n\nsizes = [1, 3, 5, 7, 9]\nexplode = (0, 0, 0, 0.1, 0)\n\n\nplt.pie(sizes, labels=labels, explode=explode, colors=colors, autopct='%1.1f%%');\n\n","type":"content","url":"/histograms-piecharts-animation#pie-charts","position":13},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Animations"},"type":"lvl2","url":"/histograms-piecharts-animation#animations","position":14},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Animations"},"content":"\n\nMatplotlib offers a single commonly-used animation tool, FuncAnimation. This tool must be imported separately through Matplotlib’s animation package, as shown below. You can find more information on animation with Matplotlib at the \n\nofficial documentation page.\n\nfrom matplotlib.animation import FuncAnimation\n\nFuncAnimation creates animations by repeatedly calling a function. Using this method involves three main steps:\n\nCreate an initial state of the plot\n\nMake a function that can “progress” the plot to the next frame of the animation\n\nCreate the animation using FuncAnimation\n\nFor this example, let’s create an animated sine wave.\n\n","type":"content","url":"/histograms-piecharts-animation#animations","position":15},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl3":"Step 1: Initial State","lvl2":"Animations"},"type":"lvl3","url":"/histograms-piecharts-animation#step-1-initial-state","position":16},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl3":"Step 1: Initial State","lvl2":"Animations"},"content":"In the initial state step, we will define a function called init.  This function will then create the animation plot in its initial state.  However, please note that the successful use of FuncAnimation does not technically require such a function; in a later example, creating animations without an initial-state function is demonstrated.\n\nFirst, we’ll define Figure and Axes objects.  After that, we can create a line-plot object (referred to here as a line) with plt.plot. To create the initialization function, we set the line’s data to be empty and then return the line.\n\nPlease note, this code block will display a blank plot when run as a Jupyter notebook cell.\n\nfig, ax = plt.subplots()\nax.set_xlim(0, 2 * np.pi)\nax.set_ylim(-1.5, 1.5)\n\n(line,) = ax.plot([], [])\n\n\ndef init():\n    line.set_data([], [])\n    return (line,)\n\n","type":"content","url":"/histograms-piecharts-animation#step-1-initial-state","position":17},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl3":"Step 2: Animation Progression Function","lvl2":"Animations"},"type":"lvl3","url":"/histograms-piecharts-animation#step-2-animation-progression-function","position":18},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl3":"Step 2: Animation Progression Function","lvl2":"Animations"},"content":"For this step, we create a progression function, which takes an index (usually named n or i), and returns the corresponding (in other words, n-th or i-th) frame of the animation.\n\ndef animate(i):\n    x = np.linspace(0, 2 * np.pi, 250)\n\n    y = np.sin(2 * np.pi * (x - 0.1 * i))\n\n    line.set_data(x, y)\n\n    return (line,)\n\n","type":"content","url":"/histograms-piecharts-animation#step-2-animation-progression-function","position":19},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl3":"Step 3: Using FuncAnimation","lvl2":"Animations"},"type":"lvl3","url":"/histograms-piecharts-animation#step-3-using-funcanimation","position":20},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl3":"Step 3: Using FuncAnimation","lvl2":"Animations"},"content":"The last step is to feed the parts we created to FuncAnimation. Please note, when using the FuncAnimation function, it is important to save the output in a variable, even if you do not intend to use this output later.  If you do not, Python’s garbage collector may attempt to save memory by deleting the animation data, and it will be unavailable for later use.\n\nanim = FuncAnimation(fig, animate, init_func=init, frames=200, interval=20, blit=True)\n\nIn order to show the animation in a Jupyter notebook, we have to use the rc function. This function must be imported separately, and is used to set specific parameters in Matplotlib. In this case, we need to set the html parameter for animation plots to html5, instead of the default value of none.  The code for this is written as follows:\n\nfrom matplotlib import rc\n\nrc('animation', html='html5')\n\nanim\n\n","type":"content","url":"/histograms-piecharts-animation#step-3-using-funcanimation","position":21},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl3":"Saving an Animation","lvl2":"Animations"},"type":"lvl3","url":"/histograms-piecharts-animation#saving-an-animation","position":22},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl3":"Saving an Animation","lvl2":"Animations"},"content":"To save an animation to a file, use the save() method of the animation variable, in this case anim.save(), as shown below. The arguments are the file name to save the animation to, in this case animate.gif, and the writer used to save the file. Here, the animation writer chosen is \n\nPillow, a library for image processing in Python. There are many choices for an animation writer, which are described in detail in the Matplotlib writer documentation. The documentation for the Pillow writer is described on \n\nthis page; links to other writer documentation pages are on the left side of the Pillow writer documentation.\n\nanim.save('animate.gif', writer='pillow');\n\n\n\n","type":"content","url":"/histograms-piecharts-animation#saving-an-animation","position":23},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Summary"},"type":"lvl2","url":"/histograms-piecharts-animation#summary","position":24},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Summary"},"content":"Matplotlib supports many different plot types, including the less-commonly-used types described in this section.\n\nSome of these lesser-used plot types include histograms and pie charts.\n\nThis section also covered animation of Matplotlib plots.","type":"content","url":"/histograms-piecharts-animation#summary","position":25},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"What’s Next"},"type":"lvl2","url":"/histograms-piecharts-animation#whats-next","position":26},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"What’s Next"},"content":"The next section introduces \n\nmore plotting functionality, such as annotations, equation rendering, colormaps, and advanced layout.","type":"content","url":"/histograms-piecharts-animation#whats-next","position":27},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Additional Resources"},"type":"lvl2","url":"/histograms-piecharts-animation#additional-resources","position":28},{"hierarchy":{"lvl1":"Histograms, Pie Charts, and Animations","lvl2":"Additional Resources"},"content":"Plot Types Cheat Sheet\n\nMatplotlib Documentation: Basic Pie Charts\n\nMatplotlib Documentation: Histograms","type":"content","url":"/histograms-piecharts-animation#additional-resources","position":29},{"hierarchy":{"lvl1":"Matplotlib Basics"},"type":"lvl1","url":"/matplotlib-basics","position":0},{"hierarchy":{"lvl1":"Matplotlib Basics"},"content":"\n\n","type":"content","url":"/matplotlib-basics","position":1},{"hierarchy":{"lvl1":"Matplotlib Basics"},"type":"lvl1","url":"/matplotlib-basics#matplotlib-basics","position":2},{"hierarchy":{"lvl1":"Matplotlib Basics"},"content":"\n\n","type":"content","url":"/matplotlib-basics#matplotlib-basics","position":3},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Overview"},"type":"lvl2","url":"/matplotlib-basics#overview","position":4},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Overview"},"content":"We will cover the basics of using the Matplotlib library to create plots in Python, including a few different plots available within the library. This page is laid out as follows:\n\nWhy Matplotlib?\n\nFigure and axes\n\nBasic line plots\n\nLabels and grid lines\n\nCustomizing colors\n\nSubplots\n\nScatterplots\n\nDisplaying Images\n\nContour and filled contour plots.\n\n","type":"content","url":"/matplotlib-basics#overview","position":5},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Prerequisites"},"type":"lvl2","url":"/matplotlib-basics#prerequisites","position":6},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nNumPy Basics\n\nNecessary\n\n\n\nMATLAB plotting experience\n\nHelpful\n\n\n\nTime to Learn: 30 minutes\n\n\n\n","type":"content","url":"/matplotlib-basics#prerequisites","position":7},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Imports"},"type":"lvl2","url":"/matplotlib-basics#imports","position":8},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Imports"},"content":"\n\nLet’s import the Matplotlib library’s pyplot interface; this interface is the simplest way to create new Matplotlib figures. To shorten this long name, we import it as plt; this helps keep things short, but clear.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nInfoMatplotlib is a Python 2-D plotting library. It is used to produce publication quality figures in a variety of hard-copy formats and interactive environments across platforms.\n\n","type":"content","url":"/matplotlib-basics#imports","position":9},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Generate test data using NumPy"},"type":"lvl2","url":"/matplotlib-basics#generate-test-data-using-numpy","position":10},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Generate test data using NumPy"},"content":"\n\nHere, we generate some test data to use for experimenting with plotting:\n\ntimes = np.array(\n    [\n        93.0,\n        96.0,\n        99.0,\n        102.0,\n        105.0,\n        108.0,\n        111.0,\n        114.0,\n        117.0,\n        120.0,\n        123.0,\n        126.0,\n        129.0,\n        132.0,\n        135.0,\n        138.0,\n        141.0,\n        144.0,\n        147.0,\n        150.0,\n        153.0,\n        156.0,\n        159.0,\n        162.0,\n    ]\n)\ntemps = np.array(\n    [\n        310.7,\n        308.0,\n        296.4,\n        289.5,\n        288.5,\n        287.1,\n        301.1,\n        308.3,\n        311.5,\n        305.1,\n        295.6,\n        292.4,\n        290.4,\n        289.1,\n        299.4,\n        307.9,\n        316.6,\n        293.9,\n        291.2,\n        289.8,\n        287.1,\n        285.8,\n        303.3,\n        310.0,\n    ]\n)\n\n","type":"content","url":"/matplotlib-basics#generate-test-data-using-numpy","position":11},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Figure and Axes"},"type":"lvl2","url":"/matplotlib-basics#figure-and-axes","position":12},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Figure and Axes"},"content":"\n\nNow, let’s make our first plot with Matplotlib. Matplotlib has two core objects: the Figure and the Axes. The Axes object is an individual plot, containing an x-axis, a y-axis, labels, etc.; it also contains all of the various methods we might use for plotting. A Figure contains one or more Axes objects; it also contains methods for saving plots to files (e.g., PNG, SVG), among other similar high-level functionality.  You may find the following diagram helpful:\n\n","type":"content","url":"/matplotlib-basics#figure-and-axes","position":13},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Basic Line Plots"},"type":"lvl2","url":"/matplotlib-basics#basic-line-plots","position":14},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Basic Line Plots"},"content":"Let’s create a Figure whose dimensions, if printed out on hardcopy, would be 10 inches wide and 6 inches long (assuming a landscape orientation). We then create an Axes object, consisting of a single subplot, on the Figure. After that, we call the Axes object’s plot method, using the times array for the data along the x-axis (i.e., the independent values), and the temps array for the data along the y-axis (i.e., the dependent values).\n\nInfoBy default, ax.plot will create a line plot, as seen in the following example:\n\n# Create a figure\nfig = plt.figure(figsize=(10, 6))\n\n# Ask, out of a 1x1 grid of plots, the first axes.\nax = fig.add_subplot(1, 1, 1)\n\n# Plot times as x-variable and temperatures as y-variable\nax.plot(times, temps);\n\n","type":"content","url":"/matplotlib-basics#basic-line-plots","position":15},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Labels and Grid Lines"},"type":"lvl2","url":"/matplotlib-basics#labels-and-grid-lines","position":16},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Labels and Grid Lines"},"content":"\n\n","type":"content","url":"/matplotlib-basics#labels-and-grid-lines","position":17},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Adding labels to an Axes object","lvl2":"Labels and Grid Lines"},"type":"lvl3","url":"/matplotlib-basics#adding-labels-to-an-axes-object","position":18},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Adding labels to an Axes object","lvl2":"Labels and Grid Lines"},"content":"\n\nNext, we add x-axis and y-axis labels to our Axes object, like this:\n\n# Add some labels to the plot\nax.set_xlabel('Time')\nax.set_ylabel('Temperature')\n\n# Prompt the notebook to re-display the figure after we modify it\nfig\n\nWe can also add a title to the plot and increase the font size:\n\nax.set_title('GFS Temperature Forecast', size=16)\n\nfig\n\nThere are many other functions and methods associated with Axes objects and labels, but they are too numerous to list here.\n\nHere, we set up another test array of temperature data, to be used later:\n\ntemps_1000 = np.array(\n    [\n        316.0,\n        316.3,\n        308.9,\n        304.0,\n        302.0,\n        300.8,\n        306.2,\n        309.8,\n        313.5,\n        313.3,\n        308.3,\n        304.9,\n        301.0,\n        299.2,\n        302.6,\n        309.0,\n        311.8,\n        304.7,\n        304.6,\n        301.8,\n        300.6,\n        299.9,\n        306.3,\n        311.3,\n    ]\n)\n\n","type":"content","url":"/matplotlib-basics#adding-labels-to-an-axes-object","position":19},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Adding labels and a grid","lvl2":"Labels and Grid Lines"},"type":"lvl3","url":"/matplotlib-basics#adding-labels-and-a-grid","position":20},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Adding labels and a grid","lvl2":"Labels and Grid Lines"},"content":"\n\nHere, we call plot more than once, in order to plot multiple series of temperature data on the same plot.  We also specify the label keyword argument to the plot method to allow Matplotlib to automatically create legend labels. These legend labels are added via a call to the legend method. By utilizing the grid() method, we can also add gridlines to our plot.\n\nfig = plt.figure(figsize=(10, 6))\nax = fig.add_subplot(1, 1, 1)\n\n# Plot two series of data\n# The label argument is used when generating a legend.\nax.plot(times, temps, label='Temperature (surface)')\nax.plot(times, temps_1000, label='Temperature (1000 mb)')\n\n# Add labels and title\nax.set_xlabel('Time')\nax.set_ylabel('Temperature')\nax.set_title('Temperature Forecast')\n\n# Add gridlines\nax.grid(True)\n\n# Add a legend to the upper left corner of the plot\nax.legend(loc='upper left');\n\n","type":"content","url":"/matplotlib-basics#adding-labels-and-a-grid","position":21},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Customizing colors"},"type":"lvl2","url":"/matplotlib-basics#customizing-colors","position":22},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Customizing colors"},"content":"\n\nWe’re not restricted to the default look for plot elements.  Most plot elements have style attributes, such as linestyle and color, that can be modified to customize the look of a plot. For example, the color attribute can accept a wide array of color options, including keywords (named colors) like red or blue, or HTML color codes. Here, we use some different shades of red taken from the Tableau colorset in Matplotlib, by using the tab:red option for the color attribute.\n\nfig = plt.figure(figsize=(10, 6))\nax = fig.add_subplot(1, 1, 1)\n\n# Specify how our lines should look\nax.plot(times, temps, color='tab:red', label='Temperature (surface)')\nax.plot(\n    times,\n    temps_1000,\n    color='tab:red',\n    linestyle='--',\n    label='Temperature (isobaric level)',\n)\n\n# Set the labels and title\nax.set_xlabel('Time')\nax.set_ylabel('Temperature')\nax.set_title('Temperature Forecast')\n\n# Add the grid\nax.grid(True)\n\n# Add a legend to the upper left corner of the plot\nax.legend(loc='upper left');\n\n","type":"content","url":"/matplotlib-basics#customizing-colors","position":23},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Subplots"},"type":"lvl2","url":"/matplotlib-basics#subplots","position":24},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Subplots"},"content":"The term “subplots” refers to working with multiple plots, or panels, in a figure.\n\nHere, we create yet another set of test data, in this case dew-point data, to be used in later examples:\n\ndewpoint = 0.9 * temps\ndewpoint_1000 = 0.9 * temps_1000\n\nNow, we can use subplots to plot this new data alongside the temperature data.\n\n","type":"content","url":"/matplotlib-basics#subplots","position":25},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Using add_subplot to create two different subplots within the figure","lvl2":"Subplots"},"type":"lvl3","url":"/matplotlib-basics#using-add-subplot-to-create-two-different-subplots-within-the-figure","position":26},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Using add_subplot to create two different subplots within the figure","lvl2":"Subplots"},"content":"We can use the .add_subplot() method to add subplots to our figure! This method takes the arguments (rows, columns, subplot_number).\n\nFor example, if we want a single row and two columns, we can use the following code block:\n\nfig = plt.figure(figsize=(10, 6))\n\n# Create a plot for temperature\nax = fig.add_subplot(1, 2, 1)\nax.plot(times, temps, color='tab:red')\n\n# Create a plot for dewpoint\nax2 = fig.add_subplot(1, 2, 2)\nax2.plot(times, dewpoint, color='tab:green');\n\nYou can also call plot.subplots() with the keyword arguments nrows (number of rows) and ncols (number of columns).  This initializes a new Axes object, called ax, with the specified number of rows and columns.  This object also contains a 1-D list of subplots, with a size equal to nrows x ncols.\n\nYou can index this list, using ax[0].plot(), for example, to decide which subplot you’re plotting to. Here is some example code for this technique:\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 6))\n\nax[0].plot(times, temps, color='tab:red')\nax[1].plot(times, dewpoint, color='tab:green');\n\n","type":"content","url":"/matplotlib-basics#using-add-subplot-to-create-two-different-subplots-within-the-figure","position":27},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Adding titles to each subplot","lvl2":"Subplots"},"type":"lvl3","url":"/matplotlib-basics#adding-titles-to-each-subplot","position":28},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Adding titles to each subplot","lvl2":"Subplots"},"content":"We can add titles to these plots too; notice that these subplots are titled separately, by calling ax.set_title after plotting each subplot:\n\nfig = plt.figure(figsize=(10, 6))\n\n# Create a plot for temperature\nax = fig.add_subplot(1, 2, 1)\nax.plot(times, temps, color='tab:red')\nax.set_title('Temperature')\n\n# Create a plot for dewpoint\nax2 = fig.add_subplot(1, 2, 2)\nax2.plot(times, dewpoint, color='tab:green')\nax2.set_title('Dewpoint');\n\n","type":"content","url":"/matplotlib-basics#adding-titles-to-each-subplot","position":29},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Using ax.set_xlim and ax.set_ylim to control the plot boundaries","lvl2":"Subplots"},"type":"lvl3","url":"/matplotlib-basics#using-ax-set-xlim-and-ax-set-ylim-to-control-the-plot-boundaries","position":30},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Using ax.set_xlim and ax.set_ylim to control the plot boundaries","lvl2":"Subplots"},"content":"It is common when plotting data to set the extent (boundaries) of plots, which can be performed by calling .set_xlim and .set_ylim on the Axes object containing the plot or subplot(s):\n\nfig = plt.figure(figsize=(10, 6))\n\n# Create a plot for temperature\nax = fig.add_subplot(1, 2, 1)\nax.plot(times, temps, color='tab:red')\nax.set_title('Temperature')\nax.set_xlim(110, 130)\nax.set_ylim(290, 315)\n\n# Create a plot for dewpoint\nax2 = fig.add_subplot(1, 2, 2)\nax2.plot(times, dewpoint, color='tab:green')\nax2.set_title('Dewpoint')\nax2.set_xlim(110, 130);\n\n","type":"content","url":"/matplotlib-basics#using-ax-set-xlim-and-ax-set-ylim-to-control-the-plot-boundaries","position":31},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Using sharex and sharey to share plot limits","lvl2":"Subplots"},"type":"lvl3","url":"/matplotlib-basics#using-sharex-and-sharey-to-share-plot-limits","position":32},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Using sharex and sharey to share plot limits","lvl2":"Subplots"},"content":"You may want to have both subplots share the same x/y axis limits.  When setting up a new Axes object through a method like add_subplot, specify the keyword arguments sharex=ax and sharey=ax, where ax is the Axes object with which to share axis limits.\n\nLet’s take a look at an example:\n\nfig = plt.figure(figsize=(10, 6))\n\n# Create a plot for temperature\nax = fig.add_subplot(1, 2, 1)\nax.plot(times, temps, color='tab:red')\nax.set_title('Temperature')\nax.set_ylim(260, 320)\n\n# Create a plot for dewpoint\nax2 = fig.add_subplot(1, 2, 2, sharex=ax, sharey=ax)\nax2.plot(times, dewpoint, color='tab:green')\nax2.set_title('Dewpoint');\n\n","type":"content","url":"/matplotlib-basics#using-sharex-and-sharey-to-share-plot-limits","position":33},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Putting this all together","lvl2":"Subplots"},"type":"lvl3","url":"/matplotlib-basics#putting-this-all-together","position":34},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl3":"Putting this all together","lvl2":"Subplots"},"content":"\n\nInfoIf desired, you can move the location of your legend; to do this, specify the loc keyword argument when calling ax.legend().\n\nfig = plt.figure(figsize=(10, 6))\nax = fig.add_subplot(1, 2, 1)\n\n# Specify how our lines should look\nax.plot(times, temps, color='tab:red', label='Temperature (surface)')\nax.plot(\n    times,\n    temps_1000,\n    color='tab:red',\n    linestyle=':',\n    label='Temperature (isobaric level)',\n)\n\n# Add labels, grid, and legend\nax.set_xlabel('Time')\nax.set_ylabel('Temperature')\nax.set_title('Temperature Forecast')\nax.grid(True)\nax.legend(loc='upper left')\nax.set_ylim(257, 312)\nax.set_xlim(95, 162)\n\n\n# Add our second plot - for dewpoint, changing the colors and labels\nax2 = fig.add_subplot(1, 2, 2, sharex=ax, sharey=ax)\nax2.plot(times, dewpoint, color='tab:green', label='Dewpoint (surface)')\nax2.plot(\n    times,\n    dewpoint_1000,\n    color='tab:green',\n    linestyle=':',\n    marker='o',\n    label='Dewpoint (isobaric level)',\n)\n\nax2.set_xlabel('Time')\nax2.set_ylabel('Dewpoint')\nax2.set_title('Dewpoint Forecast')\nax2.grid(True)\nax2.legend(loc='upper left');\n\n","type":"content","url":"/matplotlib-basics#putting-this-all-together","position":35},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Scatterplot"},"type":"lvl2","url":"/matplotlib-basics#scatterplot","position":36},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Scatterplot"},"content":"Some data cannot be plotted accurately as a line plot.  Another type of plot that is popular in science is the marker plot, more commonly known as a scatter plot. A simple scatter plot can be created by setting the linestyle to None, and specifying a marker type, size, color, etc., like this:\n\nfig = plt.figure(figsize=(10, 6))\nax = fig.add_subplot(1, 1, 1)\n\n# Specify no line with circle markers\nax.plot(temps, temps_1000, linestyle='None', marker='o', markersize=5)\n\nax.set_xlabel('Temperature (surface)')\nax.set_ylabel('Temperature (1000 hPa)')\nax.set_title('Temperature Cross Plot')\nax.grid(True);\n\nInfoYou can also use the scatter method, which is slower, but will give you more control, such as being able to color the points individually based upon a third variable.\n\nfig = plt.figure(figsize=(10, 6))\nax = fig.add_subplot(1, 1, 1)\n\n# Specify no line with circle markers\nax.scatter(temps, temps_1000)\n\nax.set_xlabel('Temperature (surface)')\nax.set_ylabel('Temperature (1000 hPa)')\nax.set_title('Temperature Cross Plot')\nax.grid(True);\n\nLet’s put together the following:\n\nBeginning with our code above, add the c keyword argument to the scatter call; in this case, to color the points by the difference between the temperature at the surface and the temperature at 1000 hPa.\n\nAdd a 1:1 line to the plot (slope of 1, intercept of zero). Use a black dashed line.\n\nChange the colormap to one more suited for a temperature-difference plot.\n\nAdd a colorbar to the plot (have a look at the Matplotlib documentation for help).\n\nfig = plt.figure(figsize=(10, 6))\nax = fig.add_subplot(1, 1, 1)\n\nax.plot([285, 320], [285, 320], color='black', linestyle='--')\ns = ax.scatter(temps, temps_1000, c=(temps - temps_1000), cmap='bwr', vmin=-5, vmax=5)\nfig.colorbar(s)\n\nax.set_xlabel('Temperature (surface)')\nax.set_ylabel('Temperature (1000 hPa)')\nax.set_title('Temperature Cross Plot')\nax.grid(True);\n\n","type":"content","url":"/matplotlib-basics#scatterplot","position":37},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Displaying Images"},"type":"lvl2","url":"/matplotlib-basics#displaying-images","position":38},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Displaying Images"},"content":"imshow displays the values in an array as colored pixels, similar to a heat map.\n\nHere, we declare some fake data in a bivariate normal distribution, to illustrate the imshow method:\n\nx = y = np.arange(-3.0, 3.0, 0.025)\nX, Y = np.meshgrid(x, y)\nZ1 = np.exp(-(X**2) - Y**2)\nZ2 = np.exp(-((X - 1) ** 2) - (Y - 1) ** 2)\nZ = (Z1 - Z2) * 2\n\nWe can now pass this fake data to imshow to create a heat map of the distribution:\n\nfig, ax = plt.subplots()\nim = ax.imshow(\n    Z, interpolation='bilinear', cmap='RdYlGn', origin='lower', extent=[-3, 3, -3, 3]\n)\n\n","type":"content","url":"/matplotlib-basics#displaying-images","position":39},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Contour and Filled Contour Plots"},"type":"lvl2","url":"/matplotlib-basics#contour-and-filled-contour-plots","position":40},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Contour and Filled Contour Plots"},"content":"contour creates contours around data.\n\ncontourf creates filled contours around data.\n\nLet’s start with the contour method, which, as just mentioned, creates contours around data:\n\nfig, ax = plt.subplots()\nax.contour(X, Y, Z);\n\nAfter creating contours, we can label the lines using the clabel method, like this:\n\nfig, ax = plt.subplots()\nc = ax.contour(X, Y, Z, levels=np.arange(-2, 2, 0.25))\nax.clabel(c);\n\nAs described above, the contourf (contour fill) method creates filled contours around data, like this:\n\nfig, ax = plt.subplots()\nc = ax.contourf(X, Y, Z);\n\nAs a final example, let’s create a heatmap figure with contours using the contour and imshow methods.  First, we use imshow to create the heatmap, specifying a colormap using the cmap keyword argument.  We then call contour, specifying black contours and an interval of 0.5.  Here is the example code, and resulting figure:\n\nfig, ax = plt.subplots()\nim = ax.imshow(\n    Z, interpolation='bilinear', cmap='PiYG', origin='lower', extent=[-3, 3, -3, 3]\n)\nc = ax.contour(X, Y, Z, levels=np.arange(-2, 2, 0.5), colors='black')\nax.clabel(c);\n\n\n\n","type":"content","url":"/matplotlib-basics#contour-and-filled-contour-plots","position":41},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Summary"},"type":"lvl2","url":"/matplotlib-basics#summary","position":42},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Summary"},"content":"Matplotlib can be used to visualize datasets you are working with.\n\nYou can customize various features such as labels and styles.\n\nThere are a wide variety of plotting options available, including (but not limited to):\n\nLine plots (plot)\n\nScatter plots (scatter)\n\nHeatmaps (imshow)\n\nContour line and contour fill plots (contour, contourf)\n\n","type":"content","url":"/matplotlib-basics#summary","position":43},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"What’s Next?"},"type":"lvl2","url":"/matplotlib-basics#whats-next","position":44},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"What’s Next?"},"content":"In the next section, \n\nmore plotting functionality is covered, such as histograms, pie charts, and animation.\n\n","type":"content","url":"/matplotlib-basics#whats-next","position":45},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Resources and References"},"type":"lvl2","url":"/matplotlib-basics#resources-and-references","position":46},{"hierarchy":{"lvl1":"Matplotlib Basics","lvl2":"Resources and References"},"content":"The goal of this tutorial is to provide an overview of the use of the Matplotlib library. It covers creating simple line plots, but it is by no means comprehensive. For more information, try looking at the following documentation:\n\nMatplotlib documentation\n\nMatplotlib examples gallery\n\nGeoCAT examples gallery","type":"content","url":"/matplotlib-basics#resources-and-references","position":47},{"hierarchy":{"lvl1":"NumPy"},"type":"lvl1","url":"/numpy","position":0},{"hierarchy":{"lvl1":"NumPy"},"content":"","type":"content","url":"/numpy","position":1},{"hierarchy":{"lvl1":"NumPy"},"type":"lvl1","url":"/numpy#numpy","position":2},{"hierarchy":{"lvl1":"NumPy"},"content":"This section contains tutorials on array computing with \n\nNumPy.\n\nFrom the \n\nNumPy documentation:\n\nNumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation, and much more.\n\nNumPy’s position at the center of the scientific Python ecosystem means that all users should start here in their learning journey through the core scientific packages.","type":"content","url":"/numpy#numpy","position":3},{"hierarchy":{"lvl1":"Intermediate NumPy"},"type":"lvl1","url":"/intermediate-numpy","position":0},{"hierarchy":{"lvl1":"Intermediate NumPy"},"content":"","type":"content","url":"/intermediate-numpy","position":1},{"hierarchy":{"lvl1":"Intermediate NumPy"},"type":"lvl1","url":"/intermediate-numpy#intermediate-numpy","position":2},{"hierarchy":{"lvl1":"Intermediate NumPy"},"content":"\n\n","type":"content","url":"/intermediate-numpy#intermediate-numpy","position":3},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Overview"},"type":"lvl2","url":"/intermediate-numpy#overview","position":4},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Overview"},"content":"Working with multiple dimensions\n\nSubsetting of irregular arrays with booleans\n\nSorting, or indexing with indices\n\n","type":"content","url":"/intermediate-numpy#overview","position":5},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Prerequisites"},"type":"lvl2","url":"/intermediate-numpy#prerequisites","position":6},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nNumPy Basics\n\nNecessary\n\n\n\nTime to learn: 20 minutes\n\n","type":"content","url":"/intermediate-numpy#prerequisites","position":7},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Imports"},"type":"lvl2","url":"/intermediate-numpy#imports","position":8},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Imports"},"content":"We will be including \n\nMatplotlib to illustrate some of our examples, but you don’t need knowledge of it to complete this notebook.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n","type":"content","url":"/intermediate-numpy#imports","position":9},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Using axes to slice arrays"},"type":"lvl2","url":"/intermediate-numpy#using-axes-to-slice-arrays","position":10},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Using axes to slice arrays"},"content":"Here we introduce an important concept when working with NumPy: the axis. This indicates the particular dimension along which a function should operate (provided the function does something taking multiple values and converts to a single value).\n\nLet’s look at a concrete example with sum:\n\na = np.arange(12).reshape(3, 4)\na\n\nThis calculates the total of all values in the array.\n\nnp.sum(a)\n\nInfoSome of NumPy's functions can be accessed as `ndarray` methods!\n\na.sum()\n\nNow, with a reminder about how our array is shaped,\n\na.shape\n\nwe can specify axis to get just the sum across each of our rows.\n\nnp.sum(a, axis=0)\n\nOr do the same and take the sum across columns:\n\nnp.sum(a, axis=1)\n\nAfter putting together some data and introducing some more advanced calculations, let’s demonstrate a multi-layered example: calculating temperature advection. If you’re not familiar with this (don’t worry!), we’ll be looking to calculate\\text{advection} = -\\vec{v} \\cdot \\nabla T\n\nand to do so we’ll start with some random T and \\vec{v} values,\n\ntemp = np.random.randn(100, 50)\nu = np.random.randn(100, 50)\nv = np.random.randn(100, 50)\n\nWe can calculate the np.gradient of our new T(100x50) field as two separate component gradients,\n\ngradient_x, gradient_y = np.gradient(temp)\n\nIn order to calculate -\\vec{v} \\cdot \\nabla T, we will use np.dstack to turn our two separate component gradient fields into one multidimensional field containing x and y gradients at each of our 100x50 points,\n\ngrad_vectors = np.dstack([gradient_x, gradient_y])\nprint(grad_vectors.shape)\n\nand then do the same for our separate u and v wind components,\n\nwind_vectors = np.dstack([u, v])\nprint(wind_vectors.shape)\n\nFinally, we can calculate the dot product of these two multidimensional fields of wind and temperature gradient components by hand as an element-wise multiplication, *, and then a sum of our separate components at each point (i.e., along the last axis),\n\nadvection = (wind_vectors * -grad_vectors).sum(axis=-1)\nprint(advection.shape)\n\n","type":"content","url":"/intermediate-numpy#using-axes-to-slice-arrays","position":11},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Indexing arrays with boolean values"},"type":"lvl2","url":"/intermediate-numpy#indexing-arrays-with-boolean-values","position":12},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Indexing arrays with boolean values"},"content":"","type":"content","url":"/intermediate-numpy#indexing-arrays-with-boolean-values","position":13},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl3":"Array comparisons","lvl2":"Indexing arrays with boolean values"},"type":"lvl3","url":"/intermediate-numpy#array-comparisons","position":14},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl3":"Array comparisons","lvl2":"Indexing arrays with boolean values"},"content":"NumPy can easily create arrays of boolean values and use those to select certain values to extract from an array\n\n# Create some synthetic data representing temperature and wind speed data\nnp.random.seed(19990503)  # Make sure we all have the same data\ntemp = 20 * np.cos(np.linspace(0, 2 * np.pi, 100)) + 50 + 2 * np.random.randn(100)\nspeed = np.abs(\n    10 * np.sin(np.linspace(0, 2 * np.pi, 100)) + 10 + 5 * np.random.randn(100)\n)\n\nplt.plot(temp, 'tab:red')\nplt.plot(speed, 'tab:blue');\n\nBy doing a comparison between a NumPy array and a value, we get an\narray of values representing the results of the comparison between\neach element and the value\n\ntemp > 45\n\nThis, which is its own NumPy array of boolean values, can be used as an index to another array of the same size. We can even use it as an index within the original temp array we used to compare,\n\ntemp[temp > 45]\n\nInfoThis only returns the values from our original array meeting the indexing conditions, nothing more! Note the size,\n\ntemp[temp > 45].shape\n\nWarningIndexing arrays with arrays requires them to be the same size!\n\nIf we store this array somewhere new,\n\ntemp_45 = temp[temp > 45]\n\ntemp_45[temp < 45]\n\nWe find that our original (100,) shape array is too large to subset our new (60,) array.\n\nIf their sizes do match, the boolean array can come from a totally different array!\n\nspeed > 10\n\ntemp[speed > 10]\n\n","type":"content","url":"/intermediate-numpy#array-comparisons","position":15},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl3":"Replacing values","lvl2":"Indexing arrays with boolean values"},"type":"lvl3","url":"/intermediate-numpy#replacing-values","position":16},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl3":"Replacing values","lvl2":"Indexing arrays with boolean values"},"content":"To extend this, we can use this conditional indexing to assign new values to certain positions within our array, somewhat like a masking operation.\n\n# Make a copy so we don't modify the original data\ntemp2 = temp.copy()\nspeed2 = speed.copy()\n\n# Replace all places where speed is <10 with NaN (not a number)\ntemp2[speed < 10] = np.nan\nspeed2[speed < 10] = np.nan\n\nplt.plot(temp2, 'tab:red');\n\nand to put this in context,\n\nplt.plot(temp, 'r:')\nplt.plot(temp2, 'r')\nplt.plot(speed, 'b:')\nplt.plot(speed2, 'b');\n\nIf we use parentheses to preserve the order of operations, we can combine these conditions with other bitwise operators like the & for bitwise_and,\n\nmulti_mask = (temp < 45) & (speed > 10)\nmulti_mask\n\ntemp[multi_mask]\n\nHeat index is only defined for temperatures >= 80F and relative humidity values >= 40%. Using the data generated below, we can use boolean indexing to extract the data where heat index has a valid value.\n\n# Here's the \"data\"\nnp.random.seed(19990503)\ntemp = 20 * np.cos(np.linspace(0, 2 * np.pi, 100)) + 80 + 2 * np.random.randn(100)\nrelative_humidity = np.abs(\n    20 * np.cos(np.linspace(0, 4 * np.pi, 100)) + 50 + 5 * np.random.randn(100)\n)\n\n# Create a mask for the two conditions described above\ngood_heat_index = (temp >= 80) & (relative_humidity >= 0.4)\n\n# Use this mask to grab the temperature and relative humidity values that together\n# will give good heat index values\nprint(temp[good_heat_index])\n\nAnother bitwise operator we can find helpful is Python’s ~ complement operator, which can give us the inverse of our specific mask to let us assign np.nan to every value not satisfied in good_heat_index.\n\nplot_temp = temp.copy()\nplot_temp[~good_heat_index] = np.nan\nplt.plot(plot_temp, 'tab:red');\n\n","type":"content","url":"/intermediate-numpy#replacing-values","position":17},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Indexing using arrays of indices"},"type":"lvl2","url":"/intermediate-numpy#indexing-using-arrays-of-indices","position":18},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Indexing using arrays of indices"},"content":"You can also use a list or array of indices to extract particular values--this is a natural extension of the regular indexing. For instance, just as we can select the first element:\n\ntemp[0]\n\nWe can also extract the first, fifth, and tenth elements as a list:\n\ntemp[[0, 4, 9]]\n\nOne of the ways this comes into play is trying to sort NumPy arrays using argsort. This function returns the indices of the array that give the items in sorted order. So for our temp,\n\ninds = np.argsort(temp)\ninds\n\ni.e., our lowest value is at index 52, next 57, and so on. We can use this array of indices as an index for temp,\n\ntemp[inds]\n\nto get a sorted array back!\n\nWith some clever slicing, we can pull out the last 10, or 10 highest, values of temp,\n\nten_highest = inds[-10:]\nprint(temp[ten_highest])\n\nThere are other NumPy arg functions that return indices for operating; check out the \n\nNumPy docs on sorting your arrays!\n\n\n\n","type":"content","url":"/intermediate-numpy#indexing-using-arrays-of-indices","position":19},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Summary"},"type":"lvl2","url":"/intermediate-numpy#summary","position":20},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Summary"},"content":"In this notebook we introduced the power of understanding the dimensions of our data by specifying math along axis, used True and False values to subset our data according to conditions, and used lists of positions within our array to sort our data.","type":"content","url":"/intermediate-numpy#summary","position":21},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl3":"What’s Next","lvl2":"Summary"},"type":"lvl3","url":"/intermediate-numpy#whats-next","position":22},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl3":"What’s Next","lvl2":"Summary"},"content":"Taking some time to practice this is valuable to be able to quickly manipulate arrays of information in useful or scientific ways.\n\n","type":"content","url":"/intermediate-numpy#whats-next","position":23},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Resources and references"},"type":"lvl2","url":"/intermediate-numpy#resources-and-references","position":24},{"hierarchy":{"lvl1":"Intermediate NumPy","lvl2":"Resources and references"},"content":"The \n\nNumPy Users Guide expands further on some of these topics, as well as suggests various \n\nTutorials, lectures, and more at this stage.","type":"content","url":"/intermediate-numpy#resources-and-references","position":25},{"hierarchy":{"lvl1":"NumPy Basics"},"type":"lvl1","url":"/numpy-basics","position":0},{"hierarchy":{"lvl1":"NumPy Basics"},"content":"","type":"content","url":"/numpy-basics","position":1},{"hierarchy":{"lvl1":"NumPy Basics"},"type":"lvl1","url":"/numpy-basics#numpy-basics","position":2},{"hierarchy":{"lvl1":"NumPy Basics"},"content":"\n\n","type":"content","url":"/numpy-basics#numpy-basics","position":3},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Overview"},"type":"lvl2","url":"/numpy-basics#overview","position":4},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Overview"},"content":"Welcome to your first Python library - NumPy! NumPy is the fundamental package for numerical operations with Python. It contains among other things:\n\na powerful N-dimensional array object\n\nsophisticated (broadcasting) functions\n\nuseful linear algebra, Fourier transform, and random number capabilities\n\nLet’s get you started with the basics! In this notebook we will cover\n\nCreating an array\n\nMath and calculations with arrays\n\nInspecting an array with slicing and indexing\n\n","type":"content","url":"/numpy-basics#overview","position":5},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Prerequisites"},"type":"lvl2","url":"/numpy-basics#prerequisites","position":6},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nPython Quickstart\n\nNecessary\n\nLists, indexing, slicing, math\n\nTime to learn: 35 minutes\n\n","type":"content","url":"/numpy-basics#prerequisites","position":7},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Imports"},"type":"lvl2","url":"/numpy-basics#imports","position":8},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Imports"},"content":"A common convention you might encounter is to rename numpy to np on import to shorten it for the many times we will be calling on numpy for functionality.\n\nimport numpy as np\n\n","type":"content","url":"/numpy-basics#imports","position":9},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Create an array of ‘data’"},"type":"lvl2","url":"/numpy-basics#create-an-array-of-data","position":10},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Create an array of ‘data’"},"content":"The NumPy array represents a contiguous block of memory, holding entries of a given type (and hence fixed size). The entries are laid out in memory according to the shape, or list of dimension sizes. Let’s start by creating an array from a list of integers and taking a look at it,\n\na = np.array([1, 2, 3])\na\n\nWe can inspect the number of dimensions our array is organized along with ndim, and how long each of these dimensions are with shape\n\na.ndim\n\na.shape\n\nSo our 1-dimensional array has a shape of 3 along that dimension! Finally we can check out the underlying type of our underlying data,\n\na.dtype\n\nNow, let’s expand this with a new data type, and by using a list of lists we can grow the dimensions of our array!\n\na = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\na\n\na.ndim\n\na.shape\n\na.dtype\n\nAnd as before we can use ndim, shape, and dtype to discover how many dimensions of what lengths are making up our array of floats.\n\n","type":"content","url":"/numpy-basics#create-an-array-of-data","position":11},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Generation","lvl2":"Create an array of ‘data’"},"type":"lvl3","url":"/numpy-basics#generation","position":12},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Generation","lvl2":"Create an array of ‘data’"},"content":"NumPy also provides helper functions for generating arrays of data to save you typing for regularly spaced data. Don’t forget your Python indexing rules!\n\narange(start, stop, step) creates a range of values in the interval [start,stop) with step spacing.\n\nlinspace(start, stop, num) creates a range of num evenly spaced values over the range [start,stop].\n\n","type":"content","url":"/numpy-basics#generation","position":13},{"hierarchy":{"lvl1":"NumPy Basics","lvl4":"arange","lvl3":"Generation","lvl2":"Create an array of ‘data’"},"type":"lvl4","url":"/numpy-basics#arange","position":14},{"hierarchy":{"lvl1":"NumPy Basics","lvl4":"arange","lvl3":"Generation","lvl2":"Create an array of ‘data’"},"content":"\n\na = np.arange(5)\na\n\na = np.arange(3, 11)\na\n\na = np.arange(1, 10, 2)\na\n\n","type":"content","url":"/numpy-basics#arange","position":15},{"hierarchy":{"lvl1":"NumPy Basics","lvl4":"linspace","lvl3":"Generation","lvl2":"Create an array of ‘data’"},"type":"lvl4","url":"/numpy-basics#linspace","position":16},{"hierarchy":{"lvl1":"NumPy Basics","lvl4":"linspace","lvl3":"Generation","lvl2":"Create an array of ‘data’"},"content":"\n\nb = np.linspace(0, 4, 5)\nb\n\nb.shape\n\nb = np.linspace(3, 10, 15)\nb\n\nb = np.linspace(2.5, 10.25, 11)\nb\n\nb = np.linspace(0, 100, 30)\nb\n\n","type":"content","url":"/numpy-basics#linspace","position":17},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Perform calculations with NumPy"},"type":"lvl2","url":"/numpy-basics#perform-calculations-with-numpy","position":18},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Perform calculations with NumPy"},"content":"","type":"content","url":"/numpy-basics#perform-calculations-with-numpy","position":19},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Arithmetic","lvl2":"Perform calculations with NumPy"},"type":"lvl3","url":"/numpy-basics#arithmetic","position":20},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Arithmetic","lvl2":"Perform calculations with NumPy"},"content":"In core Python, that is without NumPy, creating sequences of values and adding them together requires writing a lot of manual loops, just like one would do in C/C++:\n\na = list(range(5, 10))\nb = [3 + i * 1.5 / 4 for i in range(5)]\n\na, b\n\nresult = []\nfor x, y in zip(a, b):\n    result.append(x + y)\nprint(result)\n\nThat is very verbose and not very intuitive. Using NumPy this becomes:\n\na = np.arange(5, 10)\nb = np.linspace(3, 4.5, 5)\n\na + b\n\nMany major mathematical operations operate in the same way. They perform an element-by-element calculation of the two arrays.\n\na - b\n\na / b\n\na**b\n\nWarningThese arrays must be the same shape!\n\nb = np.linspace(3, 4.5, 6)\na.shape, b.shape\n\na * b\n\n","type":"content","url":"/numpy-basics#arithmetic","position":21},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Constants","lvl2":"Perform calculations with NumPy"},"type":"lvl3","url":"/numpy-basics#constants","position":22},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Constants","lvl2":"Perform calculations with NumPy"},"content":"NumPy provides us access to some useful constants as well - remember you should never be typing these in manually! Other libraries such as SciPy and MetPy have their own set of constants that are more domain specific.\n\nnp.pi\n\nnp.e\n\nYou can use these for classic calculations you might be familiar with! Here we can create a range t = [0, 2 pi] by pi/4,\n\nt = np.arange(0, 2 * np.pi + np.pi / 4, np.pi / 4)\nt\n\nt / np.pi\n\n","type":"content","url":"/numpy-basics#constants","position":23},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Array math functions","lvl2":"Perform calculations with NumPy"},"type":"lvl3","url":"/numpy-basics#array-math-functions","position":24},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Array math functions","lvl2":"Perform calculations with NumPy"},"content":"NumPy also has math functions that can operate on arrays. Similar to the math operations, these greatly simplify and speed up these operations. Let’s start with calculating \\sin(t)!\n\nsin_t = np.sin(t)\nsin_t\n\nand clean it up a bit by rounding to three decimal places.\n\nnp.round(sin_t, 3)\n\ncos_t = np.cos(t)\ncos_t\n\nInfoCheck out NumPy's list of mathematical functions \n\nhere!\n\nWe can convert between degrees and radians with only NumPy, by hand\n\nt / np.pi * 180\n\nor with built-in function rad2deg,\n\ndegrees = np.rad2deg(t)\ndegrees\n\nWe are similarly provided algorithms for operations including integration, bulk summing, and cumulative summing.\n\nsine_integral = np.trapz(sin_t, t)\nnp.round(sine_integral, 3)\n\ncos_sum = np.sum(cos_t)\ncos_sum\n\ncos_csum = np.cumsum(cos_t)\nprint(cos_csum)\n\n","type":"content","url":"/numpy-basics#array-math-functions","position":25},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Indexing and subsetting arrays"},"type":"lvl2","url":"/numpy-basics#indexing-and-subsetting-arrays","position":26},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Indexing and subsetting arrays"},"content":"","type":"content","url":"/numpy-basics#indexing-and-subsetting-arrays","position":27},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Indexing","lvl2":"Indexing and subsetting arrays"},"type":"lvl3","url":"/numpy-basics#indexing","position":28},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Indexing","lvl2":"Indexing and subsetting arrays"},"content":"We can use integer indexing to reach into our arrays and pull out individual elements. Let’s make a toy 2-d array to explore. Here we create a 12-value arange and reshape it into a 3x4 array.\n\na = np.arange(12).reshape(3, 4)\na\n\nRecall that Python indexing starts at 0, and we can begin indexing our array with the list-style list[element] notation,\n\na[0]\n\nto pull out just our first row of data within a. Similarly we can index in reverse with negative indices,\n\na[-1]\n\nto pull out just the last row of data within a. This notation extends to as many dimensions as make up our array as array[m, n, p, ...]. The following diagram shows these indices for an example, 2-dimensional 6x6 array,\n\n\n\nFor example, let’s find the entry in our array corresponding to the 2nd row (m=1 in Python) and the 3rd column (n=2 in Python)\n\na[1, 2]\n\nWe can again use these negative indices to index backwards,\n\na[-1, -1]\n\nand even mix-and-match along dimensions,\n\na[1, -2]\n\n","type":"content","url":"/numpy-basics#indexing","position":29},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Slices","lvl2":"Indexing and subsetting arrays"},"type":"lvl3","url":"/numpy-basics#slices","position":30},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Slices","lvl2":"Indexing and subsetting arrays"},"content":"Slicing syntax is written as array[start:stop:step]. Note that all numbers are optional. Importantly, the step parameter is optional and can be omitted, in which case the slice uses a default step of 1.\n\ndefaults:\n\nstart = 0\n\nstop = len(dim)\n\nstep = 1\n\nThe second colon is also optional if no step is used.\n\nLet’s pull out just the first row, m=0 of a and see how this works!\n\nb = a[0]\nb\n\nLaying out our default slice to see the entire array explicitly looks something like this,\n\nb[0:4:1]\n\nwhere again, these default values are optional,\n\nb[::]\n\nand even the second : is optional\n\nb[:]\n\nNow to actually make our own slice, let’s select all elements from m=0 to m=2\n\nb[0:2]\n\nWarningSlice notation is exclusive of the final index.\n\nThis means that slices will include every value up to your stop index and not this index itself, like a half-open interval [start, end). For example,\n\nb[3]\n\nreveals a different value than\n\nb[0:3]\n\nFinally, a few more examples of this notation before reintroducing our 2-d array a.\n\nb[2:]  # m=2 through the end, can leave off the number\n\nb[:3]  # similarly, the same as our b[0:3]\n\n","type":"content","url":"/numpy-basics#slices","position":31},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Multidimensional slicing","lvl2":"Indexing and subsetting arrays"},"type":"lvl3","url":"/numpy-basics#multidimensional-slicing","position":32},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"Multidimensional slicing","lvl2":"Indexing and subsetting arrays"},"content":"This entire syntax can be extended to each dimension of multidimensional arrays.\n\na\n\nFirst let’s pull out rows 0 through 2, and then every : column for each of those\n\na[0:2, :]\n\nSimilarly, let’s get all rows for just column 2,\n\na[:, 2]\n\nor just take a look at the full row :, for every second column, ::2,\n\na[:, ::2]\n\nFor any shape of array, you can use ... to capture full slices of every non-specified dimension. Consider the 3-D array,\n\nc = a.reshape(2, 2, 3)\nc\n\nc[0, ...]\n\nand so this is equivalent to\n\nc[0, :, :]\n\nfor extracting every dimension across our first row. We can also flip this around,\n\nc[..., -1]\n\nto investigate every preceding dimension along our the last entry of our last axis, the same as c[:, :, -1].\n\n\n\n","type":"content","url":"/numpy-basics#multidimensional-slicing","position":33},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Summary"},"type":"lvl2","url":"/numpy-basics#summary","position":34},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Summary"},"content":"In this notebook we introduced NumPy and the ndarray that is so crucial to the entirety of the scientific Python community ecosystem. We created some arrays, used some of NumPy’s own mathematical functions to manipulate them, and then introduced the world of NumPy indexing and selecting for even multi-dimensional arrays.","type":"content","url":"/numpy-basics#summary","position":35},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/numpy-basics#whats-next","position":36},{"hierarchy":{"lvl1":"NumPy Basics","lvl3":"What’s next?","lvl2":"Summary"},"content":"This notebook is the gateway to nearly every other Pythia resource here. This information is crucial for understanding SciPy, pandas, xarray, and more. Continue into NumPy to explore some more intermediate and advanced topics!\n\n","type":"content","url":"/numpy-basics#whats-next","position":37},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Resources and references"},"type":"lvl2","url":"/numpy-basics#resources-and-references","position":38},{"hierarchy":{"lvl1":"NumPy Basics","lvl2":"Resources and references"},"content":"NumPy User Guide\n\nSciPy Lecture Notes","type":"content","url":"/numpy-basics#resources-and-references","position":39},{"hierarchy":{"lvl1":"NumPy Broadcasting"},"type":"lvl1","url":"/numpy-broadcasting","position":0},{"hierarchy":{"lvl1":"NumPy Broadcasting"},"content":"","type":"content","url":"/numpy-broadcasting","position":1},{"hierarchy":{"lvl1":"NumPy Broadcasting"},"type":"lvl1","url":"/numpy-broadcasting#numpy-broadcasting","position":2},{"hierarchy":{"lvl1":"NumPy Broadcasting"},"content":"\n\n","type":"content","url":"/numpy-broadcasting#numpy-broadcasting","position":3},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Overview"},"type":"lvl2","url":"/numpy-broadcasting#overview","position":4},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Overview"},"content":"Before we begin, it is important to know that broadcasting is a valuable part of the power that NumPy provides. However, there’s no looking past the fact that broadcasting can be conceptually difficult to digest. This information can be helpful and very powerful, but it may be more prudent to first start learning the other label-based elements of the Python ecosystem, \n\nPandas and \n\nXarray.  This can make understanding NumPy broadcasting easier or simpler when using real-world data. When you are ready to learn about NumPy broadcasting, this section is organized as follows:\n\nAn introduction to broadcasting\n\nAvoiding loops with vectorization\n\n","type":"content","url":"/numpy-broadcasting#overview","position":5},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Prerequisites"},"type":"lvl2","url":"/numpy-broadcasting#prerequisites","position":6},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nNumPy Basics\n\nNecessary\n\n\n\nIntermediate NumPy\n\nHelpful\n\n\n\nConceptual guide to broadcasting\n\nHelpful\n\n\n\nTime to learn: 30 minutes\n\n","type":"content","url":"/numpy-broadcasting#prerequisites","position":7},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Imports"},"type":"lvl2","url":"/numpy-broadcasting#imports","position":8},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Imports"},"content":"As always, when working with NumPy, it must be imported first:\n\nimport numpy as np\n\n","type":"content","url":"/numpy-broadcasting#imports","position":9},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Using broadcasting to implicitly loop over data"},"type":"lvl2","url":"/numpy-broadcasting#using-broadcasting-to-implicitly-loop-over-data","position":10},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Using broadcasting to implicitly loop over data"},"content":"\n\n","type":"content","url":"/numpy-broadcasting#using-broadcasting-to-implicitly-loop-over-data","position":11},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"What is broadcasting?","lvl2":"Using broadcasting to implicitly loop over data"},"type":"lvl3","url":"/numpy-broadcasting#what-is-broadcasting","position":12},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"What is broadcasting?","lvl2":"Using broadcasting to implicitly loop over data"},"content":"Broadcasting is a useful NumPy tool that allows us to perform operations between arrays with different shapes, provided that they are compatible with each other in certain ways. To start, we can create an array below and add 5 to it:\n\na = np.array([10, 20, 30, 40])\na + 5\n\nThis works even though 5 is not an array. It behaves as expected, adding 5 to each of the elements in a. This also works if 5 is an array:\n\nb = np.array([5])\na + b\n\nThis takes the single element in b and adds it to each of the elements in a. This won’t work for just any b, though; for instance, the following won’t work:\n\nb = np.array([5, 6, 7])\na + b\n\nIt does work if a and b are the same shape:\n\nb = np.array([5, 5, 10, 10])\na + b\n\nWhat if what we really want is pairwise addition of a and b? Without broadcasting, we could accomplish this by looping:\n\nb = np.array([1, 2, 3, 4, 5])\n\nresult = np.empty((5, 4), dtype=np.int32)\nfor row, valb in enumerate(b):\n    for col, vala in enumerate(a):\n        result[row, col] = vala + valb\nresult\n\nWe can also do this by manually repeating the arrays to the proper shape for the result, using np.tile. This avoids the need to manually loop:\n\naa = np.tile(a, (5, 1))\naa\n\n# Turn b into a column array, then tile it\nbb = np.tile(b.reshape(5, 1), (1, 4))\nbb\n\naa + bb\n\n","type":"content","url":"/numpy-broadcasting#what-is-broadcasting","position":13},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"Giving NumPy room for broadcasting","lvl2":"Using broadcasting to implicitly loop over data"},"type":"lvl3","url":"/numpy-broadcasting#giving-numpy-room-for-broadcasting","position":14},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"Giving NumPy room for broadcasting","lvl2":"Using broadcasting to implicitly loop over data"},"content":"We can also do this using broadcasting, which is where NumPy implicitly repeats the array without using additional memory. With broadcasting, NumPy takes care of repeating for you, provided dimensions are “compatible”. This works as follows:\n\nCheck the number of dimensions of the arrays. If they are different, prepend dimensions of size one until the arrays are the same dimension shape.\n\nCheck if each of the dimensions are compatible. This works as follows:\n\nEach dimension is checked.\n\nIf one of the arrays has a size of 1 in the checked dimension, or both arrays have the same size in the checked dimension, the check passes.\n\nIf all dimension checks pass, the dimensions are compatible.\n\nFor example, consider the following arrays:\n\na.shape\n\nb.shape\n\nRight now, these arrays both have the same number of dimensions.  They both have only one dimension, but that dimension is incompatible.  We can solve this by appending a dimension using np.newaxis when indexing, like this:\n\nbb = b[:, np.newaxis]\nbb.shape\n\na + bb\n\n(a + bb).shape\n\nWe can also make the code more succinct by performing the newaxis and addition operations in a single line, like this:\n\na + b[:, np.newaxis]\n\n","type":"content","url":"/numpy-broadcasting#giving-numpy-room-for-broadcasting","position":15},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"Extending to higher dimensions","lvl2":"Using broadcasting to implicitly loop over data"},"type":"lvl3","url":"/numpy-broadcasting#extending-to-higher-dimensions","position":16},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"Extending to higher dimensions","lvl2":"Using broadcasting to implicitly loop over data"},"content":"The same broadcasting ability and rules also apply for arrays of higher dimensions. Consider the following arrays x, y, and z, which are all different dimensions. We can use newaxis and broadcasting to perform x^2 + y^2 + z^2:\n\nx = np.array([1, 2])\ny = np.array([3, 4, 5])\nz = np.array([6, 7, 8, 9])\n\nFirst, we extend the x array using newaxis, and then square it.  Then, we square y, and broadcast it onto the extended x array:\n\nd_2d = x[:, np.newaxis] ** 2 + y**2\n\nd_2d.shape\n\nFinally, we further extend this new 2-D array to a 3-D array using newaxis, square the z array, and then broadcast z onto the newly extended array:\n\nd_3d = d_2d[..., np.newaxis] + z**2\n\nd_3d.shape\n\nAs described above, we can also perform these operations in a single line of code, like this:\n\nh = x[:, np.newaxis, np.newaxis] ** 2 + y[np.newaxis, :, np.newaxis] ** 2 + z**2\n\nWe can use the shape method to see the shape of the array created by the single line of code above.  As you can see, it matches the shape of the array created by the multi-line process above:\n\nh.shape\n\nWe can also use the all method to confirm that both arrays contain the same data:\n\nnp.all(h == d_3d)\n\nBroadcasting is often useful when you want to do calculations with coordinate values, which are often given as 1-D arrays corresponding to positions along a particular array dimension. For example, we can use broadcasting to help with taking range and azimuth values for radar data (1-D separable polar coordinates) and converting to x,y pairs relative to the radar location.\n\nGiven the 3-D temperature field and 1-D pressure coordinates below, let’s calculate T * exp(P / 1000). We will need to use broadcasting to make the arrays compatible.  The following code demonstrates how to use newaxis and broadcasting to perform this calculation:\n\npressure = np.array([1000, 850, 500, 300])\ntemps = np.linspace(20, 30, 24).reshape(4, 3, 2)\npressure.shape, temps.shape\n\npressure[:, np.newaxis, np.newaxis].shape\n\ntemps * np.exp(pressure[:, np.newaxis, np.newaxis] / 1000)\n\n","type":"content","url":"/numpy-broadcasting#extending-to-higher-dimensions","position":17},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Vectorize calculations to avoid explicit loops"},"type":"lvl2","url":"/numpy-broadcasting#vectorize-calculations-to-avoid-explicit-loops","position":18},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Vectorize calculations to avoid explicit loops"},"content":"\n\nWhen working with arrays of data, loops over the individual array elements is a fact of life. However, for improved runtime performance, it is important to avoid performing these loops in Python as much as possible, and let NumPy handle the looping for you. Avoiding these loops frequently, but not always, results in shorter and clearer code as well.\n\n","type":"content","url":"/numpy-broadcasting#vectorize-calculations-to-avoid-explicit-loops","position":19},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"Look ahead/behind","lvl2":"Vectorize calculations to avoid explicit loops"},"type":"lvl3","url":"/numpy-broadcasting#look-ahead-behind","position":20},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"Look ahead/behind","lvl2":"Vectorize calculations to avoid explicit loops"},"content":"One common pattern for vectorizing is in converting loops that work over the current point, in addition to the previous point and/or the next point. This comes up when doing finite-difference calculations, e.g., approximating derivatives:f'(x) = f_{i+1} - f_{i}\n\na = np.linspace(0, 20, 6)\na\n\nWe can calculate the forward difference for this array using a manual loop, like this:\n\nd = np.zeros(a.size - 1)\nfor i in range(len(a) - 1):\n    d[i] = a[i + 1] - a[i]\nd\n\nIt would be nice to express this calculation without a loop, if possible. To see how to go about this, let’s consider the values that are involved in calculating d[i]; in other words, the values a[i+1] and a[i]. The values over the loop iterations are:\n\ni\n\na[i+1]\n\na[i]\n\n0\n\n4\n\n0\n\n1\n\n8\n\n4\n\n2\n\n12\n\n8\n\n3\n\n16\n\n12\n\n4\n\n20\n\n16\n\nWe can then express the series of values for a[i+1] as follows:\n\na[1:]\n\nWe can also express the series of values for a[i] as follows:\n\na[:-1]\n\nThis means that we can express the forward difference using the following statement:\n\na[1:] - a[:-1]\n\nIt should be noted that using slices in this way returns only a view on the original array. In other words, you can use the slices to modify the original data, either intentionally or accidentally.  Also, this is a quick operation that does not involve a copy and does not bloat memory usage.\n\n","type":"content","url":"/numpy-broadcasting#look-ahead-behind","position":21},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl4":"2nd Derivative","lvl3":"Look ahead/behind","lvl2":"Vectorize calculations to avoid explicit loops"},"type":"lvl4","url":"/numpy-broadcasting#id-2nd-derivative","position":22},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl4":"2nd Derivative","lvl3":"Look ahead/behind","lvl2":"Vectorize calculations to avoid explicit loops"},"content":"A finite-difference estimate of the 2nd derivative is given by the following equation (ignoring \\Delta x):f''(x) = 2\nf_i - f_{i+1} - f_{i-1}\n\nLet’s write some vectorized code to calculate this finite difference for a, using slices.  Analyze the code below, and compare the result to the values you would expect to see from the 2nd derivative of a.\n\n2 * a[1:-1] - a[2:] - a[:-2]\n\n","type":"content","url":"/numpy-broadcasting#id-2nd-derivative","position":23},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"Blocking","lvl2":"Vectorize calculations to avoid explicit loops"},"type":"lvl3","url":"/numpy-broadcasting#blocking","position":24},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"Blocking","lvl2":"Vectorize calculations to avoid explicit loops"},"content":"Another application that can become more efficient using vectorization is operating on blocks of data. Let’s start by creating some temperature data (rounding to make it easier to see and recognize the values):\n\ntemps = np.round(20 + np.random.randn(10) * 5, 1)\ntemps\n\nLet’s start by writing a loop to take a 3-point running mean of the data. We’ll do this by iterating over all points in the array and averaging the 3 points centered on each point. We’ll simplify the problem by avoiding dealing with the cases at the edges of the array:\n\navg = np.zeros_like(temps)\nfor i in range(1, len(temps) - 1):\n    sub = temps[i - 1 : i + 2]\n    avg[i] = sub.mean()\n\navg\n\nAs with the case of doing finite differences, we can express this using slices of the original array instead of loops:\n\n# i - 1            i          i + 1\n(temps[:-2] + temps[1:-1] + temps[2:]) / 3\n\nAnother option to solve this type of problem is to use the powerful NumPy tool as_strided instead of slicing. This tool can result in some odd behavior, so take care when using it.  However, the trade-off is that the as_strided tool can be used to perform powerful operations. What we’re doing here is altering how NumPy is interpreting the values in the memory that underpins the array. Take this array, for example:\n\ntemps\n\nUsing as_strided, we can create a view of this array with a new, bigger shape, with rows made up of overlapping values. We do this by specifying a new shape of 8x3.  There are 3 columns, for fitting blocks of data containing 3 values each, and 8 rows, to correspond to the 8 blocks of data of that size that are possible in the original 1-D array. We can then use the strides argument to control how NumPy walks between items in each dimension. The last item in the strides tuple simply states that the number of bytes to walk between items is just the size of an item. (Increasing this last item would skip items.) The first item says that when we go to a new element (in this example, a new row), only advance the size of a single item. This is what gives us overlapping rows. The code for these operations looks like this:\n\nblock_size = 3\nnew_shape = (len(temps) - block_size + 1, block_size)\nbytes_per_item = temps.dtype.itemsize\ntemps_strided = np.lib.stride_tricks.as_strided(\n    temps, shape=new_shape, strides=(bytes_per_item, bytes_per_item)\n)\ntemps_strided\n\nNow that we have this view of the array with the rows representing overlapping blocks, we can operate across the rows with mean and the axis=-1 argument to get our running average:\n\ntemps_strided.mean(axis=-1)\n\nIt should be noted that there are no copies going on here, so if we change a value at a single indexed location, the change actually shows up in multiple locations:\n\ntemps_strided[0, 2] = 2000\ntemps_strided\n\n","type":"content","url":"/numpy-broadcasting#blocking","position":25},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"Finding the difference between min and max","lvl2":"Vectorize calculations to avoid explicit loops"},"type":"lvl3","url":"/numpy-broadcasting#finding-the-difference-between-min-and-max","position":26},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"Finding the difference between min and max","lvl2":"Vectorize calculations to avoid explicit loops"},"content":"Another operation that crops up when slicing and dicing data is trying to identify a set of indices along a particular axis, contained within a larger multidimensional array. For instance, say we have a 3-D array of temperatures, and we want to identify the location of the -10^oC isotherm within each column:\n\npressure = np.linspace(1000, 100, 25)\ntemps = np.random.randn(25, 30, 40) * 3 + np.linspace(25, -100, 25).reshape(-1, 1, 1)\n\nNumPy has the function argmin(), which returns the index of the minimum value. We can use this to find the minimum absolute difference between the value and -10:\n\n# Using axis=0 to tell it to operate along the pressure dimension\ninds = np.argmin(np.abs(temps - -10), axis=0)\ninds\n\ninds.shape\n\nGreat! We now have an array representing the index of the point closest to -10^oC in each column of data. We can use this new array as a lookup index for our pressure coordinate array to find the pressure level for each column:\n\npressure[inds]\n\nNow, we can try to find the closest actual temperature value using the new array:\n\ntemps[inds, :, :].shape\n\nUnfortunately, this replaced the pressure dimension (size 25) with the shape of our index array (30 x 40), giving us a 30 x 40 x 30 x 40 array.  Obviously, if scientifically relevant data values were being used, this result would almost certainly make such data invalid. One solution would be to set up a loop with the ndenumerate function, like this:\n\noutput = np.empty(inds.shape, dtype=temps.dtype)\nfor (i, j), val in np.ndenumerate(inds):\n    output[i, j] = temps[val, i, j]\noutput\n\nOf course, what we really want to do is avoid the explicit loop. Let’s temporarily simplify the problem to a single dimension. If we have a 1-D array, we can pass a 1-D array of indices (a full range), and get back the same as the original data array:\n\npressure[np.arange(pressure.size)]\n\nnp.all(pressure[np.arange(pressure.size)] == pressure)\n\nWe can use this to select all the indices on the other dimensions of our temperature array. We will also need to use the magic of broadcasting to combine arrays of indices across dimensions.\n\nThis can be written as a vectorized solution.  For example:\n\ny_inds = np.arange(temps.shape[1])[:, np.newaxis]\nx_inds = np.arange(temps.shape[2])\ntemps[inds, y_inds, x_inds]\n\nNow, we can use this new array to find, for example, the relative humidity at the -10^oC isotherm:\n\nnp.all(output == temps[inds, y_inds, x_inds])\n\n\n\n","type":"content","url":"/numpy-broadcasting#finding-the-difference-between-min-and-max","position":27},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Summary"},"type":"lvl2","url":"/numpy-broadcasting#summary","position":28},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Summary"},"content":"We’ve previewed some advanced NumPy capabilities, with a focus on vectorization; in other words, using clever broadcasting and data windowing techniques to enhance the speed and readability of our calculation code. By making use of vectorization, you can reduce explicit construction of loops in your code, and improve speed of calculation throughout the execution of such code.","type":"content","url":"/numpy-broadcasting#summary","position":29},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"What’s next","lvl2":"Summary"},"type":"lvl3","url":"/numpy-broadcasting#whats-next","position":30},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl3":"What’s next","lvl2":"Summary"},"content":"This is an advanced NumPy topic; however, it is important to learn this topic in order to design calculation code that maximizes scalability and speed. If you would like to explore this topic further, please review the links below. We also suggest diving into label-based indexing and subsetting with \n\nPandas and \n\nXarray, where some of this broadcasting can be simplified, or have added context.\n\n","type":"content","url":"/numpy-broadcasting#whats-next","position":31},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Resources and references"},"type":"lvl2","url":"/numpy-broadcasting#resources-and-references","position":32},{"hierarchy":{"lvl1":"NumPy Broadcasting","lvl2":"Resources and references"},"content":"NumPy Broadcasting Documentation","type":"content","url":"/numpy-broadcasting#resources-and-references","position":33},{"hierarchy":{"lvl1":"Overview"},"type":"lvl1","url":"/overview-1","position":0},{"hierarchy":{"lvl1":"Overview"},"content":"\n\nYou’ve made it to the Core Packages section of the book!\n\nAs you might know by now that Python is a programming language. To make your job easier, developers of this programming language provide users like you with libraries (or packages). Core libraries will help you with fundamental numerical functions, and high-level libraries will help you efficiently analyze and visualize your data. Some of these libraries are used all across the Python community, while others are domain-specific. Read below to learn more about core and high-level libraries, and domain-specific libraries of the geoscience community. We suggest that new users start with the \n\nFoundational Skills section in order to get the most out of the tutorials below.","type":"content","url":"/overview-1","position":1},{"hierarchy":{"lvl1":"Overview","lvl2":"Core libraries"},"type":"lvl2","url":"/overview-1#core-libraries","position":2},{"hierarchy":{"lvl1":"Overview","lvl2":"Core libraries"},"content":"Most geoscience data analysis involves working with numerical arrays.\nThe default library for dealing with numerical arrays in Python is \n\nNumPy.\nIt has some built in functions for calculating very simple statistics\n(e.g. maximum, mean, standard deviation),\nbut for more complex analysis\n(e.g. interpolation, integration, linear algebra)\nthe \n\nSciPy library is the default.\nIf you’re dealing with particularly large arrays,\n\n\nDask works with the existing Python ecosystem\n(including NumPy) to scale your analysis\nto multi-core machines and/or distributed clusters (i.e. parallel processing).\n\nAnother common feature of geo-data science is time series analysis.\nThe Python standard library comes with a \n\ndatetime\npackage for manipulating dates and times.\nNumPy also includes a \n\ndatetime64\nmodule for efficient vectorized datetime operations\nand the \n\ncftime library\nis useful for dealing with non-standard calendars.\n\nWhen it comes to data visualization,\nthe default library is \n\nMatplotlib.\nAs you can see at the \n\nMatplotlib gallery,\nthis library is great for any simple (e.g. bar charts, contour plots, line graphs),\nstatic (e.g. .png, .eps, .pdf) plots.\nThe \n\nCartopy library\nprovides additional plotting functionality for common geographic map projections.","type":"content","url":"/overview-1#core-libraries","position":3},{"hierarchy":{"lvl1":"Overview","lvl2":"High-level libraries"},"type":"lvl2","url":"/overview-1#high-level-libraries","position":4},{"hierarchy":{"lvl1":"Overview","lvl2":"High-level libraries"},"content":"While pretty much all data analysis and visualization tasks\ncould be achieved with a combination of the core libraries,\ntheir flexible, all-purpose nature means relatively common/simple tasks\ncan often require quite a bit of work (i.e. many lines of code).\nTo make things more efficient for data scientists,\nthe scientific Python community has therefore built a number of libraries on top of the core stack.\nThese high-levels libraries aren’t as flexible\n– they can’t do everything like the core stack can –\nbut they can do common tasks with far less effort.\n\nThe most popular high-level data science library is undoubtedly \n\nPandas.\nThe key advance offered by Pandas is the concept of labeled arrays.\nRather than referring to the individual elements of a data array using a numeric index\n(as is required with NumPy),\nthe actual row and column headings can be used.\nThat means information from the cardiac ward on 3 July 2005\ncould be obtained from a medical dataset by asking for data['cardiac'].loc['2005-07-03'],\nrather than having to remember the numeric index corresponding to that ward and date.\nThis labeled array feature,\ncombined with a bunch of other features that streamline common statistical and plotting tasks\ntraditionally performed with SciPy, datetime and Matplotlib,\ngreatly simplifies the code development process (read: less lines of code).\n\nOne of the limitations of Pandas\nis that it’s only able to handle one- or two-dimensional (i.e. tabular) data arrays.\nThe \n\nXarray library was therefore created\nto extend the labelled array concept to x-dimensional arrays.\nNot all of the Pandas functionality is available\n(which is a trade-off associated with being able to handle multi-dimensional arrays),\nbut the ability to refer to array elements by their actual latitude (e.g. 20 South),\nlongitude (e.g. 50 East), height (e.g. 500 hPa) and time (e.g. 2015-04-27), for example,\nmakes the Xarray data array far easier to deal with than the NumPy array.\nAs an added bonus,\nXarray also has built in functionality for reading/writing specific geoscience file formats\n(e.g netCDF, GRIB)\nand incorporates Dask under the hood to make dealing with large arrays easier.\n\nYou will occasionally find yourself needing to use a core library directly\n(e.g. you might create a plot with Xarray and then call a specific Matplotlib\nfunction to customise a label on that plot),\nbut to avoid re-inventing the wheel your first impulse should always be\nto check whether a high-level library like Pandas or Xarray has the functionality you need.\nNothing would be more heartbreaking than spending hours writing your own function\nusing the netCDF4 library for extracting the metadata contained within a netCDF file,\nfor instance,\nonly to find that Xarray automatically keeps this information upon reading a netCDF file.\nIn this way, a solid working knowledge of the geoscience stack\ncan save you a lot of time and effort.","type":"content","url":"/overview-1#high-level-libraries","position":5},{"hierarchy":{"lvl1":"Overview","lvl2":"Domain-specific libraries"},"type":"lvl2","url":"/overview-1#domain-specific-libraries","position":6},{"hierarchy":{"lvl1":"Overview","lvl2":"Domain-specific libraries"},"content":"So far we’ve considered libraries that do general,\nbroad-scale tasks like data input/output, common statistics, visualisation, etc.\nGiven their large user base,\nthese libraries are usually written and supported by large companies/institutions\n(e.g. the MetOffice supports Cartopy)\nor the wider PyData community (e.g. NumPy, Pandas, Xarray).\nWithin each sub-discipline of the geosciences,\nindividuals and research groups take these general libraries\nand apply them to their very specific data analysis tasks.\nIncreasingly, these individuals and groups\nare formally packaging and releasing their code for use within their community.\nFor instance, Andrew Dawson (an atmospheric scientist at Oxford)\ndoes a lot of EOF analysis and manipulation of wind data,\nso he has released his \n\neofs\nand \n\nwindspharm libraries\n(which are able to handle data arrays from NumPy or Xarray).\nSimilarly, a group at the Atmospheric Radiation Measurement (ARM) Climate Research Facility\nhave released their Python ARM Radar Toolkit (\n\nPy-ART)\nfor analysing weather radar data.\n\nA great place to start learning about use-cases for domain-specific libraries across the geosciences is the \n\nPythia Cookbook Gallery. Also check out the \n\nPythia Resource Gallery and try filtering by domain. The \n\nPython for Atmosphere and Ocean Science (PyAOS) package index\nattempt to keep track of the domain-specific libraries in these subfiels.","type":"content","url":"/overview-1#domain-specific-libraries","position":7},{"hierarchy":{"lvl1":"Overview","lvl2":"Tutorials"},"type":"lvl2","url":"/overview-1#tutorials","position":8},{"hierarchy":{"lvl1":"Overview","lvl2":"Tutorials"},"content":"NumPy: Core package for array computing, the workhorse of the Scientific Python stack\n\nMatplotlib: Basic plotting\n\nCartopy: Plotting on map projections\n\nDatetime: Dealing with time and calendar data\n\nPandas: Working with labeled tabular data\n\nData formats: Working with common geoscience data formats\n\nXarray: Working with gridded and labeled N-dimensional data","type":"content","url":"/overview-1#tutorials","position":9},{"hierarchy":{"lvl1":"Pandas"},"type":"lvl1","url":"/pandas","position":0},{"hierarchy":{"lvl1":"Pandas"},"content":"Note\n\nThis content is under construction!\n\nThis section will contain tutorials on using \n\npandas for labeled tabular data.\n\nFrom the \n\nofficial documentation, Pandas “is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.”\n\nPandas is a very powerful library for working with tabular data (e.g., spreadsheets, comma-separated-value files, or database printouts; all of these are quite common for geoscientific data). It allows us to use labels for our data; this, in turn, allows us to write expressive and robust code to manipulate the data.\n\nKey features of Pandas are the abilities to read in tabular data and to slice and dice data, as well as exploratory analysis tools native to the library.","type":"content","url":"/pandas","position":1},{"hierarchy":{"lvl1":"Introduction to Pandas"},"type":"lvl1","url":"/pandas-1","position":0},{"hierarchy":{"lvl1":"Introduction to Pandas"},"content":"","type":"content","url":"/pandas-1","position":1},{"hierarchy":{"lvl1":"Introduction to Pandas"},"type":"lvl1","url":"/pandas-1#introduction-to-pandas","position":2},{"hierarchy":{"lvl1":"Introduction to Pandas"},"content":"\n\n","type":"content","url":"/pandas-1#introduction-to-pandas","position":3},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Overview"},"type":"lvl2","url":"/pandas-1#overview","position":4},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Overview"},"content":"Introduction to pandas data structures\n\nHow to slice and dice pandas dataframes and dataseries\n\nHow to use pandas for exploratory data analysis","type":"content","url":"/pandas-1#overview","position":5},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Prerequisites"},"type":"lvl2","url":"/pandas-1#prerequisites","position":6},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nPython Quickstart\n\nNecessary\n\nIntro to dict\n\nNumpy Basics\n\nNecessary\n\n\n\nTime to learn: 60 minutes\n\n\n\n","type":"content","url":"/pandas-1#prerequisites","position":7},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Imports"},"type":"lvl2","url":"/pandas-1#imports","position":8},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Imports"},"content":"\n\nYou will often see the nickname pd used as an abbreviation for pandas in the import statement, just like numpy is often imported as np. We also import the DATASETS class from pythia_datasets, which allows us to use example datasets created for Pythia.\n\nimport pandas as pd\nfrom pythia_datasets import DATASETS\n\n","type":"content","url":"/pandas-1#imports","position":9},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"The pandas DataFrame..."},"type":"lvl2","url":"/pandas-1#the-pandas-dataframe","position":10},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"The pandas DataFrame..."},"content":"...is a labeled, two-dimensional columnar structure, similar to a table, spreadsheet, or the R data.frame.\n\nThe columns that make up our DataFrame can be lists, dictionaries, NumPy arrays, pandas Series, or many other data types not mentioned here. Within these columns, you can have data values of many different data types used in Python and NumPy, including text, numbers, and dates/times. The first column of a DataFrame, shown in the image above in dark gray, is uniquely referred to as an index; this column contains information characterizing each row of our DataFrame. Similar to any other column, the index can label rows by text, numbers, datetime objects, and many other data types. Datetime objects are a quite popular way to label rows.\n\nFor our first example using Pandas DataFrames, we start by reading in some data in comma-separated value (.csv) format. We retrieve this dataset from the Pythia DATASETS class (imported at the top of this page); however, the dataset was originally contained within the NCDC teleconnections database. This dataset contains many types of geoscientific data, including El Nino/Southern Oscillation (ENSO) indices. See \n\nhere for more information on these indices and the underlying data.\n\nInfoAs described above, we are retrieving the datasets for these examples from Project Pythia's custom library of example data. In order to retrieve datasets from this library, you must use the statement from pythia_datasets import DATASETS. This is shown and described in the Imports section at the top of this page. The fetch() method of the DATASETS class will automatically download the data file specified as a string argument, in this case enso_data.csv, and cache the file locally, assuming the argument corresponds to a valid Pythia example dataset. This is illustrated in the following example.\n\nfilepath = DATASETS.fetch('enso_data.csv')\n\nOnce we have a valid path to a data file that Pandas knows how to read, we can open it, as shown in the following example:\n\ndf = pd.read_csv(filepath)\n\nIf we print out our DataFrame, it will render as text by default, in a tabular-style ASCII output, as shown in the following example. However, if you are using a Jupyter notebook, there exists a better way to print DataFrames, as described below.\n\nprint(df)\n\nAs described above, there is a better way to print Pandas DataFrames. If you are using a Jupyter notebook, you can run a code cell containing the DataFrame object name, by itself, and it will display a nicely rendered table, as shown below.\n\ndf\n\nThe DataFrame index, as described above, contains information characterizing rows; each row has a unique ID value, which is displayed in the index column.  By default, the IDs for rows in a DataFrame are represented as sequential integers, which start at 0.\n\ndf.index\n\nAt the moment, the index column of our DataFrame is not very helpful for humans. However, Pandas has clever ways to make index columns more human-readable. The next example demonstrates how to use optional keyword arguments to convert DataFrame index IDs to a human-friendly datetime format.\n\ndf = pd.read_csv(filepath, index_col=0, parse_dates=True)\n\ndf\n\ndf.index\n\nEach of our data rows is now helpfully labeled by a datetime-object-like index value; this means that we can now easily identify data values not only by named columns, but also by date labels on rows. This is a sneak preview of the DatetimeIndex functionality of Pandas; this functionality enables a large portion of Pandas’ timeseries-related usage. Don’t worry; DatetimeIndex will be discussed in full detail later on this page. In the meantime, let’s look at the columns of data read in from the .csv file:\n\ndf.columns\n\n","type":"content","url":"/pandas-1#the-pandas-dataframe","position":11},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"The pandas Series..."},"type":"lvl2","url":"/pandas-1#the-pandas-series","position":12},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"The pandas Series..."},"content":"...is essentially any one of the columns of our DataFrame. A Series also includes the index column from the source DataFrame, in order to provide a label for each value in the Series.\n\nThe pandas Series is a fast and capable 1-dimensional array of nearly any data type we could want, and it can behave very similarly to a NumPy ndarray or a Python dict. You can take a look at any of the Series that make up your DataFrame, either by using its column name and the Python dict notation, or by using dot-shorthand with the column name:\n\ndf[\"Nino34\"]\n\nTip: You can also use the dot notation illustrated below to specify a column name, but this syntax is mostly provided for convenience. For the most part, this notation is interchangeable with the dictionary notation; however, if the column name is not a valid Python identifier (e.g., it starts with a number or space), you cannot use dot notation.\n\ndf.Nino34\n\n","type":"content","url":"/pandas-1#the-pandas-series","position":13},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Slicing and Dicing the DataFrame and Series"},"type":"lvl2","url":"/pandas-1#slicing-and-dicing-the-dataframe-and-series","position":14},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Slicing and Dicing the DataFrame and Series"},"content":"In this section, we will expand on topics covered in the previous sections on this page. One of the most important concepts to learn about Pandas is that it allows you to access anything by its associated label, regardless of data organization structure.\n\n","type":"content","url":"/pandas-1#slicing-and-dicing-the-dataframe-and-series","position":15},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Indexing a Series","lvl2":"Slicing and Dicing the DataFrame and Series"},"type":"lvl3","url":"/pandas-1#indexing-a-series","position":16},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Indexing a Series","lvl2":"Slicing and Dicing the DataFrame and Series"},"content":"As a review of previous examples, we’ll start our next example by pulling a Series out of our DataFrame using its column label.\n\nnino34_series = df[\"Nino34\"]\n\nnino34_series\n\nYou can use syntax similar to that of NumPy ndarrays to index, select, and subset with Pandas Series, as shown in this example:\n\nnino34_series[3]\n\nYou can also use labels alongside Python dictionary syntax to perform the same operations:\n\nnino34_series[\"1982-04-01\"]\n\nYou can probably figure out some ways to extend these indexing methods, as shown in the following examples:\n\nnino34_series[0:12]\n\nInfoIndex-based slices are exclusive of the final value, similar to Python's usual indexing rules.\n\nHowever, there are many more ways to index a Series. The following example shows a powerful and useful indexing method:\n\nnino34_series[\"1982-01-01\":\"1982-12-01\"]\n\nThis is an example of label-based slicing. With label-based slicing, Pandas will automatically find a range of values based on the labels you specify.\n\nInfoAs opposed to index-based slices, label-based slices are inclusive of the final value.\n\nIf you already have some knowledge of xarray, you will quite likely know how to create slice objects by hand. This can also be used in pandas, as shown below.  If you are completely unfamiliar with xarray, it will be covered on a \n\nlater Pythia tutorial page.\n\nnino34_series[slice(\"1982-01-01\", \"1982-12-01\")]\n\n","type":"content","url":"/pandas-1#indexing-a-series","position":17},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Using .iloc and .loc to index","lvl2":"Slicing and Dicing the DataFrame and Series"},"type":"lvl3","url":"/pandas-1#using-iloc-and-loc-to-index","position":18},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Using .iloc and .loc to index","lvl2":"Slicing and Dicing the DataFrame and Series"},"content":"In this section, we introduce ways to access data that are preferred by Pandas over the methods listed above. When accessing by label, it is preferred to use the .loc method, and when accessing by index, the .iloc method is preferred. These methods behave similarly to the notation introduced above, but provide more speed, security, and rigor in your value selection. Using these methods can also help you avoid \n\nchained assignment warnings generated by pandas.\n\nnino34_series.iloc[3]\n\nnino34_series.iloc[0:12]\n\nnino34_series.loc[\"1982-04-01\"]\n\nnino34_series.loc[\"1982-01-01\":\"1982-12-01\"]\n\n","type":"content","url":"/pandas-1#using-iloc-and-loc-to-index","position":19},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Extending to the DataFrame","lvl2":"Slicing and Dicing the DataFrame and Series"},"type":"lvl3","url":"/pandas-1#extending-to-the-dataframe","position":20},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Extending to the DataFrame","lvl2":"Slicing and Dicing the DataFrame and Series"},"content":"These subsetting capabilities can also be used in a full DataFrame; however, if you use the same syntax, there are issues, as shown below:\n\ndf[\"1982-01-01\"]\n\nDangerAttempting to use Series subsetting with a DataFrame can crash your program. A proper way to subset a DataFrame is shown below.\n\nWhen indexing a DataFrame, pandas will not assume as readily the intention of your code. In this case, using a row label by itself will not work; with DataFrames, labels are used for identifying columns.\n\ndf[\"Nino34\"]\n\nAs shown below, you also cannot subset columns in a DataFrame using integer indices:\n\ndf[0]\n\nFrom earlier examples, we know that we can use an index or label with a DataFrame to pull out a column as a Series, and we know that we can use an index or label with a Series to pull out a single value.  Therefore, by chaining brackets, we can pull any individual data value out of the DataFrame.\n\ndf[\"Nino34\"][\"1982-04-01\"]\n\ndf[\"Nino34\"][3]\n\nHowever, subsetting data using this chained-bracket technique is not preferred by Pandas. As described above, Pandas prefers us to use the .loc and .iloc methods for subsetting.  In addition, these methods provide a clearer, more efficient way to extract specific data from a DataFrame, as illustrated below:\n\ndf.loc[\"1982-04-01\", \"Nino34\"]\n\nInfoWhen using this syntax to pull individual data values from a DataFrame, make sure to list the row first, and then the column.\n\nThe .loc and .iloc methods also allow us to pull entire rows out of a DataFrame, as shown in these examples:\n\ndf.loc[\"1982-04-01\"]\n\ndf.loc[\"1982-01-01\":\"1982-12-01\"]\n\ndf.iloc[3]\n\ndf.iloc[0:12]\n\nIn the next example, we illustrate how you can use slices of rows and lists of columns to create a smaller DataFrame out of an existing DataFrame:\n\ndf.loc[\n    \"1982-01-01\":\"1982-12-01\",  # slice of rows\n    [\"Nino12\", \"Nino3\", \"Nino4\", \"Nino34\"],  # list of columns\n]\n\nInfoThere are certain limitations to these subsetting techniques. For more information on these limitations, as well as a comparison of DataFrame and Series indexing methods, see the \n\nPandas indexing documentation.\n\n","type":"content","url":"/pandas-1#extending-to-the-dataframe","position":21},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Exploratory Data Analysis"},"type":"lvl2","url":"/pandas-1#exploratory-data-analysis","position":22},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Exploratory Data Analysis"},"content":"","type":"content","url":"/pandas-1#exploratory-data-analysis","position":23},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Get a Quick Look at the Beginning/End of your DataFrame","lvl2":"Exploratory Data Analysis"},"type":"lvl3","url":"/pandas-1#get-a-quick-look-at-the-beginning-end-of-your-dataframe","position":24},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Get a Quick Look at the Beginning/End of your DataFrame","lvl2":"Exploratory Data Analysis"},"content":"Pandas also gives you a few shortcuts to quickly investigate entire DataFrames. The head method shows the first five rows of a DataFrame, and the tail method shows the last five rows of a DataFrame.\n\ndf.head()\n\ndf.tail()\n\n","type":"content","url":"/pandas-1#get-a-quick-look-at-the-beginning-end-of-your-dataframe","position":25},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Quick Plots of Your Data","lvl2":"Exploratory Data Analysis"},"type":"lvl3","url":"/pandas-1#quick-plots-of-your-data","position":26},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Quick Plots of Your Data","lvl2":"Exploratory Data Analysis"},"content":"A good way to explore your data is by making a simple plot. Pandas contains its own plot method; this allows us to plot Pandas series without needing matplotlib.  In this example, we plot the Nino34 series of our df DataFrame in this way:\n\ndf.Nino34.plot();\n\nBefore, we called .plot(), which generated a single line plot. Line plots can be helpful for understanding some types of data, but there are other types of data that can be better understood with different plot types. For example, if your data values form a distribution, you can better understand them using a histogram plot.\n\nThe code for plotting histogram data differs in two ways from the code above for the line plot. First, two series are being used from the DataFrame instead of one.  Second, after calling the plot method, we call an additional method called hist, which converts the plot into a histogram.\n\ndf[['Nino12', 'Nino34']].plot.hist();\n\nThe histogram plot helped us better understand our data; there are clear differences in the distributions. To even better understand this type of data, it may also be helpful to create a box plot. This can be done using the same line of code, with one change: we call the box method instead of hist.\n\ndf[['Nino12', 'Nino34']].plot.box();\n\nJust like the histogram plot, this box plot indicates a clear difference in the distributions. Using multiple types of plot in this way can be useful for verifying large datasets. The pandas plotting methods are capable of creating many different types of plots. To see how to use the plotting methods to generate each type of plot, please review the \n\npandas plot documentation.\n\n","type":"content","url":"/pandas-1#quick-plots-of-your-data","position":27},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl4":"Customize your Plot","lvl3":"Quick Plots of Your Data","lvl2":"Exploratory Data Analysis"},"type":"lvl4","url":"/pandas-1#customize-your-plot","position":28},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl4":"Customize your Plot","lvl3":"Quick Plots of Your Data","lvl2":"Exploratory Data Analysis"},"content":"The pandas plotting methods are, in fact, wrappers for similar methods in matplotlib. This means that you can customize pandas plots by including keyword arguments to the plotting methods.  These keyword arguments, for the most part, are equivalent to their matplotlib counterparts.\n\ndf.Nino34.plot(\n    color='black',\n    linewidth=2,\n    xlabel='Year',\n    ylabel='ENSO34 Index (degC)',\n    figsize=(8, 6),\n);\n\nAlthough plotting data can provide a clear visual picture of data values, sometimes a more quantitative look at data is warranted. As elaborated on in the next section, this can be achieved using the describe method.  The describe method is called on the entire DataFrame, and returns various summarized statistics for each column in the DataFrame.","type":"content","url":"/pandas-1#customize-your-plot","position":29},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Basic Statistics","lvl2":"Exploratory Data Analysis"},"type":"lvl3","url":"/pandas-1#basic-statistics","position":30},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Basic Statistics","lvl2":"Exploratory Data Analysis"},"content":"We can garner statistics for a DataFrame by using the describe method. When this method is called on a DataFrame, a set of statistics is returned in tabular format.  The columns match those of the DataFrame, and the rows indicate different statistics, such as minimum.\n\ndf.describe()\n\nYou can also view specific statistics using corresponding methods. In this example, we look at the mean values in the entire DataFrame, using the mean method.  When such methods are called on the entire DataFrame, a Series is returned. The indices of this Series are the column names in the DataFrame, and the values are the calculated values (in this case, mean values) for the DataFrame columns.\n\ndf.mean()\n\nIf you want a specific statistic for only one column in the DataFrame, pull the column out of the DataFrame with dot notation, then call the statistic function (in this case, mean) on that column, as shown below:\n\ndf.Nino34.mean()\n\n","type":"content","url":"/pandas-1#basic-statistics","position":31},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Subsetting Using the Datetime Column","lvl2":"Exploratory Data Analysis"},"type":"lvl3","url":"/pandas-1#subsetting-using-the-datetime-column","position":32},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Subsetting Using the Datetime Column","lvl2":"Exploratory Data Analysis"},"content":"Slicing is a useful technique for subsetting a DataFrame, but there are also other options that can be equally useful. In this section, some of these additional techniques are covered.\n\nIf your DataFrame uses datetime values for indices, you can select data from only one month using df.index.month. In this example, we specify the number 1, which only selects data from January.\n\n# Uses the datetime column\ndf[df.index.month == 1]\n\nThis example shows how to create a new column containing the month portion of the datetime index for each data row. The value returned by df.index.month is used to obtain the data for this new column:\n\ndf['month'] = df.index.month\n\nThis next example illustrates how to use the new month column to calculate average monthly values over the other data columns. First, we use the groupby method to group the other columns by the month.  Second, we take the average (mean) to obtain the monthly averages. Finally, we plot the resulting data as a line plot by simply calling plot().\n\ndf.groupby('month').mean().plot();\n\n","type":"content","url":"/pandas-1#subsetting-using-the-datetime-column","position":33},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Investigating Extreme Values","lvl2":"Exploratory Data Analysis"},"type":"lvl3","url":"/pandas-1#investigating-extreme-values","position":34},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Investigating Extreme Values","lvl2":"Exploratory Data Analysis"},"content":"\n\nIf you need to search for rows that meet a specific criterion, you can use conditional indexing.  In this example, we search for rows where the Nino34 anomaly value (Nino34anom) is greater than 2:\n\ndf[df.Nino34anom > 2]\n\nThis example shows how to use the sort_values method on a DataFrame. This method sorts values in a DataFrame by the column specified as an argument.\n\ndf.sort_values('Nino34anom')\n\nYou can also reverse the ordering of the sort by specifying the ascending keyword argument as False:\n\ndf.sort_values('Nino34anom', ascending=False)\n\n","type":"content","url":"/pandas-1#investigating-extreme-values","position":35},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Resampling","lvl2":"Exploratory Data Analysis"},"type":"lvl3","url":"/pandas-1#resampling","position":36},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Resampling","lvl2":"Exploratory Data Analysis"},"content":"In these examples, we illustrate a process known as resampling. Using resampling, you can change the frequency of index data values, reducing so-called ‘noise’ in a data plot. This is especially useful when working with timeseries data; plots can be equally effective with resampled data in these cases. The resampling performed in these examples converts monthly values to yearly averages. This is performed by passing the value ‘1Y’ to the resample method.\n\ndf.Nino34.plot();\n\ndf.Nino34.resample('1Y').mean().plot();\n\n","type":"content","url":"/pandas-1#resampling","position":37},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Applying operations to a DataFrame","lvl2":"Exploratory Data Analysis"},"type":"lvl3","url":"/pandas-1#applying-operations-to-a-dataframe","position":38},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"Applying operations to a DataFrame","lvl2":"Exploratory Data Analysis"},"content":"One of the most commonly used features in Pandas is the performing of calculations to multiple data values in a DataFrame simultaneously. Let’s first look at a familiar concept: a function that converts single values.  The following example uses such a function to convert temperature values from degrees Celsius to Kelvin.\n\ndef convert_degc_to_kelvin(temperature_degc):\n    \"\"\"\n    Converts from degrees celsius to Kelvin\n    \"\"\"\n\n    return temperature_degc + 273.15\n\n# Convert a single value\nconvert_degc_to_kelvin(0)\n\nThe following examples instead illustrate a new concept: using such functions with DataFrames and Series. For the first example, we start by creating a Series; in order to do so, we subset the DataFrame by the Nino34 column. This has already been done earlier in this page; we do not need to create this Series again. We are using this particular Series for a reason: the data values are in degrees Celsius.\n\nnino34_series\n\nHere, we look at a portion of an existing DataFrame column. Notice that this column portion is a Pandas Series.\n\ntype(df.Nino12[0:10])\n\nAs shown in the following example, each Pandas Series contains a representation of its data in numpy format. Therefore, it is possible to convert a Pandas Series into a numpy array; this is done using the .values method:\n\ntype(df.Nino12.values[0:10])\n\nThis example illustrates how to use the temperature-conversion function defined above on a Series object. Just as calling the function with a single value returns a single value, calling the function on a Series object returns another Series object. The function performs the temperature conversion on each data value in the Series, and returns a Series with all values converted.\n\nconvert_degc_to_kelvin(nino34_series)\n\nIf we call the .values method on the Series passed to the function, the Series is converted to a numpy array, as described above. The function then converts each value in the numpy array, and returns a new numpy array with all values sorted.\n\nWarningIt is recommended to only convert Series to NumPy arrays when necessary; doing so removes the label information that enables much of the Pandas core functionality.\n\nconvert_degc_to_kelvin(nino34_series.values)\n\nAs described above, when our temperature-conversion function accepts a Series as an argument, it returns a Series. We can directly assign this returned Series to a new column in our DataFrame, as shown below:\n\ndf['Nino34_degK'] = convert_degc_to_kelvin(nino34_series)\n\ndf.Nino34_degK\n\nIn this final example, we demonstrate the use of the to_csv method to save a DataFrame as a .csv file. This example also demonstrates the read_csv method, which reads .csv files into Pandas DataFrames.\n\ndf.to_csv('nino_analyzed_output.csv')\n\npd.read_csv('nino_analyzed_output.csv', index_col=0, parse_dates=True)\n\n","type":"content","url":"/pandas-1#applying-operations-to-a-dataframe","position":39},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Summary"},"type":"lvl2","url":"/pandas-1#summary","position":40},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Summary"},"content":"Pandas is a very powerful tool for working with tabular (i.e., spreadsheet-style) data\n\nThere are multiple ways of subsetting your pandas dataframe or series\n\nPandas allows you to refer to subsets of data by label, which generally makes code more readable and more robust\n\nPandas can be helpful for exploratory data analysis, including plotting and basic statistics\n\nOne can apply calculations to pandas dataframes and save the output via csv files","type":"content","url":"/pandas-1#summary","position":41},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/pandas-1#whats-next","position":42},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl3":"What’s Next?","lvl2":"Summary"},"content":"In the next notebook, we will look more into using pandas for more in-depth data analysis.","type":"content","url":"/pandas-1#whats-next","position":43},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Resources and References"},"type":"lvl2","url":"/pandas-1#resources-and-references","position":44},{"hierarchy":{"lvl1":"Introduction to Pandas","lvl2":"Resources and References"},"content":"ENSO data used in this example\n\nGetting Started with Pandas\n\nPandas User Guide","type":"content","url":"/pandas-1#resources-and-references","position":45},{"hierarchy":{"lvl1":"Xarray"},"type":"lvl1","url":"/xarray","position":0},{"hierarchy":{"lvl1":"Xarray"},"content":"","type":"content","url":"/xarray","position":1},{"hierarchy":{"lvl1":"Xarray"},"type":"lvl1","url":"/xarray#xarray","position":2},{"hierarchy":{"lvl1":"Xarray"},"content":"This section contains tutorials on using \n\nXarray. Xarray is used widely in the geosciences and beyond for analysis of gridded N-dimensional datasets.\n\nFrom the \n\nXarray website:\n\nXarray (formerly Xray) is an open source project and Python package that makes working with labelled multi-dimensional arrays simple, efficient, and fun!\n\nXarray introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy-like arrays, which allows for a more intuitive, more concise, and less error-prone developer experience. The package includes a large and growing library of domain-agnostic functions for advanced analytics and visualization with these data structures.\n\nXarray is inspired by and borrows heavily from pandas, the popular data analysis package focused on labelled tabular data. It is particularly tailored to working with netCDF files, which were the source of xarray’s data model, and integrates tightly with dask for parallel computing.\n\nYou should have a basic familiarity with \n\nNumpy arrays prior to working through the Xarray notebooks presented here.","type":"content","url":"/xarray#xarray","position":3},{"hierarchy":{"lvl1":"Computations and Masks with Xarray"},"type":"lvl1","url":"/computation-masking","position":0},{"hierarchy":{"lvl1":"Computations and Masks with Xarray"},"content":"\n\n","type":"content","url":"/computation-masking","position":1},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Overview"},"type":"lvl2","url":"/computation-masking#overview","position":2},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Overview"},"content":"In this tutorial, we will cover the following topics:\n\nPerforming basic arithmetic on DataArrays and Datasets\n\nPerforming aggregation (i.e., reduction) along single or multiple dimensions of a DataArray or Dataset\n\nComputing climatologies and anomalies of data using Xarray’s “split-apply-combine” approach, via the .groupby() method\n\nPerforming weighted-reduction operations along single or multiple dimensions of a DataArray or Dataset\n\nProviding a broad overview of Xarray’s data-masking capability\n\nUsing the .where() method to mask Xarray data\n\n","type":"content","url":"/computation-masking#overview","position":3},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Prerequisites"},"type":"lvl2","url":"/computation-masking#prerequisites","position":4},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntroduction to Xarray\n\nNecessary\n\n\n\nTime to learn: 60 minutes\n\n\n\n","type":"content","url":"/computation-masking#prerequisites","position":5},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Imports"},"type":"lvl2","url":"/computation-masking#imports","position":6},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Imports"},"content":"In order to work with data and plotting, we must import NumPy, Matplotlib, and Xarray. These packages are covered in greater detail in earlier tutorials. We also import a package that allows quick download of Pythia example datasets.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport xarray as xr\nfrom pythia_datasets import DATASETS\n\n","type":"content","url":"/computation-masking#imports","position":7},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Data Setup"},"type":"lvl2","url":"/computation-masking#data-setup","position":8},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Data Setup"},"content":"The bulk of the examples in this tutorial make use of a single dataset. This dataset contains monthly sea surface temperature (SST, call ‘tos’ here) data, and is obtained from the Community Earth System Model v2 (CESM2). (For this tutorial, however, the dataset will be retrieved from the Pythia example data repository.) The following example illustrates the process of retrieving this Global Climate Model dataset:\n\nfilepath = DATASETS.fetch('CESM2_sst_data.nc')\nds = xr.open_dataset(filepath)\nds\n\n","type":"content","url":"/computation-masking#data-setup","position":9},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Arithmetic Operations"},"type":"lvl2","url":"/computation-masking#arithmetic-operations","position":10},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Arithmetic Operations"},"content":"In a similar fashion to NumPy arrays, performing an arithmetic operation on a DataArray will automatically perform the operation on all array values; this is known as vectorization. To illustrate the process of vectorization, the following example converts the air temperature data from units of degrees Celsius to units of Kelvin:\n\nds.tos + 273.15\n\nIn addition, there are many other arithmetic operations that can be performed on DataArrays. In this example, we demonstrate squaring the original Celsius values of our air temperature data:\n\nds.tos**2\n\n","type":"content","url":"/computation-masking#arithmetic-operations","position":11},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Aggregation Methods"},"type":"lvl2","url":"/computation-masking#aggregation-methods","position":12},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Aggregation Methods"},"content":"A common practice in the field of data analysis is aggregation. Aggregation is the process of reducing data through methods such as sum(), mean(), median(), min(), and max(), in order to gain greater insight into the nature of large datasets. In this set of examples, we demonstrate correct usage of a select group of aggregation methods:\n\nCompute the mean:\n\nds.tos.mean()\n\nNotice that we did not specify the dim keyword argument; this means that the function was applied over all of the dataset’s dimensions. In other words, the aggregation method computed the mean of every element of the temperature dataset across every temporal and spatial data point. However, if a dimension name is used with the dim keyword argument, the aggregation method computes an aggregation along the given dimension. In this next example, we use aggregation to calculate the temporal mean across all spatial data; this is performed by providing the dimension name 'time' to the dim keyword argument:\n\nds.tos.mean(dim='time').plot(size=7);\n\nThere are many other combinations of aggregation methods and dimensions on which to perform these methods. In this example, we compute the temporal minimum:\n\nds.tos.min(dim=['time'])\n\nThis example computes the spatial sum. Note that this dataset contains no altitude data; as such, the required spatial dimensions passed to the method consist only of latitude and longitude.\n\nds.tos.sum(dim=['lat', 'lon'])\n\nFor the last example in this set of aggregation examples, we compute the temporal median:\n\nds.tos.median(dim='time')\n\nIn addition, there are many other commonly used aggregation methods in Xarray. Some of the more popular aggregation methods are summarized in the following table:\n\nAggregation\n\nDescription\n\ncount()\n\nTotal number of items\n\nmean(), median()\n\nMean and median\n\nmin(), max()\n\nMinimum and maximum\n\nstd(), var()\n\nStandard deviation and variance\n\nprod()\n\nCompute product of elements\n\nsum()\n\nCompute sum of elements\n\nargmin(), argmax()\n\nFind index of minimum and maximum value\n\n","type":"content","url":"/computation-masking#aggregation-methods","position":13},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"GroupBy: Split, Apply, Combine"},"type":"lvl2","url":"/computation-masking#groupby-split-apply-combine","position":14},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"GroupBy: Split, Apply, Combine"},"content":"While we can obtain useful summaries of datasets using simple aggregation methods, it is more often the case that aggregation must be performed over coordinate labels or groups. In order to perform this type of aggregation, it is helpful to use the split-apply-combine workflow. Fortunately, Xarray provides this functionality for DataArrays and Datasets by means of the groupby operation. The following figure illustrates the split-apply-combine workflow in detail:\n\nBased on the above figure, you can understand the split-apply-combine process performed by groupby. In detail, the steps of this process are:\n\nThe split step involves breaking up and grouping an xarray Dataset or DataArray depending on the value of the specified group key.\n\nThe apply step involves computing some function, usually an aggregate, transformation, or filtering, within the individual groups.\n\nThe combine step merges the results of these operations into an output xarray Dataset or DataArray.\n\nIn this set of examples, we will remove the seasonal cycle (also known as a climatology) from our dataset using groupby. There are many types of input that can be provided to groupby; a full list can be found in \n\nXarray’s groupby user guide.\n\nIn this first example, we plot data to illustrate the annual cycle described above. We first select the grid point closest to a specific latitude-longitude point. Once we have this grid point, we can plot a temporal series of sea-surface temperature (SST) data at that location. Reviewing the generated plot, the annual cycle of the data becomes clear.\n\nds.tos.sel(lon=310, lat=50, method='nearest').plot();\n\n","type":"content","url":"/computation-masking#groupby-split-apply-combine","position":15},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl3":"Split","lvl2":"GroupBy: Split, Apply, Combine"},"type":"lvl3","url":"/computation-masking#split","position":16},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl3":"Split","lvl2":"GroupBy: Split, Apply, Combine"},"content":"The first step of the split-apply-combine process is splitting. As described above, this step involves splitting a dataset into groups, with each group matching a group key. In this example, we split the SST data using months as a group key. Therefore, there is one resulting group for January data, one for February data, etc. This code illustrates how to perform such a split:\n\nds.tos.groupby(ds.time.dt.month)\n\nInfo\n\nIn the above code example, we are extracting components of date/time data by way of the time coordinate’s .dt attribute. This attribute is a DatetimeAccessor object that contains additional attributes for units of time, such as hour, day, and year. Since we are splitting the data into monthly data, we use the month attribute of .dt in this example. (In addition, there exists similar functionality in Pandas; see the \n\nofficial documentation for details.)\n\nIn addition, there is a more concise syntax that can be used in specific instances. This syntax can be used if the variable on which the grouping is performed is already present in the dataset. The following example illustrates this syntax; it is functionally equivalent to the syntax used in the above example.\n\nds.tos.groupby('time.month')\n\n","type":"content","url":"/computation-masking#split","position":17},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl3":"Apply & Combine","lvl2":"GroupBy: Split, Apply, Combine"},"type":"lvl3","url":"/computation-masking#apply-combine","position":18},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl3":"Apply & Combine","lvl2":"GroupBy: Split, Apply, Combine"},"content":"Now that we have split our data into groups, the next step is to apply a calculation to the groups. There are two types of calculation that can be applied:\n\naggregation: reduces the size of the group\n\ntransformation: preserves the group’s full size\n\nAfter a calculation is applied to the groups, Xarray will automatically combine the groups back into a single object, completing the split-apply-combine workflow.","type":"content","url":"/computation-masking#apply-combine","position":19},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl4":"Compute climatology","lvl3":"Apply & Combine","lvl2":"GroupBy: Split, Apply, Combine"},"type":"lvl4","url":"/computation-masking#compute-climatology","position":20},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl4":"Compute climatology","lvl3":"Apply & Combine","lvl2":"GroupBy: Split, Apply, Combine"},"content":"In this example, we use the split-apply-combine workflow to calculate the monthly climatology at every point in the dataset. Notice that we are using the month DatetimeAccessor, as described above, as well as the .mean() aggregation function:\n\ntos_clim = ds.tos.groupby('time.month').mean()\ntos_clim\n\nNow that we have a DataArray containing the climatology data, we can plot the data in different ways. In this example, we plot the climatology at a specific latitude-longitude point:\n\ntos_clim.sel(lon=310, lat=50, method='nearest').plot();\n\nIn this example, we plot the zonal mean climatology:\n\ntos_clim.mean(dim='lon').transpose().plot.contourf(levels=12, cmap='turbo');\n\nFinally, this example calculates and plots the difference between the climatology for January and the climatology for December:\n\n(tos_clim.sel(month=1) - tos_clim.sel(month=12)).plot(size=6, robust=True);\n\n","type":"content","url":"/computation-masking#compute-climatology","position":21},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl4":"Compute anomaly","lvl3":"Apply & Combine","lvl2":"GroupBy: Split, Apply, Combine"},"type":"lvl4","url":"/computation-masking#compute-anomaly","position":22},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl4":"Compute anomaly","lvl3":"Apply & Combine","lvl2":"GroupBy: Split, Apply, Combine"},"content":"In this example, we compute the anomaly of the original data by removing the climatology from the data values. As shown in previous examples, the climatology is first calculated. The calculated climatology is then removed from the data using arithmetic and Xarray’s groupby method:\n\ngb = ds.tos.groupby('time.month')\ntos_anom = gb - gb.mean(dim='time')\ntos_anom\n\ntos_anom.sel(lon=310, lat=50, method='nearest').plot();\n\nIn this example, we compute and plot our dataset’s mean global anomaly over time. In order to specify global data, we must provide both lat and lon to the mean() method’s dim keyword argument:\n\nunweighted_mean_global_anom = tos_anom.mean(dim=['lat', 'lon'])\nunweighted_mean_global_anom.plot();\n\nInfo\n\nMany geoscientific algorithms perform operations over data contained in many different grid cells. However, if the grid cells are not equivalent in size, the operation is not scientifically valid by default. Fortunately, this can be fixed by weighting the data in each grid cell by the size of the cell. Weighting data in Xarray is simple, as Xarray has a built-in weighting method, known as \n\n.weighted().\n\nIn this example, we again make use of the Pythia example data library to load a new CESM2 dataset. Contained in this dataset are weights corresponding to the grid cells in our anomaly data:\n\nfilepath2 = DATASETS.fetch('CESM2_grid_variables.nc')\nareacello = xr.open_dataset(filepath2).areacello\nareacello\n\nIn a similar fashion to a previous example, this example calculates mean global anomaly. However, this example makes use of the .weighted() method and the newly loaded CESM2 dataset to weight the grid cell data as described above:\n\nweighted_mean_global_anom = tos_anom.weighted(areacello).mean(dim=['lat', 'lon'])\n\nThis example plots both unweighted and weighted mean data, which illustrates the degree of scientific error with unweighted data:\n\nunweighted_mean_global_anom.plot(size=7)\nweighted_mean_global_anom.plot()\nplt.legend(['unweighted', 'weighted']);\n\n","type":"content","url":"/computation-masking#compute-anomaly","position":23},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Other high level computation functionality"},"type":"lvl2","url":"/computation-masking#other-high-level-computation-functionality","position":24},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Other high level computation functionality"},"content":"resample: \n\nThis method behaves similarly to groupby, but is specialized for time dimensions, and can perform temporal upsampling and downsampling.\n\nrolling: \n\nThis method is used to compute aggregation functions, such as mean, on moving windows of data in a dataset.\n\ncoarsen: \n\nThis method provides generic functionality for performing downsampling operations on various types of data.\n\nThis example illustrates the resampling of a dataset’s time dimension to annual frequency:\n\nr = ds.tos.resample(time='AS')\nr\n\nr.mean()\n\nThis example illustrates using the rolling method to compute averages in a moving window of 5 months of data:\n\nm_avg = ds.tos.rolling(time=5, center=True).mean()\nm_avg\n\nlat = 50\nlon = 310\n\nm_avg.isel(lat=lat, lon=lon).plot(size=6)\nds.tos.isel(lat=lat, lon=lon).plot()\nplt.legend(['5-month moving average', 'monthly data']);\n\n","type":"content","url":"/computation-masking#other-high-level-computation-functionality","position":25},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Masking Data"},"type":"lvl2","url":"/computation-masking#masking-data","position":26},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Masking Data"},"content":"\n\nMasking of data can be performed in Xarray by providing single or multiple conditions to either Xarray’s .where() method or a Dataset or DataArray’s .where() method. Data values matching the condition(s) are converted into a single example value, effectively masking them from the scientifically important data. In the following set of examples, we use the .where() method to mask various data values in the tos DataArray.\n\nFor reference, we will first print our entire sea-surface temperature (SST) dataset:\n\nds\n\n","type":"content","url":"/computation-masking#masking-data","position":27},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl3":"Using where with one condition","lvl2":"Masking Data"},"type":"lvl3","url":"/computation-masking#using-where-with-one-condition","position":28},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl3":"Using where with one condition","lvl2":"Masking Data"},"content":"\n\nIn this set of examples, we are trying to analyze data at the last temporal value in the dataset. This first example illustrates the use of .isel() to perform this analysis:\n\nsample = ds.tos.isel(time=-1)\nsample\n\nAs shown in the previous example, methods like .isel() and .sel() return data of a different shape than the original data provided to them. However, .where() preserves the shape of the original data by masking the values with a Boolean condition. Data values for which the condition is True are returned identical to the values passed in. On the other hand, data values for which the condition is False are returned as a preset example value. (This example value defaults to nan, but can be set to other values as well.)\n\nBefore testing .where(), it is helpful to look at the \n\nofficial documentation. As stated above, the .where() method takes a Boolean condition. (Boolean conditions use operators such as less-than, greater-than, and equal-to, and return a value of True or False.) Most uses of .where() check whether or not specific data values are less than or greater than a constant value. As stated in the documentation, the data values specified in the Boolean condition of .where() can be any of the following:\n\na DataArray\n\na Dataset\n\na function\n\nIn the following example, we make use of .where() to mask data with temperature values greater than 0. Therefore, values greater than 0 are set to nan, as described above. (It is important to note that the Boolean condition matches values to keep, not values to mask out.)\n\nmasked_sample = sample.where(sample < 0.0)\nmasked_sample\n\nIn this example, we use Matplotlib to plot the original, unmasked data, as well as the masked data created in the previous example.\n\nfig, axes = plt.subplots(ncols=2, figsize=(19, 6))\nsample.plot(ax=axes[0])\nmasked_sample.plot(ax=axes[1]);\n\n","type":"content","url":"/computation-masking#using-where-with-one-condition","position":29},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl3":"Using where with multiple conditions","lvl2":"Masking Data"},"type":"lvl3","url":"/computation-masking#using-where-with-multiple-conditions","position":30},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl3":"Using where with multiple conditions","lvl2":"Masking Data"},"content":"\n\nThose familiar with Boolean conditions know that such conditions can be combined by using logical operators. In the case of .where(), the relevant logical operators are bitwise or exclusive 'and' (represented by the & symbol) and bitwise or exclusive ‘or’ (represented by the | symbol). This allows multiple masking conditions to be specified in a single use of .where(); however, be aware that if multiple conditions are specified in this way, each simple Boolean condition must be enclosed in parentheses. (If you are not familiar with Boolean conditions, or this section is confusing in any way, please review a detailed Boolean expression guide before continuing with the tutorial.) In this example, we provide multiple conditions to .where() using a more complex Boolean condition. This allows us to mask locations with temperature values less than 25, as well as locations with temperature values greater than 30. (As stated above, the Boolean condition matches values to keep, and everything else is masked out. Because we are now using more complex Boolean conditions, understanding the following example may be difficult. Please review a Boolean condition guide if needed.)\n\nsample.where((sample > 25) & (sample < 30)).plot(size=6);\n\nIn addition to using DataArrays and Datasets in Boolean conditions provided to .where(), we can also use coordinate variables. In the following example, we make use of Boolean conditions containing latitude and longitude coordinates. This greatly simplifies the masking of regions outside of the \n\nNiño 3.4 region:\n\nsample.where(\n    (sample.lat < 5) & (sample.lat > -5) & (sample.lon > 190) & (sample.lon < 240)\n).plot(size=6);\n\n","type":"content","url":"/computation-masking#using-where-with-multiple-conditions","position":31},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl3":"Using where with a custom fill value","lvl2":"Masking Data"},"type":"lvl3","url":"/computation-masking#using-where-with-a-custom-fill-value","position":32},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl3":"Using where with a custom fill value","lvl2":"Masking Data"},"content":"\n\nIn the previous examples that make use of .where(), the masked data values are set to nan. However, this behavior can be modified by providing a second value, in numeric form, to .where(); if this numeric value is provided, it will be used instead of nan for masked data values. In this example, masked data values are set to 0 by providing a second value of 0 to the .where() method:\n\nsample.where((sample > 25) & (sample < 30), 0).plot(size=6);\n\n\n\n","type":"content","url":"/computation-masking#using-where-with-a-custom-fill-value","position":33},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Summary"},"type":"lvl2","url":"/computation-masking#summary","position":34},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Summary"},"content":"In a similar manner to NumPy arrays, performing arithmetic on a DataArray affects all values simultaneously.\n\nXarray allows for simple data aggregation, over single or multiple dimensions, by way of built-in methods such as sum() and mean().\n\nXarray supports the useful split-apply-combine workflow through the groupby method.\n\nXarray allows replacing (masking) of data matching specific Boolean conditions by means of the .where() method.","type":"content","url":"/computation-masking#summary","position":35},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/computation-masking#whats-next","position":36},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl3":"What’s next?","lvl2":"Summary"},"content":"The next tutorial illustrates the use of previously covered Xarray concepts in a geoscientifically relevant example: plotting the \n\nNiño 3.4 Index.\n\n","type":"content","url":"/computation-masking#whats-next","position":37},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Resources and References"},"type":"lvl2","url":"/computation-masking#resources-and-references","position":38},{"hierarchy":{"lvl1":"Computations and Masks with Xarray","lvl2":"Resources and References"},"content":"groupby: \n\nUseful for binning/grouping data and applying reductions and/or transformations on those groups\n\nresample: \n\nFunctionality similar to groupby, specialized for time dimensions. Can be used for temporal upsampling and downsampling\n\nrolling: \n\nUseful for computing aggregations on moving windows of your dataset, e.g., computing moving averages\n\ncoarsen: \n\nGeneric functionality for downsampling data\n\nweighted: \n\nUseful for weighting data before applying reductions\n\nMore xarray tutorials and videos\n\nXarray Documentation - Masking with where()","type":"content","url":"/computation-masking#resources-and-references","position":39},{"hierarchy":{"lvl1":"Dask Arrays with Xarray"},"type":"lvl1","url":"/dask-arrays-xarray","position":0},{"hierarchy":{"lvl1":"Dask Arrays with Xarray"},"content":"\n\n","type":"content","url":"/dask-arrays-xarray","position":1},{"hierarchy":{"lvl1":"Dask Arrays with Xarray"},"type":"lvl1","url":"/dask-arrays-xarray#dask-arrays-with-xarray","position":2},{"hierarchy":{"lvl1":"Dask Arrays with Xarray"},"content":"The scientific Python package known as Dask provides Dask Arrays: parallel, larger-than-memory, n-dimensional arrays that make use of blocked algorithms. They are analogous to Numpy arrays, but are distributed. These terms are defined below:\n\nParallel code uses many or all of the cores on the computer running the code.\n\nLarger-than-memory refers to algorithms that break up data arrays into small pieces, operate on these pieces in an optimized fashion, and stream data from a storage device. This allows a user or programmer to work with datasets of a size larger than the available memory.\n\nA blocked algorithm speeds up large computations by converting them into a series of smaller computations.\n\nIn this tutorial, we cover the use of Xarray to wrap Dask arrays. By using Dask arrays instead of Numpy arrays in Xarray data objects, it becomes possible to execute analysis code in parallel with much less code and effort.","type":"content","url":"/dask-arrays-xarray#dask-arrays-with-xarray","position":3},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Learning Objectives"},"type":"lvl2","url":"/dask-arrays-xarray#learning-objectives","position":4},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Learning Objectives"},"content":"Learn the distinction between eager and lazy execution, and performing both types of execution with Xarray\n\nUnderstand key features of Dask Arrays\n\nLearn to perform operations with Dask Arrays in similar ways to performing operations with NumPy arrays\n\nUnderstand the use of Xarray DataArrays and Datasets as “Dask collections”, and the use of top-level Dask functions such as dask.visualize() on such collections\n\nUnderstand the ability to use Dask transparently in all built-in Xarray operations","type":"content","url":"/dask-arrays-xarray#learning-objectives","position":5},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Prerequisites"},"type":"lvl2","url":"/dask-arrays-xarray#prerequisites","position":6},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntroduction to NumPy\n\nNecessary\n\nFamiliarity with Data Arrays\n\nIntroduction to Xarray\n\nNecessary\n\nFamiliarity with Xarray Data Structures\n\nTime to learn: 30-40 minutes\n\n","type":"content","url":"/dask-arrays-xarray#prerequisites","position":7},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Imports"},"type":"lvl2","url":"/dask-arrays-xarray#imports","position":8},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Imports"},"content":"For this tutorial, as we are working with Dask, there are a number of Dask packages that must be imported. Also, this is technically an Xarray tutorial, so Xarray and NumPy must also be imported. Finally, the Pythia datasets package is imported, allowing access to the Project Pythia example data library.\n\nimport dask\nimport dask.array as da\nimport numpy as np\nimport xarray as xr\nfrom dask.diagnostics import ProgressBar\nfrom dask.utils import format_bytes\nfrom pythia_datasets import DATASETS\n\n","type":"content","url":"/dask-arrays-xarray#imports","position":9},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Blocked algorithms"},"type":"lvl2","url":"/dask-arrays-xarray#blocked-algorithms","position":10},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Blocked algorithms"},"content":"As described above, the definition of “blocked algorithm” is an algorithm that replaces a large operation with many small operations. In the case of datasets, this means that a blocked algorithm separates a dataset into chunks, and performs an operation on each.\n\nAs an example of how blocked algorithms work, consider a dataset containing a billion numbers, and assume that the sum of the numbers is needed. Using a non-blocked algorithm, all of the numbers are added in one operation, which is extremely inefficient. However, by using a blocked algorithm, the dataset is broken into chunks. (For the purposes of this example, assume that 1,000 chunks are created, with 1,000,000 numbers each.) The sum of the numbers in each chunk is taken, most likely in parallel, and then each of those sums are summed to obtain the final result.\n\nBy using blocked algorithms, we achieve the result, in this case one sum of one billion numbers, through the results of many smaller operations, in this case one thousand sums of one million numbers each. (Also note that each of the one thousand sums must then be summed, making the total number of sums 1,001.) This allows for a much greater degree of parallelism, potentially speeding up the code execution dramatically.\n\n","type":"content","url":"/dask-arrays-xarray#blocked-algorithms","position":11},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"dask.array contains these algorithms","lvl2":"Blocked algorithms"},"type":"lvl3","url":"/dask-arrays-xarray#dask-array-contains-these-algorithms","position":12},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"dask.array contains these algorithms","lvl2":"Blocked algorithms"},"content":"The main object type used in Dask is dask.array, which implements a subset of the ndarray (NumPy array) interface. However, unlike ndarray, dask.array uses blocked algorithms, which break up the array into smaller arrays, as described above. This allows for the execution of computations on arrays larger than memory, by using parallelism to divide the computation among multiple cores. Dask manages and coordinates blocked algorithms for any given computation by using Dask graphs, which lay out in detail the steps Dask takes to solve a problem. In addition, dask.array objects, known as Dask Arrays, are lazy; in other words, any computation performed on them is delayed until a specific method is called.\n\n","type":"content","url":"/dask-arrays-xarray#dask-array-contains-these-algorithms","position":13},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Create a dask.array object","lvl2":"Blocked algorithms"},"type":"lvl3","url":"/dask-arrays-xarray#create-a-dask-array-object","position":14},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Create a dask.array object","lvl2":"Blocked algorithms"},"content":"As stated earlier, Dask Arrays are loosely based on NumPy arrays. In the next set of examples, we illustrate the main differences between Dask Arrays and NumPy arrays. In order to illustrate the differences, we must have both a Dask Array object and a NumPy array object. Therefore, this first example creates a 3-D NumPy array of random data:\n\nshape = (600, 200, 200)\narr = np.random.random(shape)\narr\n\nformat_bytes(arr.nbytes)\n\nAs shown above, this NumPy array contains about 183 MB of data.\n\nAs stated above, we must also create a Dask Array. This next example creates a Dask Array with the same dimension sizes as the existing NumPy array:\n\ndarr = da.random.random(shape, chunks=(300, 100, 200))\n\nBy specifying values to the chunks keyword argument, we can specify the array pieces that Dask’s blocked algorithms break the array into; in this case, we specify (300, 100, 200).\n\nSpecifying Chunks\n\nIn this tutorial, we specify Dask Array chunks in a block shape. However, there are many additional ways to specify chunks; see \n\nthis documentation for more details.\n\nIf you are viewing this page as a Jupyter Notebook, the next Jupyter cell will produce a rich information graphic giving in-depth details about the array and each individual chunk.\n\ndarr\n\nThe above graphic contains a symbolic representation of the array, including shape, dtype, and chunksize. (Your view may be different, depending on how you are accessing this page.) Notice that there is no data shown for this array; this is because Dask Arrays are lazy, as described above. Before we call a compute method for this array, we first illustrate the structure of a Dask graph. In this example, we show the Dask graph by calling .visualize() on the array:\n\ndarr.visualize()\n\nAs shown in the above Dask graph, our array has four chunks, each one created by a call to NumPy’s “random” method (np.random.random). These chunks are concatenated into a single array after the calculation is performed.\n\n","type":"content","url":"/dask-arrays-xarray#create-a-dask-array-object","position":15},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Manipulate a dask.array object as you would a numpy array","lvl2":"Blocked algorithms"},"type":"lvl3","url":"/dask-arrays-xarray#manipulate-a-dask-array-object-as-you-would-a-numpy-array","position":16},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Manipulate a dask.array object as you would a numpy array","lvl2":"Blocked algorithms"},"content":"We can perform computations on the Dask Array created above in a similar fashion to NumPy arrays. These computations include arithmetic, slicing, and reductions, among others.\n\nAlthough the code for performing these computations is similar between NumPy arrays and Dask Arrays, the process by which they are performed is quite different. For example, it is possible to call sum() on both a NumPy array and a Dask Array; however, these two sum() calls are definitely not the same, as shown below.","type":"content","url":"/dask-arrays-xarray#manipulate-a-dask-array-object-as-you-would-a-numpy-array","position":17},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl4":"What’s the difference?","lvl3":"Manipulate a dask.array object as you would a numpy array","lvl2":"Blocked algorithms"},"type":"lvl4","url":"/dask-arrays-xarray#whats-the-difference","position":18},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl4":"What’s the difference?","lvl3":"Manipulate a dask.array object as you would a numpy array","lvl2":"Blocked algorithms"},"content":"When sum() is called on a Dask Array, the computation is not performed; instead, an expression of the computation is built. The sum() computation, as well as any other computation methods called on the same Dask Array, are not performed until a specific method (known as a compute method) is called on the array. (This is known as lazy execution.) On the other hand, calling sum() on a NumPy array performs the calculation immediately; this is known as eager execution.","type":"content","url":"/dask-arrays-xarray#whats-the-difference","position":19},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl4":"Why the difference?","lvl3":"Manipulate a dask.array object as you would a numpy array","lvl2":"Blocked algorithms"},"type":"lvl4","url":"/dask-arrays-xarray#why-the-difference","position":20},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl4":"Why the difference?","lvl3":"Manipulate a dask.array object as you would a numpy array","lvl2":"Blocked algorithms"},"content":"As described earlier, a Dask Array is divided into chunks. Any computations run on the Dask Array run on each chunk individually. If the result of the computation is obtained before the computation runs through all of the chunks, Dask can stop the computation to save CPU time and memory resources.\n\nThis example illustrates calling sum() on a Dask Array; it also includes a demonstration of lazy execution, as well as another Dask graph display:\n\ntotal = darr.sum()\ntotal\n\ntotal.visualize()\n\n","type":"content","url":"/dask-arrays-xarray#why-the-difference","position":21},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl4":"Compute the result","lvl3":"Manipulate a dask.array object as you would a numpy array","lvl2":"Blocked algorithms"},"type":"lvl4","url":"/dask-arrays-xarray#compute-the-result","position":22},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl4":"Compute the result","lvl3":"Manipulate a dask.array object as you would a numpy array","lvl2":"Blocked algorithms"},"content":"As described above, Dask Array objects make use of lazy execution. Therefore, operations performed on a Dask Array wait to execute until a compute method is called. As more operations are queued in this way, the Dask Array’s Dask graph increases in complexity, reflecting the steps Dask will take to perform all of the queued operations.\n\nIn this example, we call a compute method, simply called .compute(), to run on the Dask Array all of the stored computations:\n\n%%time\ntotal.compute()\n\n","type":"content","url":"/dask-arrays-xarray#compute-the-result","position":23},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Exercise with dask.arrays","lvl2":"Blocked algorithms"},"type":"lvl3","url":"/dask-arrays-xarray#exercise-with-dask-arrays","position":24},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Exercise with dask.arrays","lvl2":"Blocked algorithms"},"content":"In this section of the page, the examples are hands-on exercises pertaining to Dask Arrays. If these exercises are not interesting to you, this section can be used strictly as examples regardless of how the page is viewed. However, if you wish to participate in the exercises, make sure that you are viewing this page as a Jupyter Notebook.\n\nFor the first exercise, modify the chunk size or shape of the Dask Array created earlier. Call .sum() on the modified Dask Array, and visualize the Dask graph to view the changes.\n\nda.random.random(shape, chunks=(50, 200, 400)).sum().visualize()\n\nAs is obvious from the above exercise, Dask quickly and easily determines a strategy for performing the operations, in this case a sum. This illustrates the appeal of Dask: automatic algorithm generation that scales from simple arithmetic problems to highly complex scientific equations with large datasets and multiple operations.\n\nIn this next set of examples, we demonstrate that increasing the complexity of the operations performed also increases the complexity of the Dask graph.\n\nIn this example, we use randomly selected functions, arguments and Python slices to create a complex set of operations. We then visualize the Dask graph to illustrate the increased complexity:\n\nz = darr.dot(darr.T).mean(axis=0)[::2, :].std(axis=1)\nz\n\nz.visualize()\n\n","type":"content","url":"/dask-arrays-xarray#exercise-with-dask-arrays","position":25},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Testing a bigger calculation","lvl2":"Blocked algorithms"},"type":"lvl3","url":"/dask-arrays-xarray#testing-a-bigger-calculation","position":26},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Testing a bigger calculation","lvl2":"Blocked algorithms"},"content":"While the earlier examples in this tutorial described well the basics of Dask, the size of the data in those examples, about 180 MB, is far too small for an actual use of Dask.\n\nIn this example, we create a much larger array, more indicative of data actually used in Dask:\n\ndarr = da.random.random((4000, 100, 4000), chunks=(1000, 100, 500)).astype('float32')\ndarr\n\nThe dataset created in the previous example is much larger, approximately 6 GB. Depending on how many programs are running on your computer, this may be greater than the amount of free RAM on your computer. However, as Dask is larger-than-memory, the amount of free RAM does not impede Dask’s ability to work on this dataset.\n\nIn this example, we again perform randomly selected operations, but this time on the much larger dataset. We also visualize the Dask graph, and then run the compute method. However, as computing complex functions on large datasets is inherently time-consuming, we show a progress bar to track the progress of the computation.\n\nz = (darr + darr.T)[::2, :].mean(axis=2)\n\nz.visualize()\n\nwith ProgressBar():\n    computed_ds = z.compute()\n\n","type":"content","url":"/dask-arrays-xarray#testing-a-bigger-calculation","position":27},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Dask Arrays with Xarray"},"type":"lvl2","url":"/dask-arrays-xarray#dask-arrays-with-xarray-1","position":28},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Dask Arrays with Xarray"},"content":"While directly interacting with Dask Arrays can be useful on occasion, more often than not Dask Arrays are interacted with through \n\nXarray. Since Xarray wraps NumPy arrays, and Dask Arrays contain most of the functionality of NumPy arrays, Xarray can also wrap Dask Arrays, allowing anyone with knowledge of Xarray to easily start using the Dask interface.\n\n","type":"content","url":"/dask-arrays-xarray#dask-arrays-with-xarray-1","position":29},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Reading data with Dask and Xarray","lvl2":"Dask Arrays with Xarray"},"type":"lvl3","url":"/dask-arrays-xarray#reading-data-with-dask-and-xarray","position":30},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Reading data with Dask and Xarray","lvl2":"Dask Arrays with Xarray"},"content":"As demonstrated in previous examples, a Dask Array consists of many smaller arrays, called chunks:\n\ndarr\n\nAs shown in the following example, to read data into Xarray as Dask Arrays, simply specify the chunks keyword argument when calling the open_dataset() function:\n\nds = xr.open_dataset(DATASETS.fetch('CESM2_sst_data.nc'), chunks={})\nds.tos\n\nWhile it is a valid operation to pass an empty list to the chunks keyword argument, this technique does not specify how to chunk the data, and therefore the resulting Dask Array contains only one chunk.\n\nCorrect usage of the chunks keyword argument specifies how many values in each dimension are contained in a single chunk. In this example, specifying the chunks keyword argument as chunks={'time':90} indicates to Xarray and Dask that 90 time slices are allocated to each chunk on the temporal axis.\n\nSince this dataset contains 180 total time slices, the data variable tos (holding the sea surface temperature data) is now split into two chunks in the temporal dimension.\n\nds = xr.open_dataset(\n    DATASETS.fetch('CESM2_sst_data.nc'),\n    engine=\"netcdf4\",\n    chunks={\"time\": 90, \"lat\": 180, \"lon\": 360},\n)\nds.tos\n\nIt is fairly straightforward to retrieve a list of the chunks and their sizes for each dimension; simply call the .chunks method on an Xarray DataArray. In this example, we show that the tos DataArray now contains two chunks on the time dimension, with each chunk containing 90 time slices.\n\nds.tos.chunks\n\n","type":"content","url":"/dask-arrays-xarray#reading-data-with-dask-and-xarray","position":31},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Xarray data structures are first-class dask collections","lvl2":"Dask Arrays with Xarray"},"type":"lvl3","url":"/dask-arrays-xarray#xarray-data-structures-are-first-class-dask-collections","position":32},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Xarray data structures are first-class dask collections","lvl2":"Dask Arrays with Xarray"},"content":"If an Xarray Dataset or DataArray object uses a Dask Array, rather than a NumPy array, it counts as a first-class Dask collection. This means that you can pass such an object to dask.visualize() and dask.compute(), in the same way as an individual Dask Array.\n\nIn this example, we call dask.visualize on our Xarray DataArray, displaying a Dask graph for the DataArray object:\n\ndask.visualize(ds)\n\n","type":"content","url":"/dask-arrays-xarray#xarray-data-structures-are-first-class-dask-collections","position":33},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Parallel and lazy computation using dask.array with Xarray","lvl2":"Dask Arrays with Xarray"},"type":"lvl3","url":"/dask-arrays-xarray#parallel-and-lazy-computation-using-dask-array-with-xarray","position":34},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Parallel and lazy computation using dask.array with Xarray","lvl2":"Dask Arrays with Xarray"},"content":"As described above, Xarray Datasets and DataArrays containing Dask Arrays are first-class Dask collections. Therefore, computations performed on such objects are deferred until a compute method is called. (This is the definition of lazy computation.)\n\nz = ds.tos.mean(['lat', 'lon']).dot(ds.tos.T)\nz\n\nAs shown in the above example, the result of the applied operations is an Xarray DataArray that contains a Dask Array, an identical object type to the object that the operations were performed on. This is true for any operations that can be applied to Xarray DataArrays, including subsetting operations; this next example illustrates this:\n\nz.isel(lat=0)\n\nBecause the data subset created above is also a first-class Dask collection, we can view its Dask graph using the dask.visualize() function, as shown in this example:\n\ndask.visualize(z)\n\nSince this object is a first-class Dask collection, the computations performed on it have been deferred. To run these computations, we must call a compute method, in this case .compute(). This example also uses a progress bar to track the computation progress.\n\nwith ProgressBar():\n    computed_ds = z.compute()\n\n\n\n","type":"content","url":"/dask-arrays-xarray#parallel-and-lazy-computation-using-dask-array-with-xarray","position":35},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Summary"},"type":"lvl2","url":"/dask-arrays-xarray#summary","position":36},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Summary"},"content":"This tutorial covered the use of Xarray to access Dask Arrays, and the use of the chunks keyword argument to open datasets with Dask data instead of NumPy data. Another important concept introduced in this tutorial is the usage of Xarray Datasets and DataArrays as Dask collections, allowing Xarray objects to be manipulated in a similar manner to Dask Arrays. Finally, the concepts of larger-than-memory datasets, lazy computation, and parallel computation, and how they relate to Xarray and Dask, were covered.","type":"content","url":"/dask-arrays-xarray#summary","position":37},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Dask Shortcomings","lvl2":"Summary"},"type":"lvl3","url":"/dask-arrays-xarray#dask-shortcomings","position":38},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl3":"Dask Shortcomings","lvl2":"Summary"},"content":"Although Dask Arrays and NumPy arrays are generally interchangeable, NumPy offers some functionality that is lacking in Dask Arrays. The usage of Dask Array comes with the following relevant issues:\n\nOperations where the resulting shape depends on the array values can produce erratic behavior, or fail altogether, when used on a Dask Array. If the operation succeeds, the resulting Dask Array will have unknown chunk sizes, which can cause other sections of code to fail.\n\nOperations that are by nature difficult to parallelize or less useful on very large datasets, such as sort, are not included in the Dask Array interface. Some of these operations have supported versions that are inherently more intuitive to parallelize, such as \n\ntopk.\n\nDevelopment of new Dask functionality is only initiated when such functionality is required; therefore, some lesser-used NumPy functions, such as np.sometrue, are not yet implemented in Dask. However, many of these functions can be added as community contributions, or have already been added in this manner.","type":"content","url":"/dask-arrays-xarray#dask-shortcomings","position":39},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Learn More"},"type":"lvl2","url":"/dask-arrays-xarray#learn-more","position":40},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Learn More"},"content":"For more in-depth information on Dask Arrays, visit the \n\nofficial documentation page. In addition, \n\nthis screencast reinforces the concepts covered in this tutorial. (If you are viewing this page as a Jupyter Notebook, the screencast will appear below as an embedded YouTube video.)\n\nfrom IPython.display import YouTubeVideo\n\nYouTubeVideo(id=\"9h_61hXCDuI\", width=600, height=300)\n\n","type":"content","url":"/dask-arrays-xarray#learn-more","position":41},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Resources and references"},"type":"lvl2","url":"/dask-arrays-xarray#resources-and-references","position":42},{"hierarchy":{"lvl1":"Dask Arrays with Xarray","lvl2":"Resources and references"},"content":"To find specific reference information about Dask and Xarray, see the official documentation pages listed below:\n\nDask Docs\n\nDask Examples\n\nDask Code\n\nDask Blog\n\nXarray Docs\n\nIf you require assistance with a specific issue involving Xarray or Dask, the following resources may be of use:\n\nDask tag on StackOverflow, for usage questions\n\ngithub discussions: dask for general, non-bug, discussion, and usage questions\n\ngithub issues: dask for bug reports and feature requests\n\ngithub discussions: xarray for general, non-bug, discussion, and usage questions\n\ngithub issues: xarray for bug reports and feature requests\n\nCertain sections of this tutorial are adapted from the following existing tutorials:\n\nDask Array Tutorial\n\nParallel Computing with Xarray and Dask","type":"content","url":"/dask-arrays-xarray#resources-and-references","position":43},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray"},"type":"lvl1","url":"/enso-xarray","position":0},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray"},"content":"\n\n","type":"content","url":"/enso-xarray","position":1},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Overview"},"type":"lvl2","url":"/enso-xarray#overview","position":2},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Overview"},"content":"In this tutorial, we perform and demonstrate the following tasks:\n\nLoad SST data from the CESM2 model\n\nMask data using .where()\n\nCompute climatologies and anomalies using .groupby()\n\nUse .rolling() to compute moving average\n\nCompute, normalize, and plot the Niño 3.4 Index\n\n","type":"content","url":"/enso-xarray#overview","position":3},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Prerequisites"},"type":"lvl2","url":"/enso-xarray#prerequisites","position":4},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntroduction to Xarray\n\nNecessary\n\n\n\nComputation and Masking\n\nNecessary\n\n\n\nTime to learn: 20 minutes\n\n\n\n","type":"content","url":"/enso-xarray#prerequisites","position":5},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Imports"},"type":"lvl2","url":"/enso-xarray#imports","position":6},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Imports"},"content":"For this tutorial, we import several Python packages. As plotting ENSO data requires a geographically accurate map, Cartopy is imported to handle geographic features and map projections. Xarray is used to manage raw data, and Matplotlib allows for feature-rich data plotting. Finally, a custom Pythia package is imported, in this case allowing access to the Pythia example data library.\n\nimport cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\nimport xarray as xr\nfrom pythia_datasets import DATASETS\n\n","type":"content","url":"/enso-xarray#imports","position":7},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"The Niño 3.4 Index"},"type":"lvl2","url":"/enso-xarray#the-ni-o-3-4-index","position":8},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"The Niño 3.4 Index"},"content":"\n\nIn this tutorial, we combine topics covered in previous Xarray tutorials to demonstrate a real-world example. The real-world scenario demonstrated in this tutorial is the computation of the \n\nNiño 3.4 Index, as shown in the CESM2 submission for the \n\nCMIP6 project. A rough definition of Niño 3.4, in addition to a definition of Niño data computation, is listed below:\n\nNiño 3.4 (5N-5S, 170W-120W): The Niño 3.4 anomalies may be thought of as representing the average equatorial SSTs across the Pacific from about the dateline to the South American coast. The Niño 3.4 index typically uses a 5-month running mean, and El Niño or La Niña events are defined when the Niño 3.4 SSTs exceed +/- 0.4C for a period of six months or more.\n\nNiño X Index computation: a) Compute area averaged total SST from Niño X region; b) Compute monthly climatology (e.g., 1950-1979) for area averaged total SST from Niño X region, and subtract climatology from area averaged total SST time series to obtain anomalies; c) Smooth the anomalies with a 5-month running mean; d) Normalize the smoothed values by its standard deviation over the climatological period.\n\nThe overall goal of this tutorial is to produce a plot of ENSO data using Xarray; this plot will resemble the Oceanic Niño Index plot shown below.\n\nIn this first example, we begin by opening datasets containing the sea-surface temperature (SST) and grid-cell size data. (These datasets are taken from the Pythia example data library, using the Pythia package imported above.) The two datasets are then combined into a single dataset using Xarray’s merge method.\n\nfilepath = DATASETS.fetch('CESM2_sst_data.nc')\ndata = xr.open_dataset(filepath)\nfilepath2 = DATASETS.fetch('CESM2_grid_variables.nc')\nareacello = xr.open_dataset(filepath2).areacello\n\nds = xr.merge([data, areacello])\nds\n\nThis example uses Matplotlib and Cartopy to plot the first time slice of the dataset on an actual geographic map. By doing so, we verify that the data values fit the pattern of SST data:\n\nfig = plt.figure(figsize=(12, 6))\nax = plt.axes(projection=ccrs.Robinson(central_longitude=180))\nax.coastlines()\nax.gridlines()\nds.tos.isel(time=0).plot(\n    ax=ax, transform=ccrs.PlateCarree(), vmin=-2, vmax=30, cmap='coolwarm'\n);\n\n","type":"content","url":"/enso-xarray#the-ni-o-3-4-index","position":9},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Select the Niño 3.4 region"},"type":"lvl2","url":"/enso-xarray#select-the-ni-o-3-4-region","position":10},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Select the Niño 3.4 region"},"content":"In this set of examples, we demonstrate the selection of data values from a dataset which are located in the Niño 3.4 geographic region. The following example illustrates a selection technique that uses the sel() or isel() method:\n\ntos_nino34 = ds.sel(lat=slice(-5, 5), lon=slice(190, 240))\ntos_nino34\n\nThis example illustrates the alternate technique for selecting Niño 3.4 data, which makes use of the where() method:\n\ntos_nino34 = ds.where(\n    (ds.lat < 5) & (ds.lat > -5) & (ds.lon > 190) & (ds.lon < 240), drop=True\n)\ntos_nino34\n\nFinally, we plot the selected region to ensure it fits the definition of the Niño 3.4 region:\n\nfig = plt.figure(figsize=(12, 6))\nax = plt.axes(projection=ccrs.Robinson(central_longitude=180))\nax.coastlines()\nax.gridlines()\ntos_nino34.tos.isel(time=0).plot(\n    ax=ax, transform=ccrs.PlateCarree(), vmin=-2, vmax=30, cmap='coolwarm'\n)\nax.set_extent((120, 300, 10, -10))\n\n","type":"content","url":"/enso-xarray#select-the-ni-o-3-4-region","position":11},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Compute the anomalies"},"type":"lvl2","url":"/enso-xarray#compute-the-anomalies","position":12},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Compute the anomalies"},"content":"There are three main steps to obtain the anomalies from the Niño 3.4 dataset created in the previous set of examples. First, we use the groupby() method to convert to monthly data. Second, we subtract the mean sea-surface temperature (SST) from the monthly data. Finally, we obtain the anomalies by computing a weighted average. These steps are illustrated in the next example:\n\ngb = tos_nino34.tos.groupby('time.month')\ntos_nino34_anom = gb - gb.mean(dim='time')\nindex_nino34 = tos_nino34_anom.weighted(tos_nino34.areacello).mean(dim=['lat', 'lon'])\n\nIn this example, we smooth the data curve by applying a mean function with a 5-month moving window to the anomaly dataset. We then plot the smoothed data against the original data to demonstrate:\n\nindex_nino34_rolling_mean = index_nino34.rolling(time=5, center=True).mean()\n\nindex_nino34.plot(size=8)\nindex_nino34_rolling_mean.plot()\nplt.legend(['anomaly', '5-month running mean anomaly'])\nplt.title('SST anomaly over the Niño 3.4 region');\n\nSince the ENSO index conveys deviations from a norm, the calculation of Niño data requires a standard deviation. In this example, we calculate the standard deviation of the SST in the Niño 3.4 region data, across the entire time period of the data array:\n\nstd_dev = tos_nino34.tos.std()\nstd_dev\n\nThe final step of the Niño 3.4 index calculation involves normalizing the data. In this example, we perform this normalization by dividing the smoothed anomaly data by the standard deviation calculated above:\n\nnormalized_index_nino34_rolling_mean = index_nino34_rolling_mean / std_dev\n\n","type":"content","url":"/enso-xarray#compute-the-anomalies","position":13},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Visualize the computed Niño 3.4 index"},"type":"lvl2","url":"/enso-xarray#visualize-the-computed-ni-o-3-4-index","position":14},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Visualize the computed Niño 3.4 index"},"content":"\n\nIn this example, we use Matplotlib to generate a plot of our final Niño 3.4 data. This plot is set up to highlight values above 0.5, corresponding to El Niño (warm) events, and values below -0.5, corresponding to La Niña (cold) events.\n\nfig = plt.figure(figsize=(12, 6))\n\nplt.fill_between(\n    normalized_index_nino34_rolling_mean.time.data,\n    normalized_index_nino34_rolling_mean.where(\n        normalized_index_nino34_rolling_mean >= 0.4\n    ).data,\n    0.4,\n    color='red',\n    alpha=0.9,\n)\nplt.fill_between(\n    normalized_index_nino34_rolling_mean.time.data,\n    normalized_index_nino34_rolling_mean.where(\n        normalized_index_nino34_rolling_mean <= -0.4\n    ).data,\n    -0.4,\n    color='blue',\n    alpha=0.9,\n)\n\nnormalized_index_nino34_rolling_mean.plot(color='black')\nplt.axhline(0, color='black', lw=0.5)\nplt.axhline(0.4, color='black', linewidth=0.5, linestyle='dotted')\nplt.axhline(-0.4, color='black', linewidth=0.5, linestyle='dotted')\nplt.title('Niño 3.4 Index');\n\n\n\n","type":"content","url":"/enso-xarray#visualize-the-computed-ni-o-3-4-index","position":15},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Summary"},"type":"lvl2","url":"/enso-xarray#summary","position":16},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Summary"},"content":"This tutorial covered the use of Xarray features, including selection, grouping, and statistical functions, to compute and visualize a data index important to climate science.\n\n","type":"content","url":"/enso-xarray#summary","position":17},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Resources and References"},"type":"lvl2","url":"/enso-xarray#resources-and-references","position":18},{"hierarchy":{"lvl1":"Calculating ENSO with Xarray","lvl2":"Resources and References"},"content":"Niño 3.4 index\n\nMatplotlib’s fill_between method\n\nMatplotlib’s axhline method (see also its analogous axvline method)","type":"content","url":"/enso-xarray#resources-and-references","position":19},{"hierarchy":{"lvl1":"Introduction to Xarray"},"type":"lvl1","url":"/xarray-intro","position":0},{"hierarchy":{"lvl1":"Introduction to Xarray"},"content":"","type":"content","url":"/xarray-intro","position":1},{"hierarchy":{"lvl1":"Introduction to Xarray"},"type":"lvl1","url":"/xarray-intro#introduction-to-xarray","position":2},{"hierarchy":{"lvl1":"Introduction to Xarray"},"content":"\n\n\n\n","type":"content","url":"/xarray-intro#introduction-to-xarray","position":3},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Overview"},"type":"lvl2","url":"/xarray-intro#overview","position":4},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Overview"},"content":"The examples in this tutorial focus on the fundamentals of working with gridded, labeled data using Xarray. Xarray works by introducing additional abstractions into otherwise ordinary data arrays. In this tutorial, we demonstrate the usefulness of these abstractions. The examples in this tutorial explain how the proper usage of Xarray abstractions generally leads to simpler, more robust code.\n\nThe following topics will be covered in this tutorial:\n\nCreate a \n\nxarray.DataArray, one of the core object types in Xarray\n\nUnderstand how to use named coordinates and metadata in a DataArray\n\nCombine individual DataArrays into a Dataset, the other core object type in Xarray\n\nSubset, slice, and interpolate the data using named coordinates\n\nOpen netCDF data using Xarray\n\nBasic subsetting and aggregation of a Dataset\n\nBrief introduction to plotting with Xarray\n\n","type":"content","url":"/xarray-intro#overview","position":5},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Prerequisites"},"type":"lvl2","url":"/xarray-intro#prerequisites","position":6},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nNumPy Basics\n\nNecessary\n\n\n\nIntermediate NumPy\n\nHelpful\n\nFamiliarity with indexing and slicing arrays\n\nNumPy Broadcasting\n\nHelpful\n\nFamiliarity with array arithmetic and broadcasting\n\nIntroduction to Pandas\n\nHelpful\n\nFamiliarity with labeled data\n\nDatetime\n\nHelpful\n\nFamiliarity with time formats and the timedelta object\n\nUnderstanding of NetCDF\n\nHelpful\n\nFamiliarity with metadata structure\n\nTime to learn: 40 minutes\n\n\n\n","type":"content","url":"/xarray-intro#prerequisites","position":7},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Imports"},"type":"lvl2","url":"/xarray-intro#imports","position":8},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Imports"},"content":"\n\nIn earlier tutorials, we explained the abbreviation of commonly used scientific Python package names in import statements. Just as numpy is abbreviated np, and just as pandas is abbreviated pd, the name xarray is often abbreviated xr in import statements. In addition, we also import pythia_datasets, which provides sample data used in these examples.\n\nfrom datetime import timedelta\n\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nfrom pythia_datasets import DATASETS\n\n","type":"content","url":"/xarray-intro#imports","position":9},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl2","url":"/xarray-intro#introducing-the-dataarray-and-dataset","position":10},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Introducing the DataArray and Dataset"},"content":"As stated in earlier tutorials, NumPy arrays contain many useful features, making NumPy an essential part of the scientific Python stack.  Xarray expands on these features, adding streamlined data manipulation capabilities. These capabilities are similar to those provided by Pandas, except that they are focused on gridded N-dimensional data instead of tabular data. Its interface is based largely on the netCDF data model (variables, attributes, and dimensions), but it goes beyond the traditional netCDF interfaces in order to provide additional useful functionality, similar to netCDF-java’s \n\nCommon Data Model (CDM).\n\n","type":"content","url":"/xarray-intro#introducing-the-dataarray-and-dataset","position":11},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Creation of a DataArray object","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl3","url":"/xarray-intro#creation-of-a-dataarray-object","position":12},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Creation of a DataArray object","lvl2":"Introducing the DataArray and Dataset"},"content":"The DataArray in one of the most basic elements of Xarray; a DataArray object is similar to a numpy ndarray object. (For more information, see the documentation \n\nhere.) In addition to retaining most functionality from NumPy arrays, Xarray DataArrays provide two critical pieces of functionality:\n\nCoordinate names and values are stored with the data, making slicing and indexing much more powerful.\n\nAttributes, similar to those in netCDF files, can be stored in a container built into the DataArray.\n\nIn these examples, we create a NumPy array, and use it as a wrapper for a new DataArray object; we then explore some properties of a DataArray.\n\n","type":"content","url":"/xarray-intro#creation-of-a-dataarray-object","position":13},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Generate a random numpy array","lvl3":"Creation of a DataArray object","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl4","url":"/xarray-intro#generate-a-random-numpy-array","position":14},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Generate a random numpy array","lvl3":"Creation of a DataArray object","lvl2":"Introducing the DataArray and Dataset"},"content":"In this first example, we create a numpy array, holding random placeholder data of temperatures in Kelvin:\n\ndata = 283 + 5 * np.random.randn(5, 3, 4)\ndata\n\n","type":"content","url":"/xarray-intro#generate-a-random-numpy-array","position":15},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Wrap the array: first attempt","lvl3":"Creation of a DataArray object","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl4","url":"/xarray-intro#wrap-the-array-first-attempt","position":16},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Wrap the array: first attempt","lvl3":"Creation of a DataArray object","lvl2":"Introducing the DataArray and Dataset"},"content":"For our first attempt at wrapping a NumPy array into a DataArray, we simply use the DataArray method of Xarray, passing the NumPy array we just created:\n\ntemp = xr.DataArray(data)\ntemp\n\nNote two things:\n\nSince NumPy arrays have no dimension names, our new DataArray takes on placeholder dimension names, in this case dim_0, dim_1, and dim_2.  In our next example, we demonstrate how to add more meaningful dimension names.\n\nIf you are viewing this page as a Jupyter Notebook, running the above example generates a rich display of the data contained in our DataArray. This display comes with many ways to explore the data; for example, clicking the array symbol expands or collapses the data view.\n\n","type":"content","url":"/xarray-intro#wrap-the-array-first-attempt","position":17},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Assign dimension names","lvl3":"Creation of a DataArray object","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl4","url":"/xarray-intro#assign-dimension-names","position":18},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Assign dimension names","lvl3":"Creation of a DataArray object","lvl2":"Introducing the DataArray and Dataset"},"content":"Much of the power of Xarray comes from making use of named dimensions. In order to make full use of this, we need to provide more useful dimension names. We can generate these names when creating a DataArray by passing an ordered list of names to the DataArray method, using the keyword argument dims:\n\ntemp = xr.DataArray(data, dims=['time', 'lat', 'lon'])\ntemp\n\nThis DataArray is already an improvement over a NumPy array; the DataArray contains names for each of the dimensions (or axes in NumPy parlance). An additional improvement is the association of coordinate-value arrays with data upon creation of a DataArray. In the next example, we illustrate the creation of NumPy arrays representing the coordinate values for each dimension of the DataArray, and how to associate these coordinate arrays with the data in our DataArray.\n\n","type":"content","url":"/xarray-intro#assign-dimension-names","position":19},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Create a DataArray with named Coordinates","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl3","url":"/xarray-intro#create-a-dataarray-with-named-coordinates","position":20},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Create a DataArray with named Coordinates","lvl2":"Introducing the DataArray and Dataset"},"content":"","type":"content","url":"/xarray-intro#create-a-dataarray-with-named-coordinates","position":21},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Make time and space coordinates","lvl3":"Create a DataArray with named Coordinates","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl4","url":"/xarray-intro#make-time-and-space-coordinates","position":22},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Make time and space coordinates","lvl3":"Create a DataArray with named Coordinates","lvl2":"Introducing the DataArray and Dataset"},"content":"In this example, we use \n\nPandas to create an array of \n\ndatetime data. This array will be used in a later example to add a named coordinate, called time, to a DataArray.\n\ntimes = pd.date_range('2018-01-01', periods=5)\ntimes\n\nBefore associating coordinates with our DataArray, we must also create latitude and longitude coordinate arrays.  In these examples, we use placeholder data, and create the arrays in NumPy format:\n\nlons = np.linspace(-120, -60, 4)\nlats = np.linspace(25, 55, 3)\n\n","type":"content","url":"/xarray-intro#make-time-and-space-coordinates","position":23},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Initialize the DataArray with complete coordinate info","lvl3":"Create a DataArray with named Coordinates","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl4","url":"/xarray-intro#initialize-the-dataarray-with-complete-coordinate-info","position":24},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Initialize the DataArray with complete coordinate info","lvl3":"Create a DataArray with named Coordinates","lvl2":"Introducing the DataArray and Dataset"},"content":"In this example, we create a new DataArray. Similar to an earlier example, we use the dims keyword argument to specify the dimension names; however, in this case, we also specify the coordinate arrays using the coords keyword argument:\n\ntemp = xr.DataArray(data, coords=[times, lats, lons], dims=['time', 'lat', 'lon'])\ntemp\n\n","type":"content","url":"/xarray-intro#initialize-the-dataarray-with-complete-coordinate-info","position":25},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Set useful attributes","lvl3":"Create a DataArray with named Coordinates","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl4","url":"/xarray-intro#set-useful-attributes","position":26},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Set useful attributes","lvl3":"Create a DataArray with named Coordinates","lvl2":"Introducing the DataArray and Dataset"},"content":"As described above, DataArrays have a built-in container for attribute metadata. These attributes are similar to those in netCDF files, and are added to a DataArray using its attrs method:\n\ntemp.attrs['units'] = 'kelvin'\ntemp.attrs['standard_name'] = 'air_temperature'\n\ntemp\n\n","type":"content","url":"/xarray-intro#set-useful-attributes","position":27},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Issues with preservation of attributes","lvl3":"Create a DataArray with named Coordinates","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl4","url":"/xarray-intro#issues-with-preservation-of-attributes","position":28},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Issues with preservation of attributes","lvl3":"Create a DataArray with named Coordinates","lvl2":"Introducing the DataArray and Dataset"},"content":"In this example, we illustrate an important concept relating to attributes. When a mathematical operation is performed on a DataArray, all of the coordinate arrays remain attached to the DataArray, but any attribute metadata assigned is lost. Attributes are removed in this way due to the fact that they may not convey correct or appropriate metadata after an arbitrary arithmetic operation.\n\nThis example converts our DataArray values from Kelvin to degrees Celsius. Pay attention to the attributes in the Jupyter rich display below. (If you are not viewing this page as a Jupyter notebook, see the Xarray documentation to learn how to display the attributes.)\n\ntemp_in_celsius = temp - 273.15\ntemp_in_celsius\n\nIn addition, if you need more details on how Xarray handles metadata, you can review this \n\ndocumentation page.\n\n","type":"content","url":"/xarray-intro#issues-with-preservation-of-attributes","position":29},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"The Dataset: a container for DataArrays with shared coordinates","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl3","url":"/xarray-intro#the-dataset-a-container-for-dataarrays-with-shared-coordinates","position":30},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"The Dataset: a container for DataArrays with shared coordinates","lvl2":"Introducing the DataArray and Dataset"},"content":"Along with the DataArray, the other main object type in Xarray is the Dataset.  Datasets are containers similar to Python dictionaries; each Dataset can hold one or more DataArrays. In addition, the DataArrays contained in a Dataset can share coordinates, although this behavior is optional.  (For more information, see the \n\nofficial documentation page.)\n\nDataset objects are most often created by loading data from a data file. We will cover this functionality in a later example; in this example, we will create a Dataset from two DataArrays. We will use our existing temperature DataArray for one of these DataArrays; the other one is created in the next example.\n\nIn addition, both of these DataArrays will share coordinate axes. Therefore, the next example will also illustrate the usage of common coordinate axes across DataArrays in a Dataset.\n\n","type":"content","url":"/xarray-intro#the-dataset-a-container-for-dataarrays-with-shared-coordinates","position":31},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Create a pressure DataArray using the same coordinates","lvl3":"The Dataset: a container for DataArrays with shared coordinates","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl4","url":"/xarray-intro#create-a-pressure-dataarray-using-the-same-coordinates","position":32},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Create a pressure DataArray using the same coordinates","lvl3":"The Dataset: a container for DataArrays with shared coordinates","lvl2":"Introducing the DataArray and Dataset"},"content":"In this example, we create a DataArray object to hold pressure data. This new DataArray is set up in a very similar fashion to the temperature DataArray created above.\n\npressure_data = 1000.0 + 5 * np.random.randn(5, 3, 4)\npressure = xr.DataArray(\n    pressure_data, coords=[times, lats, lons], dims=['time', 'lat', 'lon']\n)\npressure.attrs['units'] = 'hPa'\npressure.attrs['standard_name'] = 'air_pressure'\n\npressure\n\n","type":"content","url":"/xarray-intro#create-a-pressure-dataarray-using-the-same-coordinates","position":33},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Create a Dataset object","lvl3":"The Dataset: a container for DataArrays with shared coordinates","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl4","url":"/xarray-intro#create-a-dataset-object","position":34},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Create a Dataset object","lvl3":"The Dataset: a container for DataArrays with shared coordinates","lvl2":"Introducing the DataArray and Dataset"},"content":"Before we can create a Dataset object, we must first name each of the DataArray objects that will be added to the new Dataset.\n\nTo name the DataArrays that will be added to our Dataset, we can set up a Python dictionary as shown in the next example. We can then pass this dictionary to the Dataset method using the keyword argument data_vars; this creates a new Dataset containing both of our DataArrays.\n\nds = xr.Dataset(data_vars={'Temperature': temp, 'Pressure': pressure})\nds\n\nAs listed in the rich display above, the new Dataset object is aware that both DataArrays share the same coordinate axes. (Please note that if this page is not run as a Jupyter Notebook, the rich display may be unavailable.)\n\n","type":"content","url":"/xarray-intro#create-a-dataset-object","position":35},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Access Data variables and Coordinates in a Dataset","lvl3":"The Dataset: a container for DataArrays with shared coordinates","lvl2":"Introducing the DataArray and Dataset"},"type":"lvl4","url":"/xarray-intro#access-data-variables-and-coordinates-in-a-dataset","position":36},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Access Data variables and Coordinates in a Dataset","lvl3":"The Dataset: a container for DataArrays with shared coordinates","lvl2":"Introducing the DataArray and Dataset"},"content":"This set of examples illustrates different methods for retrieving DataArrays from a Dataset.\n\nThis first example shows how to retrieve DataArrays using the “dot” notation:\n\nds.Pressure\n\nIn addition, you can access DataArrays through a dictionary syntax, as shown in this example:\n\nds['Pressure']\n\nDataset objects are mainly used for loading data from files, which will be covered later in this tutorial.\n\n","type":"content","url":"/xarray-intro#access-data-variables-and-coordinates-in-a-dataset","position":37},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Subsetting and selection by coordinate values"},"type":"lvl2","url":"/xarray-intro#subsetting-and-selection-by-coordinate-values","position":38},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Subsetting and selection by coordinate values"},"content":"Much of the power of labeled coordinates comes from the ability to select data based on coordinate names and values instead of array indices. This functionality will be covered on a basic level in these examples.  (Later tutorials will cover this topic in much greater detail.)","type":"content","url":"/xarray-intro#subsetting-and-selection-by-coordinate-values","position":39},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"NumPy-like selection","lvl2":"Subsetting and selection by coordinate values"},"type":"lvl3","url":"/xarray-intro#numpy-like-selection","position":40},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"NumPy-like selection","lvl2":"Subsetting and selection by coordinate values"},"content":"In these examples, we are trying to extract all of our spatial data for a single date; in this case, January 2, 2018. For our first example, we retrieve spatial data using index selection, as with a NumPy array:\n\nindexed_selection = temp[1, :, :]  # Index 1 along axis 0 is the time slice we want...\nindexed_selection\n\nThis example reveals one of the major shortcomings of index selection. In order to retrieve the correct data using index selection, anyone using a DataArray must have precise knowledge of the axes in the DataArray, including the order of the axes and the meaning of their indices.\n\nBy using named coordinates, as shown in the next set of examples, we can avoid this cumbersome burden.\n\n","type":"content","url":"/xarray-intro#numpy-like-selection","position":41},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Selecting with .sel()","lvl2":"Subsetting and selection by coordinate values"},"type":"lvl3","url":"/xarray-intro#selecting-with-sel","position":42},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Selecting with .sel()","lvl2":"Subsetting and selection by coordinate values"},"content":"In this example, we show how to select data based on coordinate values, by way of the .sel() method. This method takes one or more named coordinates in keyword-argument format, and returns data matching the coordinates.\n\nnamed_selection = temp.sel(time='2018-01-02')\nnamed_selection\n\nThis method yields the same result as the index selection, however:\n\nwe didn’t have to know anything about how the array was created or stored\n\nour code is agnostic about how many dimensions we are dealing with\n\nthe intended meaning of our code is much clearer\n\n","type":"content","url":"/xarray-intro#selecting-with-sel","position":43},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Approximate selection and interpolation","lvl2":"Subsetting and selection by coordinate values"},"type":"lvl3","url":"/xarray-intro#approximate-selection-and-interpolation","position":44},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Approximate selection and interpolation","lvl2":"Subsetting and selection by coordinate values"},"content":"When working with temporal and spatial data, it is a common practice to sample data close to the coordinate points in a dataset. The following set of examples illustrates some common techniques for this practice.","type":"content","url":"/xarray-intro#approximate-selection-and-interpolation","position":45},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Nearest-neighbor sampling","lvl3":"Approximate selection and interpolation","lvl2":"Subsetting and selection by coordinate values"},"type":"lvl4","url":"/xarray-intro#nearest-neighbor-sampling","position":46},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Nearest-neighbor sampling","lvl3":"Approximate selection and interpolation","lvl2":"Subsetting and selection by coordinate values"},"content":"In this example, we are trying to sample a temporal data point within 2 days of the date 2018-01-07. Since the final date on our DataArray’s temporal axis is 2018-01-05, this is an appropriate problem.\n\nWe can use the .sel() method to perform nearest-neighbor sampling, by setting the method keyword argument to ‘nearest’. We can also optionally provide a tolerance argument; with temporal data, this is a timedelta object.\n\ntemp.sel(time='2018-01-07', method='nearest', tolerance=timedelta(days=2))\n\nUsing the rich display above, we can see that .sel indeed returned the data at the temporal value corresponding to the date 2018-01-05.\n\n","type":"content","url":"/xarray-intro#nearest-neighbor-sampling","position":47},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Interpolation","lvl3":"Approximate selection and interpolation","lvl2":"Subsetting and selection by coordinate values"},"type":"lvl4","url":"/xarray-intro#interpolation","position":48},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl4":"Interpolation","lvl3":"Approximate selection and interpolation","lvl2":"Subsetting and selection by coordinate values"},"content":"In this example, we are trying to extract a timeseries for Boulder, CO, which is located at 40°N latitude and 105°W longitude. Our DataArray does not contain a longitude data value of -105, so in order to retrieve this timeseries, we must interpolate between data points.\n\nThe .interp() method allows us to retrieve data from any latitude and longitude by means of interpolation. This method uses coordinate-value selection, similarly to .sel().  (For more information on the .interp() method, see the official documentation \n\nhere.)\n\ntemp.interp(lon=-105, lat=40)\n\nInfoIn order to interpolate data using Xarray, the SciPy package must be imported. You can learn more about SciPy from the \n\nofficial documentation.\n\n","type":"content","url":"/xarray-intro#interpolation","position":49},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Slicing along coordinates","lvl2":"Subsetting and selection by coordinate values"},"type":"lvl3","url":"/xarray-intro#slicing-along-coordinates","position":50},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Slicing along coordinates","lvl2":"Subsetting and selection by coordinate values"},"content":"Frequently, it is useful to select a range, or slice, of data along one or more coordinates.  In order to understand this process, you must first understand Python slice objects. If you are unfamiliar with slice objects, you should first read the official \n\nPython slice documentation. Once you are proficient using slice objects, you can create slices of data by passing slice objects to the .sel method, as shown below:\n\ntemp.sel(\n    time=slice('2018-01-01', '2018-01-03'), lon=slice(-110, -70), lat=slice(25, 45)\n)\n\nInfoAs detailed in the documentation page linked above, the slice function uses the argument order (start, stop[, step]), where step is optional.\n\nBecause we are now working with a slice of data, instead of our full dataset, the lengths of our coordinate axes have been shortened, as shown in the Jupyter rich display above. (You may need to use a different display technique if you are not running this page as a Jupyter Notebook.)\n\n","type":"content","url":"/xarray-intro#slicing-along-coordinates","position":51},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"One more selection method: .loc","lvl2":"Subsetting and selection by coordinate values"},"type":"lvl3","url":"/xarray-intro#one-more-selection-method-loc","position":52},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"One more selection method: .loc","lvl2":"Subsetting and selection by coordinate values"},"content":"In addition to using the sel() method to select data from a DataArray, you can also use the .loc attribute.  Every DataArray has a .loc attribute; in order to leverage this attribute to select data, you can specify a coordinate value in square brackets, as shown below:\n\ntemp.loc['2018-01-02']\n\nThis selection technique is similar to NumPy’s index-based selection, as shown below:temp[1,:,:]\n\nHowever, this technique also resembles the .sel() method’s fully label-based selection functionality. The advantages and disadvantages of using the .loc attribute are discussed in detail below.\n\nThis example illustrates a significant disadvantage of using the .loc attribute.  Namely, we specify the values for each coordinate, but cannot specify the dimension names; therefore, the dimensions must be specified in the correct order, and this order must already be known:\n\ntemp.loc['2018-01-01':'2018-01-03', 25:45, -110:-70]\n\nIn contrast with the previous example, this example shows a useful advantage of using the .loc attribute. When using the .loc attribute, you can specify data slices using a syntax similar to NumPy in addition to, or instead of, using the slice function.  Both of these slicing techniques are illustrated below:\n\ntemp.loc['2018-01-01':'2018-01-03', slice(25, 45), -110:-70]\n\nAs described above, the arguments to .loc must be in the order of the DataArray’s dimensions.  Attempting to slice data without ordering arguments properly can cause errors, as shown below:\n\n# This will generate an error\n# temp.loc[-110:-70, 25:45,'2018-01-01':'2018-01-03']\n\n","type":"content","url":"/xarray-intro#one-more-selection-method-loc","position":53},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Opening netCDF data"},"type":"lvl2","url":"/xarray-intro#opening-netcdf-data","position":54},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Opening netCDF data"},"content":"Xarray has close ties to the netCDF data format; as such, netCDF was chosen as the premier data file format for Xarray. Hence, Xarray can easily open netCDF datasets, provided they conform to certain limitations (for example, 1-dimensional coordinates).","type":"content","url":"/xarray-intro#opening-netcdf-data","position":55},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Access netCDF data with xr.open_dataset","lvl2":"Opening netCDF data"},"type":"lvl3","url":"/xarray-intro#access-netcdf-data-with-xr-open-dataset","position":56},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Access netCDF data with xr.open_dataset","lvl2":"Opening netCDF data"},"content":"\n\nInfoThe data file for this example, NARR_19930313_0000.nc, is retrieved from Project Pythia's custom example data library. The DATASETS class imported at the top of this page contains a .fetch() method, which retrieves, downloads, and caches a Pythia example data file.\n\nfilepath = DATASETS.fetch('NARR_19930313_0000.nc')\n\nOnce we have a valid path to a data file that Xarray knows how to read, we can open the data file and load it into Xarray; this is done by passing the path to Xarray’s open_dataset method, as shown below:\n\nds = xr.open_dataset(filepath)\nds\n\n","type":"content","url":"/xarray-intro#access-netcdf-data-with-xr-open-dataset","position":57},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Subsetting the Dataset","lvl2":"Opening netCDF data"},"type":"lvl3","url":"/xarray-intro#subsetting-the-dataset","position":58},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Subsetting the Dataset","lvl2":"Opening netCDF data"},"content":"Xarray’s open_dataset() method, shown in the previous example, returns a Dataset object, which must then be assigned to a variable; in this case, we call the variable ds. Once the netCDF dataset is loaded into an Xarray Dataset, we can pull individual DataArrays out of the Dataset, using the technique described earlier in this tutorial.  In this example, we retrieve isobaric pressure data, as shown below:\n\nds.isobaric1\n\n(As described earlier in this tutorial, we can also use dictionary syntax to select specific DataArrays; in this case, we would write ds['isobaric1'].)\n\nMany of the subsetting operations usable on DataArrays can also be used on Datasets.  However, when used on Datasets, these operations are performed on every DataArray in the Dataset, as shown below:\n\nds_1000 = ds.sel(isobaric1=1000.0)\nds_1000\n\nAs shown above, the subsetting operation performed on the Dataset returned a new Dataset.  If only a single DataArray is needed from this new Dataset, it can be retrieved using the familiar dot notation:\n\nds_1000.Temperature_isobaric\n\n","type":"content","url":"/xarray-intro#subsetting-the-dataset","position":59},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Aggregation operations","lvl2":"Opening netCDF data"},"type":"lvl3","url":"/xarray-intro#aggregation-operations","position":60},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Aggregation operations","lvl2":"Opening netCDF data"},"content":"As covered earlier in this tutorial, you can use named dimensions in an Xarray Dataset to manually slice and index data.  However, these dimension names also serve an additional purpose: you can use them to specify dimensions to aggregate on.  There are many different aggregation operations available; in this example, we focus on std (standard deviation).\n\nu_winds = ds['u-component_of_wind_isobaric']\nu_winds.std(dim=['x', 'y'])\n\nInfoRecall from previous tutorials that aggregations in NumPy operate over axes specified by numeric values. However, with Xarray objects, aggregation dimensions are instead specified through a list passed to the dim keyword argument.\n\nFor this set of examples, we will be using the sample dataset defined above.  The calculations performed in these examples compute the mean temperature profile, defined as temperature as a function of pressure, over Colorado.  For the purposes of these examples, the bounds of Colorado are defined as follows:\n\nx: -182km to 424km\n\ny: -1450km to -990km\n\nThis dataset uses a Lambert Conformal projection; therefore, the data values shown above are projected to specific latitude and longitude values.  In this example, these latitude and longitude values are 37°N to 41°N and 102°W to 109°W. Using the original data values and the mean aggregation function as shown below yields the following mean temperature profile data:\n\ntemps = ds.Temperature_isobaric\nco_temps = temps.sel(x=slice(-182, 424), y=slice(-1450, -990))\nprof = co_temps.mean(dim=['x', 'y'])\nprof\n\n","type":"content","url":"/xarray-intro#aggregation-operations","position":61},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Plotting with Xarray"},"type":"lvl2","url":"/xarray-intro#plotting-with-xarray","position":62},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Plotting with Xarray"},"content":"As demonstrated earlier in this tutorial, there are many benefits to storing data as Xarray DataArrays and Datasets. In this section, we will cover another major benefit: Xarray greatly simplifies plotting of data stored as DataArrays and Datasets. One advantage of this is that many common plot elements, such as axis labels, are automatically generated and optimized for the data being plotted.  The next set of examples demonstrates this and provides a general overview of plotting with Xarray.","type":"content","url":"/xarray-intro#plotting-with-xarray","position":63},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Simple visualization with .plot()","lvl2":"Plotting with Xarray"},"type":"lvl3","url":"/xarray-intro#simple-visualization-with-plot","position":64},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Simple visualization with .plot()","lvl2":"Plotting with Xarray"},"content":"Similarly to \n\nPandas, Xarray includes a built-in plotting interface, which makes use of \n\nMatplotlib behind the scenes. In order to use this interface, you can call the .plot() method, which is included in every DataArray.\n\nIn this example, we show how to create a basic plot from a DataArray. In this case, we are using the prof DataArray defined above, which contains a Colorado mean temperature profile.\n\nprof.plot()\n\nIn the figure shown above, Xarray has generated a line plot, which uses the mean temperature profile and the 'isobaric' coordinate variable as axes. In addition, the axis labels and unit information have been read automatically from the DataArray’s metadata.\n\n","type":"content","url":"/xarray-intro#simple-visualization-with-plot","position":65},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Customizing the plot","lvl2":"Plotting with Xarray"},"type":"lvl3","url":"/xarray-intro#customizing-the-plot","position":66},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Customizing the plot","lvl2":"Plotting with Xarray"},"content":"As mentioned above, the .plot() method of Xarray DataArrays uses Matplotlib behind the scenes. Therefore, knowledge of Matplotlib can help you more easily customize plots generated by Xarray.\n\nIn this example, we need to customize the air temperature profile plot created above. There are two changes that need to be made:\n\nswap the axes, so that the Y (vertical) axis corresponds to isobaric levels\n\ninvert the Y axis to match the model of air pressure decreasing at higher altitudes\n\nWe can make these changes by adding certain keyword arguments when calling .plot(), as shown below:\n\nprof.plot(y=\"isobaric1\", yincrease=False)\n\n","type":"content","url":"/xarray-intro#customizing-the-plot","position":67},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Plotting 2-D data","lvl2":"Plotting with Xarray"},"type":"lvl3","url":"/xarray-intro#plotting-2-d-data","position":68},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"Plotting 2-D data","lvl2":"Plotting with Xarray"},"content":"In the previous example, we used .plot() to generate a plot from 1-D data, and the result was a line plot. In this section, we illustrate plotting of 2-D data.\n\nIn this example, we illustrate basic plotting of a 2-D array:\n\ntemps.sel(isobaric1=1000).plot()\n\nThe figure above is generated by Matplotlib’s pcolormesh method, which was automatically called by Xarray’s plot method.  This occurred because Xarray recognized that the DataArray object calling the plot method contained two distinct coordinate variables.\n\nThe plot generated by the above example is a map of air temperatures over North America, on the 1000 hPa isobaric surface. If a different map projection or added geographic features are needed on this plot, the plot can easily be modified using \n\nCartopy.\n\n\n\n","type":"content","url":"/xarray-intro#plotting-2-d-data","position":69},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Summary"},"type":"lvl2","url":"/xarray-intro#summary","position":70},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Summary"},"content":"Xarray expands on Pandas’ labeled-data functionality, bringing the usefulness of labeled data operations to N-dimensional data. As such, it has become a central workhorse in the geoscience community for the analysis of gridded datasets. Xarray allows us to open self-describing NetCDF files and make full use of the coordinate axes, labels, units, and other metadata. By making use of labeled coordinates, our code is often easier to write, easier to read, and more robust.","type":"content","url":"/xarray-intro#summary","position":71},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/xarray-intro#whats-next","position":72},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl3":"What’s next?","lvl2":"Summary"},"content":"Additional notebooks to appear in this section will describe the following topics in greater detail:\n\nperforming arithmetic and broadcasting operations with Xarray data structures\n\nusing “group by” operations\n\nremote data access with OPeNDAP\n\nmore advanced visualization, including map integration with Cartopy\n\n","type":"content","url":"/xarray-intro#whats-next","position":73},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Resources and references"},"type":"lvl2","url":"/xarray-intro#resources-and-references","position":74},{"hierarchy":{"lvl1":"Introduction to Xarray","lvl2":"Resources and references"},"content":"This tutorial contains content adapted from the material in \n\nUnidata’s Python Training.\n\nMost basic questions and issues with Xarray can be resolved with help from the material in the \n\nXarray documentation. Some of the most popular sections of this documentation are listed below:\n\nWhy Xarray\n\nQuick overview\n\nExample gallery\n\nAnother resource you may find useful is this \n\nXarray Tutorial collection, created from content hosted on GitHub.","type":"content","url":"/xarray-intro#resources-and-references","position":75},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda"},"type":"lvl1","url":"/conda","position":0},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda"},"content":"","type":"content","url":"/conda","position":1},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Overview"},"type":"lvl2","url":"/conda#overview","position":2},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Overview"},"content":"Conda is an open-source, cross-platform, language-agnostic package manager and environment management system that allows you to quickly install, run, and update packages within your work environment(s).\n\nHere we will cover:\n\nWhat are packages?\n\nInstalling Conda\n\nCreating a Conda environment\n\nUseful Conda commands","type":"content","url":"/conda#overview","position":3},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Prerequisites"},"type":"lvl2","url":"/conda#prerequisites","position":4},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nInstalling and Running Python\n\nHelpful\n\n\n\nTime to learn: 20 minutes","type":"content","url":"/conda#prerequisites","position":5},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"What are Packages?"},"type":"lvl2","url":"/conda#what-are-packages","position":6},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"What are Packages?"},"content":"A Python package is a collection of modules, which, in turn, are essentially Python scripts that contain published functionality. There are Python packages for data input, data analysis, data visualization, etc. Each package offers a unique toolset and may have its own unique syntax rules.\n\nPackage management is useful because you may want to update a package for one of your projects, but keep it at the same version in other projects to ensure that they continue to run as expected.","type":"content","url":"/conda#what-are-packages","position":7},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Installing Conda"},"type":"lvl2","url":"/conda#installing-conda","position":8},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Installing Conda"},"content":"We recommend you install Miniforge. You can do that by following the \n\ninstructions for your machine.\n\nMiniforge uses the conda package management system and is based on Miniconda, which is a pared-down version of the full Anaconda Python distribution.\n\nInstalling Anaconda takes longer and uses up more disk space, but provides you with more functionality, including Spyder (a Python-specific integrated development environment or IDE) and Jupyter, in addition to other immediately installed packages. Also, the interface of Anaconda is great if you are uncomfortable with the terminal.\n\nWe recommend Miniforge for these reasons:\n\nIt’s quicker and takes up less disk space.\n\nIt encourages you to install only the packages you need in reproducible isolated environments for specific projects. This is generally a more robust way to work with open source tools.\n\nIt uses conda-forge as the default channel for packages, which is our recommended way to get up-to-date, interoperable packages..\n\nOnce you have conda via the Miniconda installer, the next step is to create an environment and install packages.","type":"content","url":"/conda#installing-conda","position":9},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Creating a Conda Environment"},"type":"lvl2","url":"/conda#creating-a-conda-environment","position":10},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Creating a Conda Environment"},"content":"A Conda environment is an interoperable collection of specific versions of packages or libraries that you install and use for a specific workflow. The Conda package manager takes care of dependencies, so everything works together in a predictable way. One huge advantage of using environments is that any changes you make to one environment will not affect your other environments at all, so you are much less likely to “break” something!\n\nTo create a new Conda environment, type conda create --name and the name of your environment in your terminal, and then specify any packages that you would like to have installed. For example, to install a Jupyter-ready environment called sample_environment, typeconda create --name sample_environment python jupyterlab\n\nOnce the environment is created, you need to activate it in the current terminal session (see below).\n\nIt is a good idea to create a new environment for every project. Because Python is open source, new versions of the tools are released frequently. Isolated environments help guarantee that your scripts use the same versions of packages and libraries to ensure they run as expected. Similarly, it is best practice to NOT modify your base environment.","type":"content","url":"/conda#creating-a-conda-environment","position":11},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Useful Conda commands"},"type":"lvl2","url":"/conda#conda-commands","position":12},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Useful Conda commands"},"content":"Some other \n\nConda commands that you will find useful include:\n\nActivating a specific environmentconda activate sample_environment\n\nDeactivating the current environmentconda deactivate\n\nChecking what packages/versions are installed in the current environmentconda list\n\nInstalling a new package into the current environmentconda install somepackage\n\nInstalling a specific version of a package into the current environmentconda install somepackage=0.17\n\nUpdating all packages in the current environment to the latest versionsconda update --all\n\nChecking what conda environments you haveconda env list\n\nDeleting an environmentconda env remove --name sample_environment\n\nYou can find lots more information in the \n\nConda documentation or this handy \n\nConda cheat sheet.\n\nIf you’re not a command line user, the Anaconda navigator offers GUI functionality for selecting environments and installing packages.","type":"content","url":"/conda#conda-commands","position":13},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Summary"},"type":"lvl2","url":"/conda#summary","position":14},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Summary"},"content":"Conda is a package and environment management system that allows you to quickly install, run, and update packages within your work environment(s). This is important for gathering all of the tools necessary for your workflow. Conda can be managed in the command line or in the Anaconda GUI.","type":"content","url":"/conda#summary","position":15},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/conda#whats-next","position":16},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl3":"What’s Next?","lvl2":"Summary"},"content":"How to Run Python in the Terminal\n\nHow to Run Python in a Jupyter Session","type":"content","url":"/conda#whats-next","position":17},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Resources and References"},"type":"lvl2","url":"/conda#resources-and-references","position":18},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Resources and References"},"content":"Linux commands\n\nConda documentation\n\nConda cheat sheet\n\nAnaconda\n\nMiniconda","type":"content","url":"/conda#resources-and-references","position":19},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Glossary"},"type":"lvl2","url":"/conda#glossary","position":20},{"hierarchy":{"lvl1":"Installing and Managing Python with Conda","lvl2":"Glossary"},"content":"Conda\n\nConda is an open-source, cross-platform, language-agnostic package manager and environment management system that allows you to quickly install, run, and update packages within your work environment(s). To install conda, we recommend \n\nMiniconda.\n\nSee \n\nConda documentation and the \n\nConda cheat sheet and \n\nUseful Conda commands in the context of ProjectPythia.\n\nMiniconda\n\nMiniconda is a free minimal installer for \n\nConda. Miniconda only comes with the \n\nConda package management system; it is a pared-down version of the full Anaconda Python distribution.\n\nSee \n\nInstalling Conda.\n\nPython Package\n\nA Python package is a collection of modules, which, in turn, are essentially Python scripts that contain published functionality. There are Python packages for data input, data analysis, data visualization, etc. Each package offers a unique toolset and may have its own unique syntax rules. You can install Python packages with \n\nConda.","type":"content","url":"/conda#glossary","position":21},{"hierarchy":{"lvl1":"Getting Started with GitHub"},"type":"lvl1","url":"/getting-started-github","position":0},{"hierarchy":{"lvl1":"Getting Started with GitHub"},"content":"","type":"content","url":"/getting-started-github","position":1},{"hierarchy":{"lvl1":"Getting Started with GitHub"},"type":"lvl1","url":"/getting-started-github#getting-started-with-github","position":2},{"hierarchy":{"lvl1":"Getting Started with GitHub"},"content":"Python and Jupyter are cool technologies, but they only scratch the surface of why you might want to adopt Python for your geoscience workflow.\n\nThis section will introduce GitHub, the de facto standard platform for collaboration and version control used by the open-source Python community.\n\nWe will walk users through these topics:\n\nWhat is GitHub?, and how to create your free account\n\nWhat are GitHub Repositories, and what are some Python-specific examples?\n\nIssues and Discussions on GitHub: what they’re for and how to participate\n\nCloning and Forking a Repository (and what’s the difference?)\n\nDetailed GitHub Configuration, including how to set up secure permissions and notifications\n\nBasic Version Control with git: why you may need it, and how to get started\n\nWhat is a git Branch?\n\nWhat’s a Pull Request, and how do you open one?\n\nGitHub Workflows, sets of best practices for collaborative work\n\nContributing to Project Pythia via GitHub","type":"content","url":"/getting-started-github#getting-started-with-github","position":3},{"hierarchy":{"lvl1":"Getting Started with Jupyter"},"type":"lvl1","url":"/getting-started-jupyter","position":0},{"hierarchy":{"lvl1":"Getting Started with Jupyter"},"content":"\n\n\n\n","type":"content","url":"/getting-started-jupyter","position":1},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Overview"},"type":"lvl2","url":"/getting-started-jupyter#overview","position":2},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Overview"},"content":"Project Jupyter is a project and community whose goal is to “develop open-source software, open-standards, and services for interactive computing across dozens of programming languages”. Jupyter consists of four main components: Jupyter Notebooks, Jupyter Kernels, Jupyter Lab, and Jupyter Hub. Jupyter can be executed locally and remotely.\n\nJupyter Notebooks\n\nJupyter Kernels\n\nJupyter Lab\n\nJupyter Hub\n\nExecuting Jupyter\n\n","type":"content","url":"/getting-started-jupyter#overview","position":3},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Prerequisites"},"type":"lvl2","url":"/getting-started-jupyter#prerequisites","position":4},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nInstalling and Running Python: Python in Jupyter\n\nHelpful\n\n\n\nTime to learn: 10 minutes\n\n\n\n","type":"content","url":"/getting-started-jupyter#prerequisites","position":5},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Jupyter Notebooks"},"type":"lvl2","url":"/getting-started-jupyter#jupyter-notebooks","position":6},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Jupyter Notebooks"},"content":"The Jupyter Notebook software is an open-source web application that allows you to create and share Jupyter Notebooks (*.ipynb files). Jupyter Notebooks contain executable code, LaTeX equations, visualizations (e.g., plots, pictures), and narrative text. The code does not have to just be Python, other languages such as Julia or R are supported as well.\n\nJupyter Notebooks are celebrated for their interactive output that allows movement between code, code output, explanations, and more code - similar to how scientists think and solve problems. Jupyter Notebooks can be thought of as a living, runnable publication and make for a great presentation platform.\n\n","type":"content","url":"/getting-started-jupyter#jupyter-notebooks","position":7},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Jupyter Kernels"},"type":"lvl2","url":"/getting-started-jupyter#jupyter-kernels","position":8},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Jupyter Kernels"},"content":"Software engines and their environments (e.g., conda environments) that execute the code contained in Jupyter Notebooks.\n\n","type":"content","url":"/getting-started-jupyter#jupyter-kernels","position":9},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Jupyter Lab"},"type":"lvl2","url":"/getting-started-jupyter#jupyter-lab","position":10},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Jupyter Lab"},"content":"A popular web application on which users can create and write their Jupyter Notebooks, as well as explore data, install software, etc.\n\nYou can find more information on running Jupyter Lab \n\nhere.\n\n","type":"content","url":"/getting-started-jupyter#jupyter-lab","position":11},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Jupyter Hub"},"type":"lvl2","url":"/getting-started-jupyter#jupyter-hub","position":12},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Jupyter Hub"},"content":"A web-based platform that authenticates users and launches Jupyter Lab applications for users on remote systems.\n\n","type":"content","url":"/getting-started-jupyter#jupyter-hub","position":13},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Executing Jupyter"},"type":"lvl2","url":"/getting-started-jupyter#executing-jupyter","position":14},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Executing Jupyter"},"content":"\n\n","type":"content","url":"/getting-started-jupyter#executing-jupyter","position":15},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl3":"Local Execution Model","lvl2":"Executing Jupyter"},"type":"lvl3","url":"/getting-started-jupyter#local-execution-model","position":16},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl3":"Local Execution Model","lvl2":"Executing Jupyter"},"content":"You can launch JupyterLab from a terminal; it will open up in a web browser. The application will then be running in that web browser. When you open a notebook, Jupyter opens a kernel which can be tied to a specific coding language.\n\nTo launch the JupyterLab interface in your browser, follow the instructions in \n\nInstalling and Running Python: Python in Jupyter.\n\n","type":"content","url":"/getting-started-jupyter#local-execution-model","position":17},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl3":"Remote Execution Model","lvl2":"Executing Jupyter"},"type":"lvl3","url":"/getting-started-jupyter#remote-execution-model","position":18},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl3":"Remote Execution Model","lvl2":"Executing Jupyter"},"content":"In the remote execution model, you start out in the browser, then navigate to a specific URL that points to a JupyterHub. On JupyterHub, you authenticate on the remote system, and then JupyterLab is launched and redirected back to your browser. The interface appears the same as if you were running Jupyter locally.\n\n\n\n","type":"content","url":"/getting-started-jupyter#remote-execution-model","position":19},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Summary"},"type":"lvl2","url":"/getting-started-jupyter#summary","position":20},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Summary"},"content":"Jupyter consists of four main components:\n\nJupyter Notebooks (the “*.ipynb” files),\n\nJupyter Kernels (the work environment),\n\nJupyter Lab (a popular web application and interface for local execution),\n\nand Jupyter Hub (an application and launcher for remote execution).","type":"content","url":"/getting-started-jupyter#summary","position":21},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/getting-started-jupyter#whats-next","position":22},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl3":"What’s next?","lvl2":"Summary"},"content":"JupyterLab\n\n","type":"content","url":"/getting-started-jupyter#whats-next","position":23},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Resources and references"},"type":"lvl2","url":"/getting-started-jupyter#resources-and-references","position":24},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Resources and references"},"content":"Jupyter Documentation\n\nXdev Python Tutorial Seminar Series - Jupyter Notebooks\n\n","type":"content","url":"/getting-started-jupyter#resources-and-references","position":25},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Glossary"},"type":"lvl2","url":"/getting-started-jupyter#glossary","position":26},{"hierarchy":{"lvl1":"Getting Started with Jupyter","lvl2":"Glossary"},"content":"Jupyter Notebooks\n\nThe Jupyter Notebook software is an open-source web application that allows you to create and share Jupyter Notebooks (*.ipynb files). Jupyter Notebooks contain executable code, LaTeX equations, visualizations (e.g., plots, pictures), and narrative text. The code does not have to just be Python, other languages such as Julia or R are supported as well. Jupyter Notebooks are celebrated for their interactive output that allows movement between code, code output, explanations, and more code - similar to how scientists think and solve problems. Jupyter Notebooks can be thought of as a living, runnable publication and make for a great presentation platform. See also \n\nJupyter Kernels, \n\nJupyter Lab, \n\nJupyter Hub, \n\nBinder, and \n\nBinderHub.\n\nJupyter Kernels\n\nSoftware engines and their environments (e.g., conda environments) that execute the code contained in \n\nJupyter Notebooks.\n\nJupyter Lab\n\nA popular web application on which users can create and write their \n\nJupyter Notebooks, as well as explore data, install software, etc. You can find more information on running Jupyter Lab \n\nhere.\n\nSee \n\nInstalling Python in Jupyter for more.\n\nJupyter Hub\n\nA web-based platform that authenticates users and launches \n\nJupyter Lab applications for users on remote systems.\n\nBinder\n\nAn open-source service that allows users to create sharable, interactive computing environments from \n\nJupyter Notebooks and other repositories. Binder can reproduce a computational environment directly from a GitHub repository, providing a seamless way to share and interact with code and data.\n\nThe public service to run Binder is on \n\nhttps://​mybinder​.org, which is running \n\nBinderHub. ProjectPythia\n\nBinderHub\n\nThe underlying technology and infrastructure that powers \n\nBinder. BinderHub deploys and manages the interactive computing environments for \n\nJupyter Notebooks, ensuring that users can access and share reproducible computational work.","type":"content","url":"/getting-started-jupyter#glossary","position":27},{"hierarchy":{"lvl1":"Getting Started with Python"},"type":"lvl1","url":"/getting-started-python","position":0},{"hierarchy":{"lvl1":"Getting Started with Python"},"content":"New Python users, start here!","type":"content","url":"/getting-started-python","position":1},{"hierarchy":{"lvl1":"Getting Started with Python","lvl2":"Topics"},"type":"lvl2","url":"/getting-started-python#topics","position":2},{"hierarchy":{"lvl1":"Getting Started with Python","lvl2":"Topics"},"content":"Quickstart: Zero to Python: For the impatient among us: run your first Python code in the cloud!\n\nInstalling and Running Python: Detailed instructions for choosing a Python platform and getting up and running on a laptop, including using the conda package manager.","type":"content","url":"/getting-started-python#topics","position":3},{"hierarchy":{"lvl1":"Basic Version Control with git"},"type":"lvl1","url":"/basic-git","position":0},{"hierarchy":{"lvl1":"Basic Version Control with git"},"content":"","type":"content","url":"/basic-git","position":1},{"hierarchy":{"lvl1":"Basic Version Control with git"},"type":"lvl1","url":"/basic-git#basic-version-control-with-git","position":2},{"hierarchy":{"lvl1":"Basic Version Control with git"},"content":"","type":"content","url":"/basic-git#basic-version-control-with-git","position":3},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Overview:"},"type":"lvl2","url":"/basic-git#overview","position":4},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Overview:"},"content":"The need for version control\n\nBasic git usage\n\nMaking your first git commit\n\nViewing and comparing across the commit history","type":"content","url":"/basic-git#overview","position":5},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Prerequisites"},"type":"lvl2","url":"/basic-git#prerequisites","position":6},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nWhat is GitHub?\n\nNecessary\n\nGitHub user account required\n\nGitHub Repositories\n\nNecessary\n\n\n\nIssues and Discussions\n\nRecommended\n\n\n\nCloning and Forking a Repository\n\nRecommended\n\n\n\nConfiguring your GitHub Account\n\nRecommended\n\n\n\nTime to learn: 45 minutes","type":"content","url":"/basic-git#prerequisites","position":7},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"About version control and git"},"type":"lvl2","url":"/basic-git#about-version-control-and-git","position":8},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"About version control and git"},"content":"","type":"content","url":"/basic-git#about-version-control-and-git","position":9},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"What is version control (and why should we care)?","lvl2":"About version control and git"},"type":"lvl3","url":"/basic-git#what-is-version-control-and-why-should-we-care","position":10},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"What is version control (and why should we care)?","lvl2":"About version control and git"},"content":"Version Control refers generally to systems for managing changes to documents or files. Version control systems let us keep track of what changes were made to a file, when they were made, and by whom. If you’ve ever used “Tracked changes” on a Word document with multiple authors, then you’ve seen a form of version control in action (though NOT one that is well suited to working with computer code!).\n\nThe need for version control is particularly acute when working with computer code, where small changes to the text can have huge impacts on the results of running the code.\n\nDo you have a directory somewhere on your machine right now with five different versions of a Python script like this?analysis_script_OLD.py\nanalysis_script.py\nanalysis_script_09122021.py\nanalysis_script_09122021_edit.py\nanalysis_script_NEW.py\n\nA Version Control System (VCS) like git will replace this mess with a well-ordered and labelled history of edits that you can freely browse through, and will greatly simplify collaborating with other people on writing new code.","type":"content","url":"/basic-git#what-is-version-control-and-why-should-we-care","position":11},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"What is git?","lvl2":"About version control and git"},"type":"lvl3","url":"/basic-git#what-is-git","position":12},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"What is git?","lvl2":"About version control and git"},"content":"","type":"content","url":"/basic-git#what-is-git","position":13},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl4":"Git is not GitHub","lvl3":"What is git?","lvl2":"About version control and git"},"type":"lvl4","url":"/basic-git#git-is-not-github","position":14},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl4":"Git is not GitHub","lvl3":"What is git?","lvl2":"About version control and git"},"content":"That’s the first thing to understand. GitHub is a web-based platform for hosting code and collaborating with other people. On the other hand, git is a command-line Version Control System (VCS) that you can download and install. It runs on your local computer as well as under the hood on GitHub. You need to understand something about version control with git in order to use many of GitHub’s collaboration features.","type":"content","url":"/basic-git#git-is-not-github","position":15},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl4":"A little history and nomenclature","lvl3":"What is git?","lvl2":"About version control and git"},"type":"lvl4","url":"/basic-git#a-little-history-and-nomenclature","position":16},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl4":"A little history and nomenclature","lvl3":"What is git?","lvl2":"About version control and git"},"content":"Git has been around \n\nsince the mid-2000s. It was originally written by Linus Torvalds specifically for use in development of the Linux kernel. Git is \n\nFOSS and comes pre-installed on many Linux and Mac OS systems.\n\nThere are many other VCSs out there. A few that you might encounter in scientific codebases include \n\nSubversion, \n\nMercurial, and \n\nCVS. However, git is overwhelmingly the VCS of choice for open-source projects in the Scientific Python ecosystem these days (as well as among software developers more generally).\n\nThere is no universally agreed-upon meaning of the name “git”. From the \n\ngit project’s own README file:\n\nThe name “git” was given by Linus Torvalds when he wrote the very first version. He described the tool as “the stupid content tracker” and the name as (depending on your mood):\n\nrandom three-letter combination that is pronounceable, and not actually used by any common UNIX command. The fact that it is a mispronunciation of “get” may or may not be relevant.\n\nstupid. contemptible and despicable. simple. Take your pick from the dictionary of slang.\n\n“global information tracker”: you’re in a good mood, and it actually works for you. Angels sing, and a light suddenly fills the room.\n\n“goddamn idiotic truckload of sh*t”: when it breaks","type":"content","url":"/basic-git#a-little-history-and-nomenclature","position":17},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl4":"Git is a distributed VCS","lvl3":"What is git?","lvl2":"About version control and git"},"type":"lvl4","url":"/basic-git#git-is-a-distributed-vcs","position":18},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl4":"Git is a distributed VCS","lvl3":"What is git?","lvl2":"About version control and git"},"content":"Aside from being free and widely deployed, an important distinguishing feature of git is that it is a distributed Version Control System. Essentially this means that every git directory on every computer is a complete independent repository with complete history.\n\nWhen we cloned the \n\ngithub-sandbox repository back in the \n\nCloning and Forking section, we not only copied the current repository files but also the entire revision history of the repo.\n\nIn this section we are going to explore basic git usage on our local computer. Nothing that we do here is going to affect other copies of the repositories stored elsewhere. So don’t worry about breaking anything!\n\nLater, we will explore how to collaborate on code repositories using GitHub. But in keep in mind the basic idea that all git repos are equal and independent! You will have separate copies of repos stored on your local machine and in your GitHub organization.\n\nNow that we are oriented, let’s dive into some basic git usage with the \n\ngithub-sandbox repository!","type":"content","url":"/basic-git#git-is-a-distributed-vcs","position":19},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Inspect a git repository with git status"},"type":"lvl2","url":"/basic-git#inspect-a-git-repository-with-git-status","position":20},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Inspect a git repository with git status"},"content":"First, make sure you followed the steps in the \n\nCloning a repository lesson to make a clone of the github-sandbox repo on your local computer. Navigate to wherever you saved your copy of the repo.\n\nNow meet your new best friend:git status\n\nwhich will always give you information about the current git repo. Try it! You should see something like this:On branch main\nYour branch is up to date with 'origin/main'.\n\nnothing to commit, working tree clean\n\nTwo really important things here:\n\nThe first line show you the current branch (here called main). We’ll cover branching in more detail in the \n\nnext lesson, but basically each branch is a completely independent version with its own history. When we start making changes to files, we’ll have to pay attention to which branch we’re currently on.\n\nThe last line nothing to commit, working tree clean tells us that we haven’t made any changes to files.\n\nYou’ll want to usegit status\n\nfrequently to keep track of things in your repos.","type":"content","url":"/basic-git#inspect-a-git-repository-with-git-status","position":21},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Make some changes"},"type":"lvl2","url":"/basic-git#make-some-changes","position":22},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Make some changes"},"content":"Version control is all about keeping track of changes made to files. So let’s make some changes!\n\nYou may have noticed that the file sample.txt in the github-sandbox repository contains a typo. Here we’re going to fix the error and save it locally.","type":"content","url":"/basic-git#make-some-changes","position":23},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Create a new feature branch","lvl2":"Make some changes"},"type":"lvl3","url":"/basic-git#create-a-new-feature-branch","position":24},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Create a new feature branch","lvl2":"Make some changes"},"content":"Before we start editing files, the first thing to do is to create a new branch where we can safely make any changes we want.\n\nTip\n\nWhile there’s nothing stopping us from making changes directly to the main branch, it’s often best to avoid this! The reason is that it makes collaboration trickier. See the \n\nlesson on Pull Requests.\n\nLet’s create and checkout a new branch in one line:git checkout -b fix-typo\n\nNow try your new best friend again:git status\n\nYou should see something like this:On branch fix-typo\nnothing to commit, working tree clean\n\nThis tells us that we have switched over to a new branch called fix-typo, but there are not (yet) any changes to the files in the repo.","type":"content","url":"/basic-git#create-a-new-feature-branch","position":25},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Time to make some changes","lvl2":"Make some changes"},"type":"lvl3","url":"/basic-git#time-to-make-some-changes","position":26},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Time to make some changes","lvl2":"Make some changes"},"content":"Now do the following:\n\nUsing your favorite text editor, open the file github-sandbox/sample.txt.\n\nReplace the word Fxing with the much more satisfying Fixing.\n\nSave the changes.\n\nRevisit your new best friend git status. It should now show something like this:On branch fix-typo\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n\tmodified:   sample.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\nHere git is telling us that the file sample.txt does not match what’s in the repository.\n\nOf course we know what changed in that file because we just finished editing it. But here’s a quick and easy way to see the changes:git diff\n\nwhich should show you something like this:diff --git a/sample.txt b/sample.txt\nindex 4bc074c..edc31c0 100644\n--- a/sample.txt\n+++ b/sample.txt\n@@ -4,6 +4,6 @@ We can use it to demonstrate making pull requests or raising issues in a GitHub\n\n One good way to contribute to a project is to make additions and/or edits to documentation!\n\n-Fxing something as simple as a typo is a great way to get started as a contributor!\n+Fixing something as simple as a typo is a great way to get started as a contributor!\n\n Or, consider adding some more content to this file.\n\nWe can see here that git diff finds the line(s) where our current file differs from what’s in the repo, along with a few lines before and after for context.\n\nThe next step is to add our changes to the “official” history of our repo. This is a two-step process (staging and committing).","type":"content","url":"/basic-git#time-to-make-some-changes","position":27},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Stage and commit our changes"},"type":"lvl2","url":"/basic-git#stage-and-commit-our-changes","position":28},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Stage and commit our changes"},"content":"The commit is the centerpiece of the git workflow. Each commit is a specific set of changes, additions, and/or deletions of files that gets added to the official history of the repository.","type":"content","url":"/basic-git#stage-and-commit-our-changes","position":29},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Staging","lvl2":"Stage and commit our changes"},"type":"lvl3","url":"/basic-git#staging","position":30},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Staging","lvl2":"Stage and commit our changes"},"content":"Before we make a commit, we must first stage our changes. Think of staging simply as “getting ready to commit”. The two-step process can help avoid accidentally committing something that wasn’t ready.\n\nTo stage our changes, we use git add like this:git add sample.txt\n\nand now our new best friend tells usOn branch fix-typo\nChanges to be committed:\n  (use \"git restore --staged <file>...\" to unstage)\n\tmodified:   sample.txt\n\n\nNow we see that all-important line Changes to be committed, telling us the contents of our staging area.\n\nIf you made a mistake (e.g., staged the wrong file), you can always unstage using git restore as shown in the git status output. Nothing is permanent until we commit!\n\n(And if you accidentally commit the wrong thing? Don’t worry, you can always “go back in time” to previous commits -- see below!)","type":"content","url":"/basic-git#staging","position":31},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Committing","lvl2":"Stage and commit our changes"},"type":"lvl3","url":"/basic-git#committing","position":32},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Committing","lvl2":"Stage and commit our changes"},"content":"It’s time to make a commitment. We can now permanently add our edit to the history of our fix-typo branch by doing this:git commit -m 'Fix the typo'\n\nNote\n\nEvery commit should have a “message” that explains briefly what the commit is for. Here we set the commit message with the -m flag and chose some descriptive text. Note, it’s critical to have those quotes around 'Fix the typo'. Otherwise the command shell will misinterpret what you are trying to do.\n\nNow when we do git status we seeOn branch fix-typo\nnothing to commit, working tree clean\n\nAnd we’re back to a clean state! We have now added a new permanent change to the history of our repo (or more specifically, to this branch of the repo).","type":"content","url":"/basic-git#committing","position":33},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Going back in time"},"type":"lvl2","url":"/basic-git#going-back-in-time","position":34},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Going back in time"},"content":"Each commit is essentially a snapshot in time of the state of the repo. So how can we look back on that history, or revert back to a previous version of a file?","type":"content","url":"/basic-git#going-back-in-time","position":35},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Viewing the commit history with git log","lvl2":"Going back in time"},"type":"lvl3","url":"/basic-git#viewing-the-commit-history-with-git-log","position":36},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Viewing the commit history with git log","lvl2":"Going back in time"},"content":"A simple way to see this history of the current branch is this:git log\n\nYou’ll see something like this:commit 7dca0292467e4bbd73643556f83fd1c52b5c113c (HEAD -> fix-typo)\nAuthor: Brian Rose <brose@albany.edu>\nDate:   Mon Jan 17 11:31:49 2022 -0500\n\n    Fix the typo\n\ncommit 35fcbd991f911e170df550db58f74a082ba18b50 (origin/main, origin/HEAD, main)\nAuthor: Kevin Tyle <ktyle@albany.edu>\nDate:   Thu Jan 13 11:29:40 2022 -0500\n\n    Close docstring quote on sample.py\n\ncommit e56ea58071f150ec00904a50341a672456cbcb8f\nAuthor: Kevin Tyle <ktyle@albany.edu>\nDate:   Tue Jan 11 14:15:31 2022 -0500\n\n    Create sample.md\n\ncommit f98d05e312d19a84b74c45402a2904ab94d86e45\nAuthor: Kevin Tyle <ktyle@albany.edu>\nDate:   Tue Jan 11 13:58:09 2022 -0500\n\n    Create sample.py\n\nwhich shows the last few commits on this branch, including the commit number, author, timestamp, and commit message. You can page down to see the rest of the history\nor just press Q to exit git log!\n\nNote\n\nEvery commit has a unique hexadecimal checksum code like 7dca0292467e4bbd73643556f83fd1c52b5c113c. Your history will look a little different from the above!","type":"content","url":"/basic-git#viewing-the-commit-history-with-git-log","position":37},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Checking out a previous commit","lvl2":"Going back in time"},"type":"lvl3","url":"/basic-git#checking-out-a-previous-commit","position":38},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Checking out a previous commit","lvl2":"Going back in time"},"content":"Let’s say you want to retrieve the file sample.txt from the previous commit. Two possible reasons why:\n\nYou just want to take a quick look at something in the previous commit, but then go back to the current version. That’s what we’ll do here.\n\nMaybe you don’t like the most recent commit and want to do some new edits starting from the previous commit -- in effect, undoing the most recent commit and going back in time. The simplest way to do this is to create a new branch starting from the previous commit. We’ll cover branches more fully in the next lesson.\n\nTo retrieve the previous commit, just use git checkout and the unique number code which you can just copy and paste from the git log output:git checkout 35fcbd991f911e170df550db58f74a082ba18b50\n\nYou may see output that looks like this:Note: switching to '35fcbd991f911e170df550db58f74a082ba18b50'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by switching back to a branch.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -c with the switch command. Example:\n\n  git switch -c <new-branch-name>\n\nOr undo this operation with:\n\n  git switch -\n\nTurn off this advice by setting config variable advice.detachedHead to false\n\nHEAD is now at 35fcbd9 Close docstring quote on sample.py\n\n(the details may vary depending on what version of git you are running).\n\nBy detached HEAD, git is telling us that we are NOT on the most recent commit in this branch.\n\nIf you inspect sample.txt in your editor, you will see that the typo Fxing is back!\n\nAs the git message above is reminding us, it’s possible to create an entirely new branch with changes that we make from this point in the history using git switch -c. But for now, let’s just go back to the most recent commit on our fix-typo branch:git checkout fix-typo","type":"content","url":"/basic-git#checking-out-a-previous-commit","position":39},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Comparing versions"},"type":"lvl2","url":"/basic-git#comparing-versions","position":40},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Comparing versions"},"content":"We already saw one use of the git diff command to look at changes in a repo. By default git diff will compare the currently saved files against the most recent commit.\n\nWe can also use git diff to compare across commits within a branch, or between two different branches. Here are some examples.","type":"content","url":"/basic-git#comparing-versions","position":41},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Compare across commits","lvl2":"Comparing versions"},"type":"lvl3","url":"/basic-git#compare-across-commits","position":42},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Compare across commits","lvl2":"Comparing versions"},"content":"To compare across any commits in our history, we again use the unique commit checksum that we listed with git log:git diff HEAD 35fcbd991f911e170df550db58f74a082ba18b50\n\ngivesdiff --git a/sample.txt b/sample.txt\nindex edc31c0..4bc074c 100644\n--- a/sample.txt\n+++ b/sample.txt\n@@ -4,6 +4,6 @@ We can use it to demonstrate making pull requests or raising issues in a GitHub\n\n One good way to contribute to a project is to make additions and/or edits to documentation!\n\n-Fixing something as simple as a typo is a great way to get started as a contributor!\n+Fxing something as simple as a typo is a great way to get started as a contributor!\n\n Or, consider adding some more content to this file.\n\nNote\n\nHere we use HEAD as an alias for the most recent commit.","type":"content","url":"/basic-git#compare-across-commits","position":43},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Compare across branches","lvl2":"Comparing versions"},"type":"lvl3","url":"/basic-git#compare-across-branches","position":44},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Compare across branches","lvl2":"Comparing versions"},"content":"Recall that, since we have done all our editing in a new branch, the main branch still has the typo!\n\nWe can see this with git diff using the .. notation to compare two branches:git diff main..fix-typo\n\nThe output is very similar:diff --git a/sample.txt b/sample.txt\nindex 4bc074c..edc31c0 100644\n--- a/sample.txt\n+++ b/sample.txt\n@@ -4,6 +4,6 @@ We can use it to demonstrate making pull requests or raising issues in a GitHub\n\n One good way to contribute to a project is to make additions and/or edits to documentation!\n\n-Fxing something as simple as a typo is a great way to get started as a contributor!\n+Fixing something as simple as a typo is a great way to get started as a contributor!\n\n Or, consider adding some more content to this file.\n\nThe git diff command is a powerful comparison tool (and maybe your second new best friend). For many more detail on its usage, see the \n\ngit documentation.","type":"content","url":"/basic-git#compare-across-branches","position":45},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Git commands mini-reference"},"type":"lvl2","url":"/basic-git#git-commands-mini-reference","position":46},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Git commands mini-reference"},"content":"","type":"content","url":"/basic-git#git-commands-mini-reference","position":47},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Commands we used in this tutorial","lvl2":"Git commands mini-reference"},"type":"lvl3","url":"/basic-git#commands-we-used-in-this-tutorial","position":48},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Commands we used in this tutorial","lvl2":"Git commands mini-reference"},"content":"git status: see what branch we’re on and what state our repo is in.\n\ngit checkout: switch between branches (use the -b flag to create a new branch and check it out)    git checkout -b new-branch-name\n    git checkout <unique-code-of-commit>\n    git checkout branch-name\n\ngit diff: compare files between current version and last commit (default), between two commits, or between two branches.    git diff commit-one commit-two\n    git diff branch-one..branch-two\n\ngit add: stage a file for a commit.    git add file-name\n\ngit commit: create a new commit with the staged files.    git commit -m 'message/comment between quotation marks'\n\ngit log: see the commit history of our branch.\n\nPress Q to exit","type":"content","url":"/basic-git#commands-we-used-in-this-tutorial","position":49},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Some other git commands you’ll want to know","lvl2":"Git commands mini-reference"},"type":"lvl3","url":"/basic-git#some-other-git-commands-youll-want-to-know","position":50},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"Some other git commands you’ll want to know","lvl2":"Git commands mini-reference"},"content":"We’ll cover many of these in subsequent sections.\n\ngit branch: list all the branch in the repo\n\ngit mv and git rm: git-enhanced versions of the mv (move file) and rm (remove file) commands. These will automatically stage the changes in your current branch.\n\ngit merge: merge changes from one branch into another.\n\ngit push and git pull: export or input changes between your local branch and a remote repository (e.g. hosted on GitHub).\n\ngit init: create a brand-new repo in the current directory","type":"content","url":"/basic-git#some-other-git-commands-youll-want-to-know","position":51},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Summary"},"type":"lvl2","url":"/basic-git#summary","position":52},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"Summary"},"content":"Version control is an important tool for working with code files (or anything that is saved as plain text).\n\ngit is the most common version control software in use today.\n\ngit status is your new best friend because it gives you a quick view into what’s going on in a git repository.\n\nEvery branch of a git repository has a history which is a series of numbered and labelled commits.\n\nYou can view this history with git log\n\nMaking a new commit is a two-step process with git add and git commit.\n\nCommits are non-destructive, meaning you can always go back in time to previous commits.","type":"content","url":"/basic-git#summary","position":53},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/basic-git#whats-next","position":54},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl3":"What’s Next?","lvl2":"Summary"},"content":"Next we’ll explore the concept of branching in git repositories in more detail, including how to merge changes made on one branch into another branch.","type":"content","url":"/basic-git#whats-next","position":55},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"References"},"type":"lvl2","url":"/basic-git#references","position":56},{"hierarchy":{"lvl1":"Basic Version Control with git","lvl2":"References"},"content":"Official git documentation\n\nThe Software Carpentries beginner lessons on git","type":"content","url":"/basic-git#references","position":57},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub"},"type":"lvl1","url":"/contribute-to-pythia","position":0},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub"},"content":"","type":"content","url":"/contribute-to-pythia","position":1},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub"},"type":"lvl1","url":"/contribute-to-pythia#contribute-to-project-pythia-via-github","position":2},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub"},"content":"","type":"content","url":"/contribute-to-pythia#contribute-to-project-pythia-via-github","position":3},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub","lvl2":"Overview:"},"type":"lvl2","url":"/contribute-to-pythia#overview","position":4},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub","lvl2":"Overview:"},"content":"Suggest a change\n\nMake the edits\n\nCreate a Pull Request","type":"content","url":"/contribute-to-pythia#overview","position":5},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub","lvl2":"Prerequisites"},"type":"lvl2","url":"/contribute-to-pythia#prerequisites","position":6},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nWhat is GitHub\n\nNecessary\n\n\n\nGitHub Repositories\n\nNecessary\n\n\n\nCloning and Forking\n\nNecessary\n\n\n\nBasic Version Control with git\n\nNecessary\n\n\n\nIssues and Discussions\n\nRecommended\n\n\n\nBranches\n\nNecessary\n\n\n\nPull Requests\n\nNecessary\n\n\n\nReviewing Pull Requests\n\nRecommended\n\n\n\nGitHub Workflows\n\nNecessary\n\n\n\nTime to learn: 30 minutes\n\nNow that you have become more familiar with how to use Git and GitHub, you might have an idea or some material that you want to contribute to Project Pythia! The \n\nProject Pythia Contributor’s Guide describes the steps required to submit a PR to any of Project Pythia’s repos. Here, we will go through an example of submitting a PR to pythia-foundations.","type":"content","url":"/contribute-to-pythia#prerequisites","position":7},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub","lvl2":"Suggest a change"},"type":"lvl2","url":"/contribute-to-pythia#suggest-a-change","position":8},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub","lvl2":"Suggest a change"},"content":"One simple way to contribute is to fix a typo or suggest a change to one of the tutorials. For example, in the \n\nComputations and Masks with Xarray tutorial, let’s suggest a clarification that the sea surface temperature is called tos in the dataset we are using.\n\nWe could open an issue to suggest this change in order to get feedback on the idea before we take the time to edit files, but since this is such a small change, let’s just create a PR.","type":"content","url":"/contribute-to-pythia#suggest-a-change","position":9},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub","lvl2":"Make the edits"},"type":"lvl2","url":"/contribute-to-pythia#make-the-edits","position":10},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub","lvl2":"Make the edits"},"content":"We will follow the \n\nForking Workflow described in the previous section of this tutorial, assuming pythia-foundations has already been forked:\n\nCreate a new branch with a descriptive name\n\nMake the changes and commit them locally\n\nPush to the remote repository\n\nOpen a PR on GitHub\n\nFirst, making the new branch,git branch clarify-sst-tos\ngit checkout clarify-sst-tos\n\nThere are a variety of ways to make changes, depending on the type of file, as well as preference. Here we want to edit a Jupyter Notebook (file extension .ipynb), so we can use JupyterLab. We find the file of interest at /core/xarray/computation-masking.ipynb and add in some text:\n\nAfter saving and exiting (and checking for changes with a git status), we commit with the following:git add core/xarray/computation-masking.ipynb\ngit commit -m 'Mention that SST is called tos in the model'\n\nThen pushing to our remote aliased origin:git push origin clarify-sst-tos","type":"content","url":"/contribute-to-pythia#make-the-edits","position":11},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub","lvl2":"Create a Pull Request"},"type":"lvl2","url":"/contribute-to-pythia#create-a-pull-request","position":12},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub","lvl2":"Create a Pull Request"},"content":"Now, going to our remote repo on GitHub, forked from pythia-foundations, we see that recent changes have been made. By clicking on the “Compare & pull request” button, we can open a PR, proposing that our changes be merged into the main branch of ProjectPythia/pythia-foundations.\n\nProject Pythia has an automated reviewer system: when a PR is created, two members of the organization will be randomly chosen to review it. If your PR is not immediately ready to be approved and merged, open it as a draft to delay the review process. As shown in this \n\nGit Branches section, the “Draft pull request” button is found using the arrow on the “Create pull request” button.\n\nLet’s add the content tag and open this one as a draft for now:\n\nFor any PR opened in pythia-foundations, there will be a few checks that need to pass before merging is allowed. Once the deploy-book / build check has completed (which will likely take a few minutes), there will be a Deployment Preview URL commented by the github-actions bot that will take you to a build of the Pythia Foundations book with your edits. There you can ensure your edits show up as expected.\n\nOnce it is ready, click “Ready for review” to take it out of draft mode. Now we wait for any comments or reviews!","type":"content","url":"/contribute-to-pythia#create-a-pull-request","position":13},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub","lvl2":"Summary"},"type":"lvl2","url":"/contribute-to-pythia#summary","position":14},{"hierarchy":{"lvl1":"Contribute to Project Pythia via GitHub","lvl2":"Summary"},"content":"You can contribute to Project Pythia by suggesting edits or adding content with a Pull Request","type":"content","url":"/contribute-to-pythia#summary","position":15},{"hierarchy":{"lvl1":"Git Branches"},"type":"lvl1","url":"/git-branches","position":0},{"hierarchy":{"lvl1":"Git Branches"},"content":"","type":"content","url":"/git-branches","position":1},{"hierarchy":{"lvl1":"Git Branches"},"type":"lvl1","url":"/git-branches#git-branches","position":2},{"hierarchy":{"lvl1":"Git Branches"},"content":"Git “branches” are an important component of many Git and GitHub workflows. If you plan to use GitHub to manage your own resources, or contribute to a GitHub hosted project, it is essential to have a basic understanding of what branches are and how to use them. For example, the best practices for a simple workflow for suggesting changes to a GitHub repository are: create your own fork of the repository, make a branch from your fork where your changes are made, and then suggest these changes move to the upstream repository with a Pull Request. This section of the GitHub chapter assumes you have read the prior GitHub sections, are at least somewhat familiar with git commands and the vocabulary (“cloning,” “forking,” “merging,” “Pull Request” etc), and that you have already created your own fork of the \n\nGitHub Sandbox Repository hosted by Project Pythia.","type":"content","url":"/git-branches#git-branches","position":3},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Overview:"},"type":"lvl2","url":"/git-branches#overview","position":4},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Overview:"},"content":"What are Git Branches\n\nCreating a New Branch\n\nSwitching Branches\n\nSetting up a Remote Branch\n\nMerging Branches\n\nDeleting Branches\n\nUpdating Your Branches\n\nComplete Workflow","type":"content","url":"/git-branches#overview","position":5},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Prerequisites"},"type":"lvl2","url":"/git-branches#prerequisites","position":6},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nWhat is GitHub?\n\nNecessary\n\nGitHub user account required\n\nGitHub Repositories\n\nNecessary\n\n\n\nIssues and Discussions\n\nRecommended\n\n\n\nCloning and Forking a Repository\n\nNecessary\n\n\n\nConfiguring your GitHub Account\n\nRecommended\n\n\n\nBasic Version Control with git\n\nNecessary\n\n\n\nTime to learn: 30 minutes","type":"content","url":"/git-branches#prerequisites","position":7},{"hierarchy":{"lvl1":"Git Branches","lvl2":"What are Git branches?"},"type":"lvl2","url":"/git-branches#what-are-git-branches","position":8},{"hierarchy":{"lvl1":"Git Branches","lvl2":"What are Git branches?"},"content":"Git branches allow for non-linear or differing revision histories of a repository. At a point in time, you can split your repository into multiple development paths (branches) where you can make different commits in each, typically with the ultimate intention of merging these branches and development changes together at a later time.\n\nBranching is one of git’s methods for helping with collaborative document editing, much like “change tracking” in Google Docs or Microsoft Word. It enables multiple people to edit copies of the same document content, while reducing or managing edit collisions, and with the ultimate aim of merging everyone’s changes together later. It also allows the same person to edit multiple copies of the same document, but with different intentions. Some reasons for wanting to split your repository into multiple paths (i.e. branches) is to experiment with different methods of solving a problem (before deciding which method will ultimately be merged) and to work on different problems within the same codebase (without confusing which code changes are relevant to which problem).\n\nThese branches can live on your computer (local) or on GitHub (remote). They are brought together through Git pushes, pulls, merges, and Pull Requests. Pushing is how you transfer changes from your local repository to a remote repository. Pulling is how you fetch upstream changes into your branch. Merging is how you piece the forked history back together again (i.e. join two branches). And Pull Requests are how you suggest the changes you’ve made on your branch to the upstream codebase.\n\nPull Requests\n\nWe will cover \n\nPull Requests more in-depthly in the next section.\n\nOne rule of thumb is for each development feature to have its own development branch until that feature is ready to be added to the upstream (remote) codebase. This allows you to compartmentalize your Pull Requests so that smaller working changes can be merged upstream independently of one another. For example, you might have a complete or near-complete feature on its own branch with an open Pull Request awaiting review. While you wait for feedback from the team before merging it, you can still work on a second feature on a second branch without affecting your first feature’s Pull Request. We encourage you to always do your work in a designated branch.","type":"content","url":"/git-branches#what-are-git-branches","position":9},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Creating a New Branch"},"type":"lvl2","url":"/git-branches#creating-a-new-branch","position":10},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Creating a New Branch"},"content":"Have you forked the repository?\n\nHaving forked (NOT just cloned) the \n\nGitHub Sandbox Repository is essential for following the steps in this book chapter. See the chapter on \n\nGitHub Cloning and Forking.\n\n\nThe above flowchart demonstrates forking a remote repository, labeled “Upstream”, creating a local copy, labeled “Clone”, creating a new branch, “branchA”, and adding two commits, C3 and C4, to “branchA” of the local clone of the forked repository. Different commits can be added to different branches in any order without depending on or knowing about each other.\n\nFrom your terminal, navigate to your local clone of your Github-Sandbox Repository fork:cd github-sandbox\n\nLet’s begin by checking the status of our repository:git status\n\nYou will see that you are already on a branch called “main”. And that this branch is up-to-date with “origin/main” and has nothing to commit.\n\nThe Main Branch\n\nHistorically, the main branch was called the master branch. The name change was relatively recent, so all of your GitHub repositories may not reflect this yet. See instructions to change your branch name at \n\nGithub’s Branch Renaming documentation.\n\nNow check the status of your remote repository withgit remote -v\n\nWe are set up to pull (denoted as ‘fetch’ in the output above) and push from the same remote repository.\n\nNext, check all of your exising Git branches with:git branch -a\n\nYou will see one local branch (main) and your remote branch (remotes/origin/HEAD and remotes/origin/main, where HEAD points to main). HEAD is the pointer to the current branch reference, or in essence, a pointer to your last commit. More on this in a later section.\n\nNow, before we make some sample changes to our codebase, let’s create a new branch where we’ll make these changes:git branch branchA\n\nCheck that this branch was created with:git branch\n\nThis will display the current and the new branch. You’ll notice that current or active branch, indicated by the “*” is still the main branch. Thus, any changes we make to the contents of our local repository will still be made on main. We will need to switch branches to work in the new branch, branchA.","type":"content","url":"/git-branches#creating-a-new-branch","position":11},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Switching Branches"},"type":"lvl2","url":"/git-branches#switching-branches","position":12},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Switching Branches"},"content":"To switch branches use the command git checkout as in:git checkout branchA\n\nTo check your current branch use git status:git status\n\nNotice that git status doesn’t say anything about being up-to-date, as before. This is because this branch only exists locally, not in our upstream GitHub fork.","type":"content","url":"/git-branches#switching-branches","position":13},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Setting up a Remote Branch"},"type":"lvl2","url":"/git-branches#setting-up-a-remote-branch","position":14},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Setting up a Remote Branch"},"content":"While your clone lives locally on your laptop, a remote branch exists on your GitHub server. You have to tell GitHub about your local branch before these changes are reflected remotely in your upstream fork.\n\n\nThe above flowchart demonstrates pushing two new local commits (C3 and C4) to the corresponding remote branch. Before the push, the changes from these commits exist ONLY locally and are not represented on your upstream GitHub repository. After the push, everything is up-to-date.\n\nBefore we push this branch upstream, let’s make some sample changes (like C3 or C4) by creating a new empty file, with the ending “.py”.touch hello.py\n\nNote\n\ntouch is not a Windows native command. You can use type nul > hello.py to create an empty file instead.\n\nYou can check that this file has been created by comparing an ls before and after this command, and also with a git status that will show your new untracked file.\n\ngit add and git commit your new file and check the status again.\n\nYour new branch is now one commit ahead of your main branch. You can see this with a git log.\n\nIn a real workflow, you would continue making edits and git commits on a branch until you are ready to push up to GitHub.\n\nTry to do this withgit push\n\nYou will get an error message, “fatal: The current branch branchA has no upstream branch.” So what is the proper method for getting our local branch changes up to GitHub?\n\nFirst, we need to set an upstream branch to direct our local push to:git push --set-upstream origin branchA\n\nThankfully, Git provided this command in the previous error message. If you cloned using HTTPS, you will be asked to enter your username and password, as described in \n\nGitHub’s PAT Creation page.\n\nWe can see that this worked by doing a git branch -a\n\nNotice the new branch called remotes/origin/branchA. And when you do a git status you’ll see that we are up to date with this new remote branch.\n\nOn future commits you will not have to repeat these steps, as your remote branch will already be established. Simply push with git push to have your remote branch reflect your future local changes.","type":"content","url":"/git-branches#setting-up-a-remote-branch","position":15},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Merging Branches"},"type":"lvl2","url":"/git-branches#merging-branches","position":16},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Merging Branches"},"content":"Merging is how you bring your split branches of a repository back together again.\n\nIf you want to merge two local branches together, the steps are as follows:\n\nLet’s assume your two branches are named branchA and branchB, and you want your changes from branchB to now be reflected in branchA\n\nFirst checkout the branch you want to merge INTO:git checkout branchA\n\nThen execute a merge:git merge branchB\n\nIf there were competing edits in the 2 branches that Git cannot automatically resolve, a merge conflict occurs. This typically happens if edits are to the same line in different commits. Conflicts can be \n\nresolved in the command line or in your GUI of choice (such as Visual Studio Code).\n\nA Pull Request is essentially a merge that happens on an upstream remote. We will continue this demonstration and cover the specifics of merging via a \n\nPull Request more thoroughly in the next section.\n\n\nThe above flowchart demonstrates a simple Pull Request where the upstream main repository has accepted the changes from the feature branch of your fork. The latest commit to the Upstream Main repository is now C4. Your Feature branch can now be safely deleted.","type":"content","url":"/git-branches#merging-branches","position":17},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Deleting Branches"},"type":"lvl2","url":"/git-branches#deleting-branches","position":18},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Deleting Branches"},"content":"After the feature you worked on has been completed and merged, you may want to delete your branch.\n\n\nTo do this locally, you must first switch back to main or any non-target branch. Then you can entergit branch -d <branch>\n\nfor examplegit branch -d branchA\n\nTo delete the branch remotely, typegit push <remote> --delete <branch>.\n\nas ingit push origin --delete jukent/branchA","type":"content","url":"/git-branches#deleting-branches","position":19},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Updating Your Branches"},"type":"lvl2","url":"/git-branches#updating-your-branches","position":20},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Updating Your Branches"},"content":"Previously, we showed you how to merge branches together, combining the changes from two different branches into one. Afterwards you deleted your feature branch branchA. Your local clone and fork of your main branch have now both need to pull from the upstream repository.\n\n\nThe above flowchart demonstrates pulling in the upstream changes from Upstream Main after a Pull Request has been merged, first into your fork and then into your clone. Before continuing to work, with new commits on the feature branch, it is best to pull in the upstream changes.\n\nIn this example, all of the changes to the branches were local and made by a single person, you. In a collaborative environment, other contributors may be making changes to their own feature branches (or main branch), which will ultimately be pushed up to the remote repository. Either way, your branches will become stale and need to be refreshed. The more time that passes by, the more likely this is to happen, particularly for an active GitHub repository. Here we show you how to sync your branches with the upstream branches.\n\nOnce a Pull Request has been merged, you will find that these upstream changes are not automatically included in your fork or your other branches. In order to include the changes from the upstream main branch, you will need to do a git pull.\n\nFirst check if there are any upstream changes:git status\n\nThen, if there are no merge conflicts:git pull\n\ngit pull is a combination of git fetch and git merge. That is it updates the remote tracking branches (git fetch) AND updates your current branch with any new commits on the remote tracking branch (git merge).\n\nThis same concept applies to work in a team setting. Multiple authors will have their own feature branches that merge into the same Upstream Main repository via Pull Requests. It is important for each author to do regular git pulls to stay up to date with each other’s contributions.","type":"content","url":"/git-branches#updating-your-branches","position":21},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Complete Workflow"},"type":"lvl2","url":"/git-branches#complete-workflow","position":22},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Complete Workflow"},"content":"All in all your Git Branching workflow should resemble this flow:\n\n\nFork the upstream repository\n\nCreate a local clone of your upstream fork\n\nCreate and switch to a new branch in local copy\n\nMake changes\n\nAdd and commit changes in branch\n\nPush commits to fork (Set an upstream branch only for first push)\n\nRepeat last three steps as necessary\n\nMerge into upstream main branch via Pull Request\n\nDelete branch from clone and fork\n\nPull upstream changes to main branch of fork and clone","type":"content","url":"/git-branches#complete-workflow","position":23},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Summary"},"type":"lvl2","url":"/git-branches#summary","position":24},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Summary"},"content":"Git Branches allow you to independently work on different features of a project via differing revision histories of a repository.\n\nA useful workflow is to create a new branch locally, switch to it and set up a remote branch. During your revision, push to your upstream branch and pull from main as often as necessary. Then suggest your edits via a Pull Request and, if desired, delete your branch after the merge.","type":"content","url":"/git-branches#summary","position":25},{"hierarchy":{"lvl1":"Git Branches","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/git-branches#whats-next","position":26},{"hierarchy":{"lvl1":"Git Branches","lvl3":"What’s Next?","lvl2":"Summary"},"content":"Opening a Pull Request on GitHub","type":"content","url":"/git-branches#whats-next","position":27},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Resources and references"},"type":"lvl2","url":"/git-branches#resources-and-references","position":28},{"hierarchy":{"lvl1":"Git Branches","lvl2":"Resources and references"},"content":"GitHub.com Help Documentation (GitHub Docs)\n\nXdev Python Tutorial Seminar Series - Github (Kevin Paul)\n\nResolving a Merge Conflict Using the Command Line (GitHub Docs)","type":"content","url":"/git-branches#resources-and-references","position":29},{"hierarchy":{"lvl1":"Cloning and Forking a Repository"},"type":"lvl1","url":"/github-cloning-forking","position":0},{"hierarchy":{"lvl1":"Cloning and Forking a Repository"},"content":"","type":"content","url":"/github-cloning-forking","position":1},{"hierarchy":{"lvl1":"Cloning and Forking a Repository"},"type":"lvl1","url":"/github-cloning-forking#cloning-and-forking-a-repository","position":2},{"hierarchy":{"lvl1":"Cloning and Forking a Repository"},"content":"","type":"content","url":"/github-cloning-forking#cloning-and-forking-a-repository","position":3},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Overview:"},"type":"lvl2","url":"/github-cloning-forking#overview","position":4},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Overview:"},"content":"Cloning and forking a git repository\n\nCloning a repository\n\nForking a repository","type":"content","url":"/github-cloning-forking#overview","position":5},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Prerequisites"},"type":"lvl2","url":"/github-cloning-forking#prerequisites","position":6},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nWhat is GitHub?\n\nNecessary\n\nGitHub user account required\n\nGitHub Repositories\n\nNecessary\n\n\n\nIssues and Discussions\n\nRecommended\n\n\n\nCommand-line shell\n\nHelpful\n\n\n\nTime to learn: 30 minutes","type":"content","url":"/github-cloning-forking#prerequisites","position":7},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Cloning and forking"},"type":"lvl2","url":"/github-cloning-forking#cloning-and-forking","position":8},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Cloning and forking"},"content":"Cloning and forking are two related terms in the GitHub vernacular\nthat, unfortunately, are not always used consistently throughout\nthe web-o-sphere. In Project Pythia we use the term clone to refer to\nmaking a local copy of a remote repository; the source for\nthe copy is a remote repo, and the destination for the copy is your\nlocal laptop/desktop. When working with GitHub, a fork, on the\nother hand, creates a copy of a GitHub repository on GitHub. In other\nwords, both the source and the destination of the fork operations are\nhosted in the cloud on GitHub. Forking is performed via your GitHub\naccount. While the forked repository may be owned by anyone, the\nnewly created repository will be owned by you. Cloning, on the\nother hand, is performed using a Git command. Naturally, since the\ndestination of the clone operation is your local computer, you will\nown the cloned contents. In either case, whether you clone or fork,\nany changes you make to the newly created repository will not impact\nthe original without taking explicit action (e.g. performing a\npush or submitting a Pull Request, the topics of later sections\nin this guide).\n\nCloning and forking are often used together (more on this later).\nThe illustration below demonstrates the operation of a Fork of a\nremote repository (UPSTREAM), followed by a clone of the newly\ncreated ORIGIN.","type":"content","url":"/github-cloning-forking#cloning-and-forking","position":9},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Cloning a repository"},"type":"lvl2","url":"/github-cloning-forking#cloning-a-repository","position":10},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Cloning a repository"},"content":"Cloning is ideal for the following scenarios:\n\nYou wish to download, build, and install the latest version of a software package.\n\nYou would like to experiment with a repository on your local computer, but do not desire to maintain a separate copy of it (termed a fork, to be covered later in this lesson) on your GitHub account.\n\nYou have previously forked a repository to your own GitHub account, and now wish to make changes to it for possible incorporation into the original repo, via a Pull Request.\n\nLet’s consider the 2nd scenario. Say you wish to copy a GitHub repository to a computer you have access to (which could be your own computer, or one you have access to at work or school).\n\nWe’ll use a very basic repo that is part of the \n\nProject Pythia organization as our example.\n\nFirst, point your browser to \n\nhttps://​github​.com​/ProjectPythia​/github​-sandbox:\n\nWe see that in the repository, there exists five files. Above the list of files is this row:\n\nClick on the green Code button to the right:\n\nSelect the HTTPS option, and click on the copy-to-clipboard icon:\n\nTip\n\nThis link points to where the repository “lives” on GitHub. We will use the term origin to refer to this location.\n\nNow, open up a terminal on your local computer, and if desired, cd into a directory that you’d like to house whatever repos you clone. Type git clone, and then paste in the URL that you copied from GitHub (i.e., the origin):git clone https://github.com/ProjectPythia/github-sandbox.git\n\nYou’ll see something like the following:Cloning into 'github-sandbox'...\nremote: Enumerating objects: 15, done.\nremote: Counting objects: 100% (15/15), done.\nremote: Compressing objects: 100% (14/14), done.\nremote: Total 15 (delta 3), reused 0 (delta 0), pack-reused 0\nReceiving objects: 100% (15/15), 7.41 KiB | 2.47 MiB/s, done.\nResolving deltas: 100% (3/3), done.\n\nWindows users\n\nWhile git is typically part of a Linux or Mac OS command-line shell, similar functionality must be installed if you are running Windows. Download and install the \n\nGit for Windows package.\n\nNow, you can cd into the github-sandbox directory which has been created and populated with the exact contents of the origin’s repository at the time you cloned it. If you have a Python installation, you could then typepython sample.py\n\nto run the sample Python script. You should see the following output:Hello, Python learners!\n\nBy virtue of cloning the repo, git automatically registers the URL of the origin’s repository on GitHub. You can show this by typing the following:git remote -v\n\nYou should see:origin  git@github.com:ProjectPythia/github-sandbox.git (fetch)\norigin  git@github.com:ProjectPythia/github-sandbox.git (push)\n\nTip\n\nWe discuss the git command-line interface in the \n\nBasic version control with git lesson.\n\nCongratulations! You have now cloned a GitHub repository!\n\nNow, let’s consider the 3rd scenario for cloning... which involves the related topic of forking.","type":"content","url":"/github-cloning-forking#cloning-a-repository","position":11},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Forking a repository"},"type":"lvl2","url":"/github-cloning-forking#forking-a-repository","position":12},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Forking a repository"},"content":"Forking is similar to cloning, but has a bit more involved workflow. Scenarios where forking a repo is indicated include the following:\n\nYou wish to collaborate on projects that are hosted on GitHub, but you are not one of that project’s maintainers (i.e., you do not have write permissions on it).\n\nYou wish to experiment with changing or adding new features to a project, and do not immediately intend to merge them into the original project’s repo (aka, the upstream repository).\n\nIn a fork, you create a copy of an existing repository, but store it in your own personal GitHub organization (recall that when you create a GitHub account, the organization name is your GitHub user ID).\n\nLet’s say we intend to make some changes to the \n\nProject Pythia Sandbox repo, that ultimately we’ll submit to the original repository as a Pull request.\n\nNote\n\nBe sure you have logged into GitHub at this time!\n\nNotice at the top right of the screen, there is a Fork button:\n\nClick on it:\n\nYou should see your GitHub user ID (if you administer any other GitHub organizations, you will see them as well). Click on your user ID to complete the fork. After a few seconds, your browser will be redirected to the forked repo, now residing in your personal GitHub organization:\n\nNotice that the Fork button on the upper right has incremented by one, and there is also is a line relating your fork to the original repo:\n\nTip\n\nWe discuss branches in the \n\nGit Branches lesson.\n\nYou now have a copy (essentially a clone) of the forked repository, which is now owned by you.\n\nYou could, at this point, select one of the files in the repository and use GitHub’s built-in editor to make changes to these text-based files. However, the typical use case that leverages the collaborative power of GitHub and its command-line cousin, git, involves cloning your forked copy of the repo to your local computer, where you can then perform your edits, and (in the case of software) test them on your system.\n\nCloning your fork is the same as cloning the original repo. Click on the Code button, select the HTTPS protocol, copy the URL to the clipboard, and then run git clone <URL> on your local computer. In this case, you will need to either run this command in a different directory, or rename the destination directory with git clone <URL> <directory-name>, since it will by default use the name of the repo, github-sandbox.\n\nTip\n\nUnlike cloning, forking is not an option supported by the git command-line interface. In other words, git fork is not a valid command.\n\nOnce you’ve cloned the fork to your local machine, try running git remote -v again. You will see that the origin URL now points to your GitHub account or organization.\n\nThe main purpose of cloning and forking a remote repository is so that you can make changes to the contents of those repositories in a safe and version-controlled manner. The process of making changes and submitting them as Pull Requests to the original repository is covered in our lesson on \n\nOpening a Pull Request on GitHub, but the workflow is as follows:\n\nEdit an existing file or files, and/or create new files.\n\nStage your changes by running git add.\n\nCommit your changes by running git commit.\n\n(If you created a fork): Push your changes to your fork by running git push.\n\n(If you did not create a fork): Push your changes to the upstream repository by running git push. This assumes you have write permissions on the upstream repository.\n\nIn GitHub, create a Pull request.","type":"content","url":"/github-cloning-forking#forking-a-repository","position":13},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Summary"},"type":"lvl2","url":"/github-cloning-forking#summary","position":14},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Summary"},"content":"The process of making a local copy of a GitHub repository is called cloning. The destination for the cloned copy is whatever machine you ran the git clone command from.\n\nForking a repository also makes a copy of a GitHub repo, but places it in your GitHub organization in the \n\nGitHub.com cloud.\n\nForking allows you to modify a remote repo, without affecting the original version.\n\nAfter cloning your fork to your local computer, you can make changes to your copy, which you can then submit to the original repo as a \n\nPull request.","type":"content","url":"/github-cloning-forking#summary","position":15},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Things to try"},"type":"lvl2","url":"/github-cloning-forking#things-to-try","position":16},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"Things to try"},"content":"Clone another GitHub-hosted repository that is of interest to you.\n\nTry creating a fork of that repository.","type":"content","url":"/github-cloning-forking#things-to-try","position":17},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl3":"What’s Next?","lvl2":"Things to try"},"type":"lvl3","url":"/github-cloning-forking#whats-next","position":18},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl3":"What’s Next?","lvl2":"Things to try"},"content":"In the next lesson, you will set some configurations on your GitHub account that enable uploads (aka pushes) from your local computer to GitHub. You will also configure notifications on your GitHub account.","type":"content","url":"/github-cloning-forking#whats-next","position":19},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"References"},"type":"lvl2","url":"/github-cloning-forking#references","position":20},{"hierarchy":{"lvl1":"Cloning and Forking a Repository","lvl2":"References"},"content":"Cloning vs Forking (GitHub Support)\n\nWhat the Fork?(GitHub Community)","type":"content","url":"/github-cloning-forking#references","position":21},{"hierarchy":{"lvl1":"Issues and Discussions"},"type":"lvl1","url":"/github-issues","position":0},{"hierarchy":{"lvl1":"Issues and Discussions"},"content":"","type":"content","url":"/github-issues","position":1},{"hierarchy":{"lvl1":"Issues and Discussions"},"type":"lvl1","url":"/github-issues#issues-and-discussions","position":2},{"hierarchy":{"lvl1":"Issues and Discussions"},"content":"","type":"content","url":"/github-issues#issues-and-discussions","position":3},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"Overview:"},"type":"lvl2","url":"/github-issues#overview","position":4},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"Overview:"},"content":"What are Issues and Discussions?\n\nExamine an existing Issue\n\nExamine an existing Discussion","type":"content","url":"/github-issues#overview","position":5},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"Prerequisites"},"type":"lvl2","url":"/github-issues#prerequisites","position":6},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nWhat is GitHub?\n\nNecessary\n\n\n\nGitHub Repositories\n\nNecessary\n\n\n\nTime to learn: 5 minutes","type":"content","url":"/github-issues#prerequisites","position":7},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"What are Issues and Discussions?"},"type":"lvl2","url":"/github-issues#what-are-issues-and-discussions","position":8},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"What are Issues and Discussions?"},"content":"GitHub provides two different, but related mechanisms for communicating\nwithin a repository about a project: Issues and Discussions.\nIssues are more like “todo” items; they are task-focused. For example, Issues\nare often used to report and track bugs, request new features, or\nperhaps note a performance problem. Ultimately, the maintainers of\na project may resolve the issue by fixing the bug, adding the\nfeature, etc., and then closing the resolved issue, marking the\ntask as completed. GitHub Discussions, much like the name implies,\nare more open ended, and may not have a resolution. Asking about a\ntopic, discussing the merits of a new feature, or even advertising\nan event, such as a tutorial for your project, are all examples\nof Discussions.\n\nIn the text below we discuss Issues in more detail, followed by\na discussion on Discussions. Keep in mind that when initiating a\nconversation on GitHub, it is often unclear whether something is\nmore suited as an Issue or a Discussion. We, the creators of\nProject Pythia, struggle with this ourselves. If you’re not sure, simply pick\none. Fortunately, the GitHub developers recognized this dilemma, and\nmade it easy to convert Issues into Discussions and vice versa.","type":"content","url":"/github-issues#what-are-issues-and-discussions","position":9},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"Issues"},"type":"lvl2","url":"/github-issues#issues","position":10},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"Issues"},"content":"To get started, let’s take a look at the \n\nIssues page in Project Pythia’s pythia-foundations repository:\n\nBy default, it shows all open Issues, but we can see all \n\nclosed Issues by clicking “Closed”.\n\nIssues, Discussions, and Pull Requests are all numbered for easy reference. By opening, resolving, and then closing an issue, we are leaving behind a searchable public record of what the issue was, why we thought it was important, and how we resolved it. This is great for project management, since it gets old Issues out of the way without actually deleting them.\n\nLet’s now examine \n\nIssue #144.\n\nAs you can see, some broken links were found in one of the Pythia Foundations tutorials, likely because the site being linked recently had its structure changed. An additional comment was added, as well as a label to help filtering/sorting Issues by topic. We then see that this issue was mentioned (by typing the issue number) elsewhere in the repository. In this case, it was mentioned in \n\nPull Request #145, which makes the changes to fix the issue. We can also see that the PR has been merged, which means the changes have been incorporated into the main branch of the code.\n\nLike this example, Issues can notify others of bugs or typos, but they can also be used as “calls to action”, whether you plan on addressing the issue yourself, or are hoping that someone else will be interested in making the changes. Issues \n\n#97 and \n\n#98 are examples of this, in which ideas for changes are proposed and then addressed at a later time.\n\nA new issue can be opened by pressing the “New issue” button on the top right of the Issues page. Depending on the repository, you may be prompted to choose from a template, or you may just see title and text boxes to fill out.","type":"content","url":"/github-issues#issues","position":11},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"Discussions"},"type":"lvl2","url":"/github-issues#discussions","position":12},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"Discussions"},"content":"Discussions, on the other hand, are more open-ended and do not necessarily suggest a change or addition to the repository. Here is the \n\nDiscussions page for Pythia Foundations:\n\nLet’s take a look at \n\nDiscussion #156.\n\nThis discussion brings up a resource relevant to the repository that could help others, but it is not suggesting a change like an issue would. Other Discussions might include announcements, Q&A, or general thoughts about the repository.\n\nGitHub also makes it simple to reference a Discussion in an Issue (and vice versa),\nwhich can help provide background and context for a piece of work.","type":"content","url":"/github-issues#discussions","position":13},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"Summary"},"type":"lvl2","url":"/github-issues#summary","position":14},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"Summary"},"content":"GitHub provides Issues and Discussions to facilitate collaboration.\n\nIssues are specific and actionable, while Discussions are open-ended.\n\nIf you want to discuss a topic and you’re not sure if it is an Issue\nor a Discussion, just pick one. It will be okay. :-)","type":"content","url":"/github-issues#summary","position":15},{"hierarchy":{"lvl1":"Issues and Discussions","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/github-issues#whats-next","position":16},{"hierarchy":{"lvl1":"Issues and Discussions","lvl3":"What’s Next?","lvl2":"Summary"},"content":"We will work through cloning and forking an example repository.","type":"content","url":"/github-issues#whats-next","position":17},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"References"},"type":"lvl2","url":"/github-issues#references","position":18},{"hierarchy":{"lvl1":"Issues and Discussions","lvl2":"References"},"content":"What is GitHub Discussions? A complete guide","type":"content","url":"/github-issues#references","position":19},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub"},"type":"lvl1","url":"/github-pull-request","position":0},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub"},"content":"","type":"content","url":"/github-pull-request","position":1},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub"},"type":"lvl1","url":"/github-pull-request#opening-a-pull-request-on-github","position":2},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub"},"content":"A Pull Request, aka a “merge request,” is an event that occurs when a project contributor begins the process of merging new code changes from a feature branch with the main project repository.","type":"content","url":"/github-pull-request#opening-a-pull-request-on-github","position":3},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"Overview:"},"type":"lvl2","url":"/github-pull-request#overview","position":4},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"Overview:"},"content":"What is a Pull Request?\n\nOpening a Pull Request\n\nPull Request Features\n\nGitHub Workflows","type":"content","url":"/github-pull-request#overview","position":5},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"Prerequisites"},"type":"lvl2","url":"/github-pull-request#prerequisites","position":6},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nWhat is GitHub\n\nNecessary\n\n\n\nGitHub Repositories\n\nNecessary\n\n\n\nCloning and Forking\n\nNecessary\n\n\n\nBasic Version Control with git\n\nNecessary\n\n\n\nIssues and Discussions\n\nRecommended\n\n\n\nBranches\n\nNecessary\n\n\n\nTime to learn: 60 minutes","type":"content","url":"/github-pull-request#prerequisites","position":7},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"What is a Pull Request?"},"type":"lvl2","url":"/github-pull-request#what-is-a-pull-request","position":8},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"What is a Pull Request?"},"content":"A Pull Request (PR) is a formal mechanism for requesting that changes\nthat you have made to one repository are integrated (merged) into\nanother repository. Typically, the changes are reviewed by the\nmaintainers of the destination repository, potentially triggering\na cycle of revisions, before the PR is “merged”, and your changes\nbecome part of the destination repo.\n\nJust like Issues, PRs have\ntheir own discussion forum for communicating about the proposed\nchanges. In fact, not only can maintainers or collaborators communicate\nabout your PR via GitHub, they can also suggest changes and may\neven be able to make changes of their own by pushing follow-up\ncommits. All of the activity, from start to finish, is tracked\ninside of the PR and can be reviewed at any time.\n\nWhen a contributor to a project creates a PR they are requesting\nthat the owners of another destination repository pull a git\nbranch from the contributor’s repository and merge the contents of\nthe branch into a branch of the destination repository. This means\nthat the contributor must provide four pieces of information: the\ncontributor’s repository, the contributor’s branch, the destination\nrepository, and finally, the destination branch.\n\nA typical sequence of steps consists of the following:\n\nA contributor clones a personal remote repository, creating a local copy\n\nThe contributor creates a new branch in their local repository\n\nThe contributor makes changes to the branch and commits them to\ntheir local repository\n\nThe contributor pushes the branch to a remote repository\n\nThe contributor submits a PR via GitHub\n\nAfter the maintainers or collaborators of the destination review\nthe changes, and any suggested revisions are made, the project\nmaintainer merges the feature into the destination repository and\ncloses the PR.","type":"content","url":"/github-pull-request#what-is-a-pull-request","position":9},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"Opening a Pull Request"},"type":"lvl2","url":"/github-pull-request#opening-a-pull-request","position":10},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"Opening a Pull Request"},"content":"The demonstration is a continuation from the \n\nGitHub Branches chapter. Here, we will move from your local terminal to GitHub.","type":"content","url":"/github-pull-request#opening-a-pull-request","position":11},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl3":"Navigate to Your Fork","lvl2":"Opening a Pull Request"},"type":"lvl3","url":"/github-pull-request#navigate-to-your-fork","position":12},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl3":"Navigate to Your Fork","lvl2":"Opening a Pull Request"},"content":"Go to your fork of the \n\nGitHub Sandbox Repository. One fast way to get to your fork, is to click the “fork” button and then follow the link underneath the message, “You’ve already forked github-sandbox.”\n\nWhen you’ve navigated to your fork, you should see a message box alerting you that your branch branchA had recent changes with the option to generate an open Pull Request. This Pull Request would take the changes from your branchA branch and suggest them for the original upstream ProjectPythia github-sandbox repository. You’ll also notice that you are on branch main, but that there are now 2 branches.","type":"content","url":"/github-pull-request#navigate-to-your-fork","position":13},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl3":"Switch Branches","lvl2":"Opening a Pull Request"},"type":"lvl3","url":"/github-pull-request#switch-branches","position":14},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl3":"Switch Branches","lvl2":"Opening a Pull Request"},"content":"If you click on the branch main you’ll see the list of these branches.\n\nThere you can click on the branch branchA to switch branches.\n\nHere you will see the message, “This branch is 1 commit ahead of ProjectPythia:main.” Next to this message you’ll see either the option to “Contribute” (which opens a Pull Request) or “Fetch Upstream” (which pulls in changes from the original repository). And just above your files you’ll see your most recent commit.","type":"content","url":"/github-pull-request#switch-branches","position":15},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl3":"Open a Draft Pull Request","lvl2":"Opening a Pull Request"},"type":"lvl3","url":"/github-pull-request#open-a-draft-pull-request","position":16},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl3":"Open a Draft Pull Request","lvl2":"Opening a Pull Request"},"content":"Click on the “Open pull request” button under the “Contribute” drop-down.\n\nThis will send you to a new page. Notice that you are now in “ProjectPythia/github-sandbox” and not your fork.\n\nThe page will have the two branches you are comparing with an arrow indicating which branch is to be merged into which. Here, base is the upstream origin and head is your forked repository. If you wanted, you could click on these branches to switch the merge configuration. Underneath that you’ll see a green message, “Able to merge. These branches can be automatically merged.” This message means that there are no conflicts. We will discuss conflicts in a later chapter.\n\nIn a one-commit PR, the PR title defaults to your commit message. You can change this if you’d like. There is also a space to add a commit message. This is your opportunity to explain your changes to the owners of the upstream repository.\n\nAnd if you scroll down, you’ll see a summary of this PR with every commit and changed file listed.\n\nClick the arrow next to “Create Pull Request” to change this to a draft PR.\n\nOnce you’ve clicked “Draft Pull Request,” you will be directed to the page of your new PR. Here you can add more comments or request reviews.","type":"content","url":"/github-pull-request#open-a-draft-pull-request","position":17},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"Pull Request Features"},"type":"lvl2","url":"/github-pull-request#pull-request-features","position":18},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"Pull Request Features"},"content":"Now let’s look at the features and discussions in an open (draft) PR.\nClicking “Files Changed” allows you to see all of the changes that would be merged with this PR.\n\nIf you are working in a repository that has automatic checks, it is a good idea to wait for these checks to pass successfully before you request reviewers or change to a non-draft PR. Do this by clicking “Ready for Review.”\n\nWhen working on a project with a larger team, do NOT merge your Pull Request before you have the approval of your teammates. Every team has their own requirements and best practice workflows, and will discuss/approve/reject Pull Requests together. We will cover more about the ways to interact with PRs through conversations and reviews in a later section.\n\nTo someone with write permissions on the repository, the ability to merge will look like this green button:\n\n\nHowever, this PR will NOT be merged, as the GitHub-Sandbox repository is intended to be static.","type":"content","url":"/github-pull-request#pull-request-features","position":19},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"GitHub Workflows"},"type":"lvl2","url":"/github-pull-request#github-workflows","position":20},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"GitHub Workflows"},"content":"The above demonstration is an example of the Git Forking Workflow, because we forked the \n\nGitHub Sandbox repository before making our feature branches. This is most common when you do NOT have write-access to the upstream repository.\n\nThis differs from the Feature Workflow, where all contributors work on a single, remote GitHub repository in specific feature branches. This is common when all contributors DO have write-access to the upstream repository.\n\nThe steps leading up to creating your PR depend on your workflow. The main difference in creating the PR is that\nthe contributor now, for the Feature Workflow, navigates to the upstream, remote\nrepository, not a personal remote fork, and initiates the PR there.\n\nWe will cover \n\nGitHub Workflows in greater detail in the next chapter.","type":"content","url":"/github-pull-request#github-workflows","position":21},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"Summary"},"type":"lvl2","url":"/github-pull-request#summary","position":22},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"Summary"},"content":"A Pull Request (PR) is a formal mechanism for requesting that changes\nthat you have made to one repository are integrated (merged) into\nanother repository.\n\nThe steps that lead up to\nthe PR depend your GitHub Workflow.","type":"content","url":"/github-pull-request#summary","position":23},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/github-pull-request#whats-next","position":24},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl3":"What’s Next?","lvl2":"Summary"},"content":"In the next lesson we will learn more about \n\nReviewing Pull Requests.","type":"content","url":"/github-pull-request#whats-next","position":25},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"References"},"type":"lvl2","url":"/github-pull-request#references","position":26},{"hierarchy":{"lvl1":"Opening a Pull Request on GitHub","lvl2":"References"},"content":"GitHub’s \n\nCollaborating with Pull Requests","type":"content","url":"/github-pull-request#references","position":27},{"hierarchy":{"lvl1":"GitHub Repositories"},"type":"lvl1","url":"/github-repos","position":0},{"hierarchy":{"lvl1":"GitHub Repositories"},"content":"","type":"content","url":"/github-repos","position":1},{"hierarchy":{"lvl1":"GitHub Repositories"},"type":"lvl1","url":"/github-repos#github-repositories","position":2},{"hierarchy":{"lvl1":"GitHub Repositories"},"content":"","type":"content","url":"/github-repos#github-repositories","position":3},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"Overview:"},"type":"lvl2","url":"/github-repos#overview","position":4},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"Overview:"},"content":"Explore GitHub Repositories","type":"content","url":"/github-repos#overview","position":5},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"Prerequisites"},"type":"lvl2","url":"/github-repos#prerequisites","position":6},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nWhat is GitHub?\n\nNecessary\n\n\n\nTime to learn: 15 minutes","type":"content","url":"/github-repos#prerequisites","position":7},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"What is a GitHub repository?"},"type":"lvl2","url":"/github-repos#what-is-a-github-repository","position":8},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"What is a GitHub repository?"},"content":"GitHub gives the following explanation of a \n\nrepository:\n\nA repository is usually used to organize a single project. Repositories can contain folders and files, images, videos, spreadsheets, and data sets -- anything your project needs. Often, repositories include a README file, a file with information about your project. GitHub makes it easy to add one at the same time you create your new repository. It also offers other common options such as a license file.\n\nIn short, it is a collection of files. Each GitHub repository has an owner, which could be an individual or an organization. Repositories can also be set to public or private, determining who can see and interact with it. While a repository can simply store files, GitHub is designed with collaboration in mind. Three key collaborative tools in GitHub are:\n\nIssues: report a bug, plan improvements, or provide feedback to others working on the repository.\n\nDiscussions: post ideas or other conversations that are not as specific or actionable as an Issue.\n\nPull requests: We will go into the specifics later, but a Pull request allows a user to propose a change to any of the files within a repository.\n\nTip\n\nTypically, a GitHub repository will always include the Issues and Pull requests tabs. Discussions are not enabled by default, but are increasingly prevalent.","type":"content","url":"/github-repos#what-is-a-github-repository","position":9},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"What are some examples of repositories?"},"type":"lvl2","url":"/github-repos#what-are-some-examples-of-repositories","position":10},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"What are some examples of repositories?"},"content":"All of the Python packages covered (e.g. \n\nNumpy and \n\nXarray) in this Foundations book have associated GitHub repositories, as well as \n\nPython itself:\n\nAs you can see by the recent timestamps, these repositories are actively changing; this reflects the adaptability of the \n\nopen-source software ecosystem surrounding Python.\n\nTip\n\nNotice that each of the three Repositories each exist as part of their own Organization. In other words, the NumPy repository exists within the NumPy organization; the Xarray repo exists within the Pydata org, and so forth.\n\nWhen you \n\ncreate your own GitHub account, your user ID functions as the organization. Any repositories you create (and therefore, own) will exist within that org.\n\nAnother example is this project’s \n\nPythia Foundations repository, on which this tutorial is stored. It is owned by the \n\nProject Pythia organization. This organization also owns several other repositories that store the files needed to generate \n\nhttps://​projectpythia​.org/, among other things.","type":"content","url":"/github-repos#what-are-some-examples-of-repositories","position":11},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"GitHub’s distributed repositories"},"type":"lvl2","url":"/github-repos#githubs-distributed-repositories","position":12},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"GitHub’s distributed repositories"},"content":"Finally, we introduce an important concept that is vital to your\nunderstanding when working with GitHub. It is the source of GitHub’s power, as well\nas much of its complexity. GitHub repositories\nare distributed; in the general case, there is more than one\nrepository for any project. In fact, repositories can come and go\nat any time, created and deleted as need dictates. Creating new\nrepositories from existing ones, synchronizing them, and managing them\nare the topics of later sections. For now, it is only important to\nunderstand that for a GitHub-managed project, there is typically one\n“official” repository, often called the “upstream” repository, and it lives on \n\nGitHub.com. There may be any\nnumber of copies of the “official” repository, known as forks (or origins,\nif it is owned by you),\nthat also reside on \n\nGitHub.com. Repos that are hosted on \n\nGitHub.com\nare referred to as remotes. In addition to the remotes, there may\nbe one or more copies of the remotes on your desktop or laptop\ncomputer that are referred to as locals. A conceptual diagram of\nthe various repos is shown in the image below.","type":"content","url":"/github-repos#githubs-distributed-repositories","position":13},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"Things to try:"},"type":"lvl2","url":"/github-repos#things-to-try","position":14},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"Things to try:"},"content":"Browse the \n\nNumPy, \n\nXarray, \n\nPython, and \n\nPythia Foundations repos.\n\nBrowse the organizations (e.g., \n\nPydata) which house the repos within.\n\nCheck out GitHub’s \n\n“Create a repo” tutorial to learn how to create your own repository!","type":"content","url":"/github-repos#things-to-try","position":15},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"Summary"},"type":"lvl2","url":"/github-repos#summary","position":16},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"Summary"},"content":"GitHub’s Repositories are collections of files.\n\nIssues, Discussions, and Pull requests can be used to collaborate within a repository.\n\nA GitHub Organization contains Repositories.","type":"content","url":"/github-repos#summary","position":17},{"hierarchy":{"lvl1":"GitHub Repositories","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/github-repos#whats-next","position":18},{"hierarchy":{"lvl1":"GitHub Repositories","lvl3":"What’s Next?","lvl2":"Summary"},"content":"We will further explore Issues and Discussions.","type":"content","url":"/github-repos#whats-next","position":19},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"References"},"type":"lvl2","url":"/github-repos#references","position":20},{"hierarchy":{"lvl1":"GitHub Repositories","lvl2":"References"},"content":"GitHub’s quickstart guide","type":"content","url":"/github-repos#references","position":21},{"hierarchy":{"lvl1":"Configuring Your GitHub Account"},"type":"lvl1","url":"/github-setup-advanced","position":0},{"hierarchy":{"lvl1":"Configuring Your GitHub Account"},"content":"","type":"content","url":"/github-setup-advanced","position":1},{"hierarchy":{"lvl1":"Configuring Your GitHub Account"},"type":"lvl1","url":"/github-setup-advanced#configuring-your-github-account","position":2},{"hierarchy":{"lvl1":"Configuring Your GitHub Account"},"content":"","type":"content","url":"/github-setup-advanced#configuring-your-github-account","position":3},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"Overview:"},"type":"lvl2","url":"/github-setup-advanced#overview","position":4},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"Overview:"},"content":"Configure your GitHub account for secure logins via ssh and/or https\n\nSet up notifications on repositories you own or follow","type":"content","url":"/github-setup-advanced#overview","position":5},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"Prerequisites"},"type":"lvl2","url":"/github-setup-advanced#prerequisites","position":6},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nWhat is GitHub?\n\nNecessary\n\nGitHub user account required\n\nGitHub Repositories\n\nNecessary\n\n\n\nIssues and Discussions\n\nRecommended\n\n\n\nCloning and Forking a Repository\n\nRecommended\n\n\n\nTime to learn: 35 minutes","type":"content","url":"/github-setup-advanced#prerequisites","position":7},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"GitHub secure key generation"},"type":"lvl2","url":"/github-setup-advanced#github-secure-key-generation","position":8},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"GitHub secure key generation"},"content":"When you signed up for your free account on \n\nGitHub, you established a user ID and its corresponding password. Many of the repositories that GitHub serves are readable from anywhere, not even requiring a GitHub account.\n\nHowever, especially when you use the git command-line interface to access a GitHub-hosted repo, there are cases when you need to provide an additional set of login credentials. Some of these cases are:\n\nWhen you want to clone a private, as opposed to public GitHub repository (read-access)\n\nWhen you wish to push to a repo (write-access)\n\nFor these use-cases, you won’t be able to simply type your GitHub user ID and password from the command line. Instead, you need to set up access tokens that live in two places: in your GitHub account, and in your local computer’s file system.\n\nGitHub supports two means of key-based access: via https, and via ssh.\n\nFor example, one can clone \n\nProject Pythia’s Sandbox repository using a URL for the https protocol:\n\nThe URL in this case is https://​github​.com​/ProjectPythia​/github​-sandbox​.git\n\nSimilarly, if you click on the SSH tab:\n\nHere, the URL is git@github.com:ProjectPythia/github-sandbox.git","type":"content","url":"/github-setup-advanced#github-secure-key-generation","position":9},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"Generate a secure personal access token for https"},"type":"lvl2","url":"/github-setup-advanced#generate-a-secure-personal-access-token-for-https","position":10},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"Generate a secure personal access token for https"},"content":"First, you will create a secure token in your GitHub account settings, and then use the token on your local computer.\n\nFollow the steps with helpful screenshots at \n\nGitHub’s PAT Creation page.\n\nTip:\n\nIf using the https protocol to push to a remote repo, you must have generated and downloaded a personal access token. You may also need it when cloning, if the remote repo is not open to all.","type":"content","url":"/github-setup-advanced#generate-a-secure-personal-access-token-for-https","position":11},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"Generate an SSH public/private keypair"},"type":"lvl2","url":"/github-setup-advanced#generate-an-ssh-public-private-keypair","position":12},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"Generate an SSH public/private keypair"},"content":"First, on your local computer, you will create an SSH public/private keypair, and then upload the public key to your GitHub account.\n\nFollow the steps with helpful screenshots at \n\nGitHub’s Connecting to GitHub with SSH page.\n\nTip:\n\nIf using the ssh protocol to clone or push, you must have generated and created an ssh key-pair.\n\nHTTPS vs SSH: Either is fine!\n\nEither https or ssh works fine. Choose whatever you prefer. See \n\nthis overview of the pros and cons of each protocol.","type":"content","url":"/github-setup-advanced#generate-an-ssh-public-private-keypair","position":13},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"GitHub notifications"},"type":"lvl2","url":"/github-setup-advanced#github-notifications","position":14},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"GitHub notifications"},"content":"In keeping with the social network aspect of GitHub, you can follow particular repositories that are of interest to you. Additionally, once you begin contributing to a repository, you may wish to be notified when Pull Requests are made, Issues are posted, your code review is requested, and so on. While it’s easy to have GitHub email you at the address you used when you registered for your GitHub account, you may wish to avoid email clutter.","type":"content","url":"/github-setup-advanced#github-notifications","position":15},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl3":"Email notifications","lvl2":"GitHub notifications"},"type":"lvl3","url":"/github-setup-advanced#email-notifications","position":16},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl3":"Email notifications","lvl2":"GitHub notifications"},"content":"Let’s say you wish to monitor (or watch) the Project Pythia GitHub Sandbox repository and receive emails about it.\n\nClick on the Watch link near the top of the page:\n\nYou can then select what type of notifications you wish to receive. For example, you may want to receive all notifications related to that repo:\n\nYou will then receive email at the address you used when you signed up for GitHub whenever activity occurs on that repo.\n\nYou can stop watching that repo by just clicking on the now-labeled Unwatch link again, and choosing _Participating and  to toggle it back to Unwatch.","type":"content","url":"/github-setup-advanced#email-notifications","position":17},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"Stop spamming me, GitHub!"},"type":"lvl2","url":"/github-setup-advanced#stop-spamming-me-github","position":18},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"Stop spamming me, GitHub!"},"content":"It’s easy to become overwhelmed with email from one or more repos that you are following and/or participating in! In this case, you may wish to disable email notifications.\nIn order to set your notification settings, go to https://​github​.com​/settings​/notifications. You can, for example, uncheck the Email boxes to cease receiving notifications that way:\n\nIf you turn email notifications off, get in the habit of clicking on the Notifications icon when logged into GitHub:\n\nYou can click on the Notifications icon and scroll through all notifications from repos that you opted into receiving notifications from:\n\nUse the Filter notifications control to display only those that meet certain criteria. For example, say you only wanted to view topics related to the MetPy repo:\n\nTip:\n\nIn the list of notifications, you can unsubscribe as shown below.","type":"content","url":"/github-setup-advanced#stop-spamming-me-github","position":19},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"Summary"},"type":"lvl2","url":"/github-setup-advanced#summary","position":20},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"Summary"},"content":"GitHub uses secure tokens to enable write (and sometimes read) access to GitHub repositories.\n\nYou can opt-in to notifications on a repo. The default, which can be easily changed, is to receive email.","type":"content","url":"/github-setup-advanced#summary","position":21},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/github-setup-advanced#whats-next","position":22},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl3":"What’s Next?","lvl2":"Summary"},"content":"In the next section, we will learn the basics of version control using command-line git.","type":"content","url":"/github-setup-advanced#whats-next","position":23},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"References"},"type":"lvl2","url":"/github-setup-advanced#references","position":24},{"hierarchy":{"lvl1":"Configuring Your GitHub Account","lvl2":"References"},"content":"GitHub Personal Access Token (https)\n\nGitHub Public/Private Keypair (ssh)\n\nRemotes in GitHub (Carpentries Tutorial)","type":"content","url":"/github-setup-advanced#references","position":25},{"hierarchy":{"lvl1":"GitHub Workflows"},"type":"lvl1","url":"/github-workflows","position":0},{"hierarchy":{"lvl1":"GitHub Workflows"},"content":"","type":"content","url":"/github-workflows","position":1},{"hierarchy":{"lvl1":"GitHub Workflows"},"type":"lvl1","url":"/github-workflows#github-workflows","position":2},{"hierarchy":{"lvl1":"GitHub Workflows"},"content":"A workflow is a series of activities or tasks that must be completed sequentially or parallel to achieve the desired outcome. Here we outline two different GitHub workflows that take you through the steps leading up to opening a Pull Request.","type":"content","url":"/github-workflows#github-workflows","position":3},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"Overview:"},"type":"lvl2","url":"/github-workflows#overview","position":4},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"Overview:"},"content":"GitHub workflows overview\n\nGit Feature Branch Workflow\n\nForking workflow","type":"content","url":"/github-workflows#overview","position":5},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"Prerequisites"},"type":"lvl2","url":"/github-workflows#prerequisites","position":6},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nWhat is GitHub\n\nNecessary\n\n\n\nGitHub Repositories\n\nNecessary\n\n\n\nCloning and Forking\n\nNecessary\n\n\n\nBasic Version Control with git\n\nNecessary\n\n\n\nIssues and Discussions\n\nRecommended\n\n\n\nBranches\n\nNecessary\n\n\n\nPull Requests\n\nNecessary\n\n\n\nReviewing Pull Requests\n\nRecommended\n\n\n\nTime to learn: 60 minutes","type":"content","url":"/github-workflows#prerequisites","position":7},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"GitHub workflows"},"type":"lvl2","url":"/github-workflows#github-workflows-1","position":8},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"GitHub workflows"},"content":"GitHub, together with Git, are powerful tools for managing and\ncollaborating on all kinds of digital assets, such as software,\ndocumentation, and even manuscripts for research papers. Like other\ncomplex software environments, often these tools can be employed\nin many different ways to accomplish the same goal. In order to\neffectively and consistently use Git and GitHub, over the years a\nvariety of best practices have evolved for supporting different\nmodes of collaboration. Collectively these different models, or\nrecipes, are referred to as workflows.\n\nA typical sequence of workflow steps consists of the following:\n\nA contributor clones a personal remote repository, creating a local copy\n\nThe contributor creates a new branch in their local repository\n\nThe contributor makes changes to the branch and commits them to\ntheir local repository\n\nThe contributor pushes the branch to a remote repository\n\nThe contributor submits a PR via GitHub\n\nThe sequence of steps\noutlined above provides a general framework for submitting a PR.\nBut the precise set of steps is highly dependent on the choice of\nworkflow for a given project. In this chapter we describe Pull\nRequests for two commonly used workflows: The Git Feature Branch\nWorkflow and the Forking Workflow. The former is simpler and often\nused by teams when everyone on the team is an authorized contributor\nto the destination repository. I.e. all of the contributors have\nwrite access to the remote repository hosted by GitHub. The latter\nis typically what is needed to contribute to external projects for\nwhich the contributor is not authorized (i.e. does not have write\naccess) to make changes to the destination repository. We briefly\ndescribe both workflows below, and include the steps necessary to\nmake a PR on each.","type":"content","url":"/github-workflows#github-workflows-1","position":9},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"Git Feature Branch Workflow"},"type":"lvl2","url":"/github-workflows#git-feature-branch-workflow","position":10},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"Git Feature Branch Workflow"},"content":"The Git Feature Branch Workflow is one of the simplest and oldest\ncollaborative workflows that is used for small team projects. The\nkey idea behind this workflow, which is also common to the Forking\nWorkflow, is that all development (all changes) should take place\non a dedicated Git feature branch, not the main (historically\nreferred to as master) branch. The motivation behind this is that\none or more developers can iterate over a feature branch without\ndisturbing the contents of the main branch. Consider using the Git\nFeature Branch Workflow for GitHub’s most widely used purpose,\nsoftware development. Software modifications are liable to introduce\nbugs. Isolating them to a dedicated branch until they can be fixed\nensures that a known, or official, version of the software is always\navailable and in working order.\n\nNote\n\nAvoiding making edits directly on the main branch is considered best practice for most workflows and projects!","type":"content","url":"/github-workflows#git-feature-branch-workflow","position":11},{"hierarchy":{"lvl1":"GitHub Workflows","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"type":"lvl3","url":"/github-workflows#working-with-the-git-feature-branch-workflow","position":12},{"hierarchy":{"lvl1":"GitHub Workflows","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"content":"This model assumes a single, remote GitHub repository with a branch\nnamed main, that contains the official version of all of the digital\nassets, along with a history of all of the changes made. When a\ncontributor wishes to make changes to the remote repository, they\nclone the repo and create a descriptively named feature branch,\nsuch as my-new-feature or perhaps issue-nnn, where nnn is the\nnumber of an issue opened on the repository that this new feature\nbranch will address. Changes by the contributor are then made to\nthe feature branch in a local copy of the repository. When ready,\nthe new branch is pushed to the remote repository.\n\nAt this point,\nthe new branch can be viewed, discussed, and even changed by\ncontributors with write access to the remote repository. When the\nauthor of the feature branch thinks the changes are ready to be\nmerged into main on the remote repository, they create a PR. The\nPR signals the project maintainers that the contributor would like\nto merge their feature branch into main, and invites review of the\nchanges made in the branch. GitHub simplifies the process of viewing\nthe changes by offering a variety of ways to see context differences\n(diffs) between main and the feature branch. Discussion between\nthe reviewers and the contributor inside a PR discussion forum\noccurs in the same way that discussion over GitHub \n\nIssues takes\nplace inside a discussion forum associated with a particular issue.\nIf additional changes are requested by the reviewers, these can be\nmade by the contributor in their local repository, committed, and\nthen pushed to the remote using the same processes they used with\nthe initial push. Once reviewers are satisfied with the changes, a\nproject maintainer can merge the feature branch with main.","type":"content","url":"/github-workflows#working-with-the-git-feature-branch-workflow","position":13},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Cloning the remote repository","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"type":"lvl4","url":"/github-workflows#cloning-the-remote-repository","position":14},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Cloning the remote repository","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"content":"If you don’t have a local copy of the remote repository, you’ll want\nto create one by \n\ncloning the\nremote\nto your local computer. This can be done with the git command line\ntools and the general form of the command looks like this:git clone repository-url local-directory-name\n\nWhere repository-url is the URL for the GitHub repo that you want\nto clone, and local-directory-name is the directory path on your\nlocal machine into which you want to create the clone. The local\ndirectory need not already exist. The clone command will create the\nlocal directory for you. If you don’t know the URL for your\nrepository, navigate your web browser to your GitHub repository,\nand click on the Code button. The URL will be displayed.\n\nFor example, let’s clone the \n\nProject Pythia sandbox repository:git clone https://github.com/ProjectPythia/github-sandbox.git\n\nNote, we did not specify a local-directory_name here, so git will\nuse the base name of the repository_url, “github-sandbox” as\nthe local directory.","type":"content","url":"/github-workflows#cloning-the-remote-repository","position":15},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Start with the main branch","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"type":"lvl4","url":"/github-workflows#start-with-the-main-branch","position":16},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Start with the main branch","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"content":"Continuing with our example above, make sure you are on the main\nbranch and that it is up to date with the remote repository main:cd github-sandbox\ngit checkout main\ngit pull\n\nYou should see output that looks like:Already on 'main'\nAlready up to date.\n\nRemember you can read more about \n\nGitHub branches in our previous chapter.","type":"content","url":"/github-workflows#start-with-the-main-branch","position":17},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Create a new branch","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"type":"lvl4","url":"/github-workflows#create-a-new-branch","position":18},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Create a new branch","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"content":"Create a separate branch for every new capability you work on:git checkout -b my-new-feature\n\nThis command will create a new branch named my-new-feature, if it\ndoesn’t exist already, or switch to the existing branch if it does.\nEither way, any changes you make will occur in the branch my-new-feature,\nnot in main. The output should look something like:Switched to a new branch 'my-new-feature'","type":"content","url":"/github-workflows#create-a-new-branch","position":19},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Make changes and commit","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"type":"lvl4","url":"/github-workflows#make-changes-and-commit","position":20},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Make changes and commit","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"content":"Next, we’ll make changes and commit them to the my-new-feature branch in\nthe local git repository.\n\nUse your favorite editor to edit the file “sample.py”. Add the line:print (\"Do you like to rock the party?\")\n\nafter the existing print statement in the file.\n\nRun the command git status and look at the output. You should see\nsomething like:On branch my-new-feature\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git restore <file>...\" to discard changes in working directory)\n\tmodified:   sample.py\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\nAnother helpful command is git diff, which should give output\nthat looks like:diff --git a/sample.py b/sample.py\nindex b2a3b61..bf89419 100644\n--- a/sample.py\n+++ b/sample.py\n@@ -1,5 +1,6 @@\n \"\"\"This is a text file that contains a sample Python script\"\"\"\n print (\"Hello, Python learners!\")\n+print (\"Do you like to rock the party?\")\n a = 2\n b = 8\n\nIt’s probably obvious that git status will show you which files have been modified and are\nready to be committed, while git diff will show you how your changes\nto my-new-feature branch differ from the main branch in the local\nrepository. Once you are ready, commit your changes to the local\nrepository:git add sample.py\ngit commit -m \"having fun yet?\" .\n\nAfter a successful commit you should see a message like:[my-new-feature 69162bc] having fun yet?\n 1 file changed, 1 insertion(+)","type":"content","url":"/github-workflows#make-changes-and-commit","position":21},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Push the feature branch to the remote repository","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"type":"lvl4","url":"/github-workflows#push-the-feature-branch-to-the-remote-repository","position":22},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Push the feature branch to the remote repository","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"content":"After running git commit your changes have been captured in your\nlocal repository. But most likely only you can see them, and if\nyour local file system fails your changes may be lost. To make your\nchanges visible to others, and safely stored on your remote GitHub\nrepository, you need to push them. However, remember at the beginning\nof this section we said that the Git Feature Branch Workflow works\nwhen you have write access to the remote repository? Unless you are\na member of Project Pythia you probably don’t have write access to\nthe github-sandbox remote repo. So you won’t be able to push your\nchanges to it. That’s OK. We can still run the push command. It won’t\nbreak anything. In the next section on Forking Workflow we will\ndiscuss how to make changes on remote repositories that you do NOT\nhave write access to, such as the one we’re using in this example. Here\nis the push command that we expect to fail:git push --set-upstream origin my-new-feature\n\nYou should get a helpful error message like:remote: Permission to ProjectPythia/github-sandbox.git denied to clyne.\nfatal: unable to access 'https://github.com/ProjectPythia/github-sandbox.git/': The requested URL returned error: 403\n\n\nThe use of the ‘--set-upstream’ option is a one-time operation when\nyou push a new branch. Later, if you want to push subsequent changes\nto the remote you can simply do:git push\n\nIf you are feeling unsatisfied about not having git push succeed, there\nis a simple solution: create a GitHub repository owned by you. The\nGitHub Quickstart guide provides an excellent \n\ntutorial on how to\ndo this.","type":"content","url":"/github-workflows#push-the-feature-branch-to-the-remote-repository","position":23},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Making a Pull Request","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"type":"lvl4","url":"/github-workflows#making-a-pull-request","position":24},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Making a Pull Request","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"content":"Finally, after cloning a remote repository, creating a feature\nbranch, making your changes, committing them to your local repository,\nand pushing your commits back to the remote repository, you are now\nready to issue a PR requesting that the remote repository maintainers\nreview your changes for potential merger into the main branch on\nthe remote. This final action must be performed from within your\nweb browser. After\nnavigating to your repo do the following:\n\nClick on “Pull Requests” in the top navigation bar\n\nClick on “New Pull Request”\n\nUnder “Compare changes”, make sure that base is set to main, and compare is set to the name of your feature branch, my-new-feature\n\nClick on “Create Pull Request”\n\nA PR window should open up. Provide a descriptive title, and any helpful comments that you want to communicate with the reviewers\n\nClick on “Create Pull Request” in the PR window.\n\nThat’s it! You’re done! Sit back and wait for comments from reviewers.\nIf changes are requested, simply repeat the steps above. Once your\nPR is merged you’ll receive notification from GitHub.","type":"content","url":"/github-workflows#making-a-pull-request","position":25},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Safety tip on synchronization","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"type":"lvl4","url":"/github-workflows#safety-tip-on-synchronization","position":26},{"hierarchy":{"lvl1":"GitHub Workflows","lvl4":"Safety tip on synchronization","lvl3":"Working with the Git Feature Branch Workflow","lvl2":"Git Feature Branch Workflow"},"content":"Over time your local repository will diverge from the remote. Before\nstarting on a new feature, or if the main branch on remote may have\nbeen updated while you were working on my-new-feature, it is a good\nidea to periodically sync up with the remote main. Make sure all\nof your changes to my-new-feature have been committed to the local\nrepository, and then do:git checkout main\ngit pull\ngit checkout my-new-feature\ngit merge main","type":"content","url":"/github-workflows#safety-tip-on-synchronization","position":27},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"Forking Workflow"},"type":"lvl2","url":"/github-workflows#forking-workflow","position":28},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"Forking Workflow"},"content":"The Git Feature Branch Workflow described above, along with the\nsteps needed to submit a PR, work when you have write access to the\nremote repository. But as we saw, if you don’t have write access\nyou will not be able to push your changes to the remote repo. So,\nif you are contributing to an open source project, such as Project\nPythia for example, a slightly different workflow is required.\nThe Forking Workflow is the one most commonly used for public open\nsource projects. The primary difference between the Forking Workflow\nand the Git Feature Branch Workflow is that with the former, two\nremote repositories are involved: one managed by the developers of\nthe project that you wish to contribute to, and one owned by you.\nTo help keep things clear we will refer to these remotes as the\nupstream repository and the personal repository, respectively. Not\nsurprisingly, the personal repository will be a clone of the project\nrepository that you own and can push changes too. The personal\nrepository must be public, so that the maintainers of the upstream\nrepository can pull changes from it. Other than a couple of additional\nsteps required at the beginning and the end, the process of submitting\na PR when using the Forking Workflow is identical to that of the\nGit Feature Branch Workflow. The basic steps are as follows:\n\nA contributor forks the upstream repository, creating a remote clone that is owned by the contributor: the personal repository\n\nThe contributor then clones the newly created personal remote repository, creating a local copy. Yup, that is two clones.\n\nThe contributor creates a new branch in their local repository\n\nThe contributor makes changes to the branch and commits them to their local repository\n\nThe contributor pushes the branch to their personal remote repository that was created in step 1\n\nThe contributor submits a PR via GitHub to the upstream repository\n\nNote that steps 2 through 5 are identical to steps 1 through 4 for\nthe Git Feature Branch Workflow. Hence, here we only discuss the\nfirst step, and last step.","type":"content","url":"/github-workflows#forking-workflow","position":29},{"hierarchy":{"lvl1":"GitHub Workflows","lvl3":"Forking the upstream repository","lvl2":"Forking Workflow"},"type":"lvl3","url":"/github-workflows#forking-the-upstream-repository","position":30},{"hierarchy":{"lvl1":"GitHub Workflows","lvl3":"Forking the upstream repository","lvl2":"Forking Workflow"},"content":"GitHub makes it really easy to fork a remote repository. Simply\nnavigate your web browser to the upstream repository that you want\nto fork, and click on Fork. GitHub will create a clone of the\nupstream repository in the remote destination selected by you on\nGitHub, and will then redirect your browser to the newly created\nforked, personal repository. The personal repository is owned by\nyou. Any changes made here will not impact the upstream repository\nuntil you are ready to submit a PR. Let’s try it. Follow\nthe steps under Forking a repository \n\nhere.","type":"content","url":"/github-workflows#forking-the-upstream-repository","position":31},{"hierarchy":{"lvl1":"GitHub Workflows","lvl3":"Clone, branch, change, commit, push","lvl2":"Forking Workflow"},"type":"lvl3","url":"/github-workflows#clone-branch-change-commit-push","position":32},{"hierarchy":{"lvl1":"GitHub Workflows","lvl3":"Clone, branch, change, commit, push","lvl2":"Forking Workflow"},"content":"The next steps are the same as described above for the Git Feature\nBranch Workflow. Clone a local copy of the newly created remote,\npersonal repository, create a feature branch, make your changes,\ncommit your changes, and push the new branch with your commits to your personal repository.","type":"content","url":"/github-workflows#clone-branch-change-commit-push","position":33},{"hierarchy":{"lvl1":"GitHub Workflows","lvl3":"Making a Pull Request","lvl2":"Forking Workflow"},"type":"lvl3","url":"/github-workflows#making-a-pull-request-1","position":34},{"hierarchy":{"lvl1":"GitHub Workflows","lvl3":"Making a Pull Request","lvl2":"Forking Workflow"},"content":"Once the new feature branch has been pushed to the contributor’s\npersonal repository, a PR can be created that asks the maintainers\nof the upstream repository to merge the contents of the feature\nbranch on the contributor’s repository into the main branch on the\nupstream repository. This step is remarkably similar to making a\nPR in the Git Feature Branch Workflow. The only difference is that\nthe contributor navigates their browser to the upstream, remote\nrepository, not the personal remote, and initiates the PR there.\nSpecifically, the following steps are once again followed, but\nperformed on the upstream remote:\n\nClick on “Pull Requests” in the top navigation bar\n\nClick on “New Pull Request”\n\nUnder “Compare changes”, make sure that base is set to main, and compare is set to the name of your feature branch, my-new-feature\n\nClick on “Create Pull Request”\n\nA PR window should open up. Provide a descriptive title, and any helpful comments that you want to communicate with the reviewers\n\nClick on “Create Pull Request” in the PR window.","type":"content","url":"/github-workflows#making-a-pull-request-1","position":35},{"hierarchy":{"lvl1":"GitHub Workflows","lvl3":"Safety tip on synchronization","lvl2":"Forking Workflow"},"type":"lvl3","url":"/github-workflows#safety-tip-on-synchronization-1","position":36},{"hierarchy":{"lvl1":"GitHub Workflows","lvl3":"Safety tip on synchronization","lvl2":"Forking Workflow"},"content":"Just like with the Git Feature Branch Workflow model, over time\nyour local repository will diverge from the remote(s). Before\nstarting on a new feature, or if the main branch on remote may have\nbeen updated while you were working on my-new-feature, it is a good\nidea to periodically sync up with the remote main. When working\nwith forks things get a little more complicated than when only a\nsingle remote is involved. Before syncing with the upstream remote\nyou must first configure your local repository by running the\nfollowing commands from within your local copy of the repo:git remote -v\n\nThis should produce an output that looks similar to the following:\n\norigin \n\nhttps://​github​.com​/YOUR​_USERNAME​/YOUR​_FORK​.git (fetch)\norigin \n\nhttps://​github​.com​/YOUR​_USERNAME​/YOUR​_FORK​.git (push)\n\nNext, specify a new remote upstream repository that will be synced with the fork.git remote add upstream upstream-url\n\nWhere upstream-url is the URL of the upstream repository.\n\nFinally, rerun the git remote -v command and you should see output\nthat looks like this:origin    https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch)\norigin    https://github.com/YOUR_USERNAME/YOUR_FORK.git (push)\nupstream  https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (fetch)\nupstream  https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (push)\n\nAfter performing the above steps, you can then synchronize your\nlocal repository with the upstream remote by running the following:git fetch upstream\ngit checkout main\ngit merge upstream/main","type":"content","url":"/github-workflows#safety-tip-on-synchronization-1","position":37},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"Summary"},"type":"lvl2","url":"/github-workflows#summary","position":38},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"Summary"},"content":"The steps that lead up to\nthe PR depend your GitHub Workflow.\n\nTwo commonly used GitHub Worflows are Git Feature Branch Workflow and\nForking Workflow. The former is appropriate for teams of collaborators\nwhere everyone has write access to the GitHub repository. The latter\nis commonly used when a developer wishes to contribute to a public GitHub\nproject for which they do not have write access to the repository.","type":"content","url":"/github-workflows#summary","position":39},{"hierarchy":{"lvl1":"GitHub Workflows","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/github-workflows#whats-next","position":40},{"hierarchy":{"lvl1":"GitHub Workflows","lvl3":"What’s Next?","lvl2":"Summary"},"content":"In the next lesson we will put the Forking Workflow to work and show you\nhow to use it to \n\ncontribute to Project Pythia.","type":"content","url":"/github-workflows#whats-next","position":41},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"References"},"type":"lvl2","url":"/github-workflows#references","position":42},{"hierarchy":{"lvl1":"GitHub Workflows","lvl2":"References"},"content":"Atlassian’s tutorial on \n\nworkflows\n\nGitHub’s \n\nCollaborating with Pull Requests","type":"content","url":"/github-workflows#references","position":43},{"hierarchy":{"lvl1":"Reviewing Pull Requests"},"type":"lvl1","url":"/review-pr","position":0},{"hierarchy":{"lvl1":"Reviewing Pull Requests"},"content":"","type":"content","url":"/review-pr","position":1},{"hierarchy":{"lvl1":"Reviewing Pull Requests"},"type":"lvl1","url":"/review-pr#reviewing-pull-requests","position":2},{"hierarchy":{"lvl1":"Reviewing Pull Requests"},"content":"Pull Requests (PRs) are typically reviewed by collaborators before being merged in to the main project branch. Many people feel overwhelmed, or feel as though their skills are lacking, when asked to perform their first PR review. If you find yourself in this or a similar situation, the examples in this tutorial can be quite helpful. With the help of this tutorial, anyone can quickly learn the basics of reviewing PRs, which can boost collaboration and productivity in any project hosted on GitHub. This tutorial also contains useful tips on how to effectively review a PR in many different situations.","type":"content","url":"/review-pr#reviewing-pull-requests","position":3},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Overview:"},"type":"lvl2","url":"/review-pr#overview","position":4},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Overview:"},"content":"This tutorial covers the following topics:\n\nWhat is a Pull Request Review?\n\nRequesting Pull Request Reviews\n\nWays to View a Pull Request\n\nProviding a Pull Request Review\n\nWhat to Look for When Reviewing","type":"content","url":"/review-pr#overview","position":5},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Prerequisites"},"type":"lvl2","url":"/review-pr#prerequisites","position":6},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nWhat is GitHub\n\nNecessary\n\n\n\nGitHub Repositories\n\nNecessary\n\n\n\nCloning and Forking\n\nNecessary\n\n\n\nBasic Version Control with git\n\nNecessary\n\n\n\nIssues and Discussions\n\nRecommended\n\n\n\nBranches\n\nNecessary\n\n\n\nPull Requests\n\nNecessary\n\n\n\nTime to learn: 30 minutes","type":"content","url":"/review-pr#prerequisites","position":7},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"What is a Pull Request Review?"},"type":"lvl2","url":"/review-pr#what-is-a-pull-request-review","position":8},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"What is a Pull Request Review?"},"content":"A PR Review is an opportunity for a team member to look through proposed file changes and request changes before merging these changes into the primary project branch (usually called “main”), or another important project branch. The reviewer may attempt to acquire information about the content of the PR by asking precise questions. They may also suggest edits to the content, either explicitly, such as changes to specific lines of code, or implicitly, such as a request for more detailed documentation. Before the PR is merged, the author of the PR content should attempt to satisfy all requests in the review. In fact, if the branch being updated by the PR has active protections, the author may be required to satisfy some such requests.","type":"content","url":"/review-pr#what-is-a-pull-request-review","position":9},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Requesting Pull Request Reviews"},"type":"lvl2","url":"/review-pr#requesting-pull-request-reviews","position":10},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Requesting Pull Request Reviews"},"content":"Most people learning GitHub are confused about when to request review on a PR they create. The answer is that review should be requested when a PR is (or is likely) ready to merge into the primary project branch (or another important project branch).\n\nTo start the review process, navigate to the right sidebar menu that appears when viewing your PR. Then, under “Reviewers”, select the gear icon, and then select or enter a GitHub user’s ID for whom you would like to approve your work. If the files listed in the PR are owned or recently edited by specific reviewers, GitHub may automatically suggest the user IDs of those reviewers.\n\n\n\nDid you know?\n\nIt is possible to automate this process with a CODEOWNERS file and \n\nGitHub actions.\n\nTo learn more about any topic relating to requesting a PR review, including topics such as CODEOWNERS files, please review the official \n\nRequesting a Pull Request Review Documentation.","type":"content","url":"/review-pr#requesting-pull-request-reviews","position":11},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Ways to View a Pull Request"},"type":"lvl2","url":"/review-pr#ways-to-view-a-pull-request","position":12},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Ways to View a Pull Request"},"content":"If you are unfamiliar with the process of reviewing a PR, the material in this tutorial section will describe the process in detail. The first step to reviewing a PR is to review the files changed by the PR. However, before reviewing the changed files, it is very helpful to view these files in a meaningful way.\n\nThe first useful way to view changed files in a PR is through the PR’s “Files Changed” tab. On this tab, added content is displayed in green, while removed content is displayed in red.\n\n\n\nThis method of viewing changed files works well for most types of code; however, if the code is designed to be rendered as a webpage, Jupyter Notebook, or other similar format, a different method of viewing is recommended.\n\nThere are some standard methods of easily viewing Jupyter Notebooks and rendered webpages in GitHub; these are commonly used by repositories with large amounts of this type of content. GitHub actions can be used to provide previews of the rendered content; there are also third-party services, such as \n\nReviewNB, that allow for viewing of this content. Also, it is important to know that when viewing a preview of webpage content provided by GitHub actions, using any absolute links in the preview will take the web browser out of the preview and out of GitHub.\n\nAnother popular way to easily view any type of PR content is to locally check out the PR branch. This can be accomplished by cloning the GitHub repo and switching in the local clone to the branch containing the PR. Viewing a PR through a local clone allows the reviewer to use any applications available through the terminal, including code editors, Jupyter applications, and Web browsers, to view the changed files quickly and easily. For more information on this process, please review the \n\ndocumentation GitHub provides on checking out pull requests locally.\n\nAs described above, there are many ways to view changed files in a GitHub PR, including local clones, GitHub action previews, and services such as ReviewNB. However, these services may not detail the changes to the files listed in the PR; therefore, the “Files Changed” tab should be the main resource for deciding where to focus a review.","type":"content","url":"/review-pr#ways-to-view-a-pull-request","position":13},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Providing a Pull Request Review"},"type":"lvl2","url":"/review-pr#providing-a-pull-request-review","position":14},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Providing a Pull Request Review"},"content":"There are many ways to provide a PR review. The most basic of these is to comment on specific lines. This type of review can be performed through the “Files Changed” tab. By clicking on the “+” icon next to a line of code, the reviewer can provide a comment, and either start a new review, or simply link the comment to the line of code.\n\n\n\nIf the review consists mainly of comments relevant to specific lines of code, this review method is preferred.\n\nIf you are the reviewer, and the review consists mainly of small edits that you can perform yourself, this is also the preferred review method. To start one of these small edits, open a comment on the line of code to be edited, as described above. You can then suggest the edit by clicking on the “+-” icon, circled in red in the screenshot below. This icon automatically populates the comment box with the line of code and formats it with Markdown. You must replace the line of code in the comment box with the edited version, then link the comment or start a new review as described above.\n\n \n\nIf the review is more complex than simple edits to specific lines of code, you can find more detailed reviewing tools in the Review Changes menu in the top right. This menu contains a comment box, as well as options for specific types of review. These options are described in detail after the informational screenshot below.\n\n\n\nThe “Comment” option allows the reviewer to provide simple comments or questions on the PR before the review is finished and the PR merged. Please note that comments and questions that may hinder the PR merge process should not be handled in this way.\n\nThe “Approve” option is used to indicate that the reviewer wholeheartedly approves the content changes in the PR, and that these content changes should be merged into an important project branch as quickly as possible. This option is also known as the LGTM (let’s get this merged) option.\n\nThe “Request changes” option is used to indicate that the content changes contain one or more elements that require improvement or resolution before the PR can be merged.\n\nAfter providing review text in the comment box, and selecting a review type, make sure to click on the “Submit Review” button to finish the review.","type":"content","url":"/review-pr#providing-a-pull-request-review","position":15},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"What to Look for When Reviewing"},"type":"lvl2","url":"/review-pr#what-to-look-for-when-reviewing","position":16},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"What to Look for When Reviewing"},"content":"There are specific elements of PRs that are more commonly prioritized during a review. To address these elements, most reviewers perform the following tasks:\n\nLook at the description and linked GitHub issue to make sure the PR addresses the issue\n\nAttempt to figure out the details of the content changes in the PR, and the purpose of those changes\n\nLook at the content for spelling errors\n\nProvide feedback on the code itself\n\nDoes the code contain input checks, debug statements, verification, or the like?\n\nIf the code contains any of these checks, are they sufficiently robust?\n\nIs the code written in a way that allows for understanding of its purpose?\n\nAs the reviewer, are you familiar with a way to simplify the code, or make the code more efficient?\n\nDoes the code contain identifiers with conflicting or confusing names that need correcting?\n\nDo you, as the reviewer, notice any other issue with the code that may need to be dealt with in your review?\n\nIf any of the content changed by the PR is meant to be rendered (e.g., as a webpage or Jupyter Notebook), preview this content to check for issues with design and functionality\n\nFinally, try to clearly state not only the changes made in your review, but also the issues not changed by your review. It is perfectly acceptable to not cover every item in this list; however, it is good practice to include the items covered in the review, and the nature of these changes. Most teams that manage a GitHub repository appreciate the inclusion of opinion and detail in a PR review.","type":"content","url":"/review-pr#what-to-look-for-when-reviewing","position":17},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Summary"},"type":"lvl2","url":"/review-pr#summary","position":18},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Summary"},"content":"PR Reviews safeguard the primary project branch (and other important project branches) in a GitHub repository. These reviews require contributors in a repository to perform a detailed examination of changes to code and other files. The files remain unchanged until these examinations are finished.\n\nThere exist certain standards pertaining to PR reviews; in addition to following these standards, it is important to provide detail on the basis of your review.","type":"content","url":"/review-pr#summary","position":19},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/review-pr#whats-next","position":20},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl3":"What’s Next?","lvl2":"Summary"},"content":"The next tutorial will cover standards and other details about \n\nGitHub Workflows.","type":"content","url":"/review-pr#whats-next","position":21},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Resources and References"},"type":"lvl2","url":"/review-pr#resources-and-references","position":22},{"hierarchy":{"lvl1":"Reviewing Pull Requests","lvl2":"Resources and References"},"content":"GitHub’s tutorial on \n\nCollaborating with Pull Requests\n\nGitHub’s tutorial on \n\nRequesting a Pull Request Review\n\nGitHub’s tutorial on \n\nChecking Out Pull Requests Locally","type":"content","url":"/review-pr#resources-and-references","position":23},{"hierarchy":{"lvl1":"What is GitHub?"},"type":"lvl1","url":"/what-is-github","position":0},{"hierarchy":{"lvl1":"What is GitHub?"},"content":"","type":"content","url":"/what-is-github","position":1},{"hierarchy":{"lvl1":"What is GitHub?"},"type":"lvl1","url":"/what-is-github#what-is-github","position":2},{"hierarchy":{"lvl1":"What is GitHub?"},"content":"","type":"content","url":"/what-is-github#what-is-github","position":3},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"Overview:"},"type":"lvl2","url":"/what-is-github#overview","position":4},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"Overview:"},"content":"What is GitHub?\n\nNo experience necessary!\n\nFree and open-source software (FOSS)\n\nVersion control systems (VCS)\n\nGitHub = FOSS + VCS + Web\n\nRegister for a free GitHub account","type":"content","url":"/what-is-github#overview","position":5},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"Prerequisites"},"type":"lvl2","url":"/what-is-github#prerequisites","position":6},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nNone\n\n\n\n\n\nTime to learn: 15 minutes","type":"content","url":"/what-is-github#prerequisites","position":7},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"What is GitHub?"},"type":"lvl2","url":"/what-is-github#what-is-github-1","position":8},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"What is GitHub?"},"content":"GitHub is a web-based platform for the dissemination of free and open-source software.\n\nIf you are reading this lesson, you are already using GitHub, as that is where Project Pythia hosts its content!\n\nGitHub provides the following:\n\nVersion control for free and open-source software and other digital assets\n\nProject discussion forums\n\nDevOps to facilitate building and testing software\n\nBug reporting, patching, and tracking\n\nDocumentation hosting\n\nAn environment that fosters collaboration\n\nAlthough GitHub can host any digital asset, the most common use case for GitHub is for individuals or organizations to house repositories of free and open-source software:","type":"content","url":"/what-is-github#what-is-github-1","position":9},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"No experience necessary!"},"type":"lvl2","url":"/what-is-github#no-experience-necessary","position":10},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"No experience necessary!"},"content":"You do not need to be an experienced software developer or be proficient in version control to make use of GitHub! Perhaps, though, you have used a particular package (e.g., Xarray or Matplotlib) and have had questions about its usage, noticed a bug, or had an idea for a new feature for the package! You can participate in a project’s development via GitHub the same way you might have interacted with its developers via email in the past.","type":"content","url":"/what-is-github#no-experience-necessary","position":11},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"Free and open-source software (FOSS)"},"type":"lvl2","url":"/what-is-github#free-and-open-source-software-foss","position":12},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"Free and open-source software (FOSS)"},"content":"Much of what we term the scientific Python software ecosystem consists of free and open-source software. Often abbreviated as FOSS, this means:\n\nThe software is free of charge, and\n\nThe various files which contain the software code are publicly available.\n\nDid you know?\n\nThe \n\nPython language itself is an example of FOSS!\n\nFOSS is nothing new. For example, the \n\nLinux kernel source code has been available to download for many years.\n\nFree ≠ open source!\n\nJust because a software package may be free does not mean that its source code is open! For example, although Nvidia makes its video drivers available for free download, the source code for those drivers is proprietary.\n\nArguably, the greatest advantage of open-source software is that it enables collaborative sharing, and thus community feedback.\n\nTypes of community input may include the following:\n\nIssues: usage questions, bug reports, feature requests\n\nPull requests: a user can ask that that their changes/additions be incorporated into the project\n\nDiscussions: a community forum on the open source project","type":"content","url":"/what-is-github#free-and-open-source-software-foss","position":13},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"Version control systems (VCS)"},"type":"lvl2","url":"/what-is-github#version-control-systems-vcs","position":14},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"Version control systems (VCS)"},"content":"We will discuss version control in more detail later in this series, but the need to track and manage changes to a project, especially one that involves software, has long been known. Over the years, FOSS developers have used VCS such as cvs, svn, and most recently, git. All of these systems are command-line tools.","type":"content","url":"/what-is-github#version-control-systems-vcs","position":15},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"FOSS and VCS on the Internet"},"type":"lvl2","url":"/what-is-github#foss-and-vcs-on-the-internet","position":16},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"FOSS and VCS on the Internet"},"content":"A successful FOSS project needs to be accessible via the web. As mentioned before, the Linux kernel and the Python language have long been available using first-generation remote access protocols such as FTP and HTTP, and SSH. Later, VCS tools such as cvs and svn established their own TCP protocols for remote access. With the advent of git, web-based services that supported HTTP(S) and SSH sprung up. Each of these VCS leverages the concept of a particular FOSS project as a code repository.\n\nDid you know?\n\nLinus Torvalds, the original developer (and still the lead maintainer) of Linux, is also the original developer of \n\nGit!\n\nStay tuned!\n\nWe will discuss version control and the use of Git via the command line later in this series.","type":"content","url":"/what-is-github#foss-and-vcs-on-the-internet","position":17},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"FOSS + VCS + Web = GitHub"},"type":"lvl2","url":"/what-is-github#foss-vcs-web-github","position":18},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"FOSS + VCS + Web = GitHub"},"content":"Perhaps the most popular web-based platform that uses Git for FOSS VCS is \n\nGitHub. GitHub hosts all of the Python software packages that Project Pythia covers as code repositories (we’ll use the term Git repo, or more generally just repo henceforth to represent a GitHub code repository).\n\nFor example, here is a screenshot from \n\nXarray’s GitHub Git repo:\n\nNote\n\nThe above screenshot is from one moment in time. When you visit the Xarray GitHub link above, it will no doubt look different!","type":"content","url":"/what-is-github#foss-vcs-web-github","position":19},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"Register for a free GitHub account"},"type":"lvl2","url":"/what-is-github#register-for-a-free-github-account","position":20},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"Register for a free GitHub account"},"content":"While one can freely browse GitHub repositories such as Xarray anonymously, it’s necessary to log into a unique (and free) user account in order to take advantage of GitHub’s full capabilities, such as:\n\nOpening Issues and Pull Requests\n\nParticipating in Discussions\n\nHosting your own repository\n\nYour next step (if you haven’t already) should be to register for your free GitHub account. As with many online services, you will specify a user ID, password, and email address to use with your account.\n\nTo do so, simply point your browser to the \n\nGitHub sign-up page:\n\nWhile GitHub offers paid options, a free account is typically all that is needed!","type":"content","url":"/what-is-github#register-for-a-free-github-account","position":21},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"Summary"},"type":"lvl2","url":"/what-is-github#summary","position":22},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"Summary"},"content":"GitHub serves as a web-based platform for digital assets, particularly FOSS.\n\nGitHub uses Git as its version control system.\n\nYou can set up a free user account on GitHub.","type":"content","url":"/what-is-github#summary","position":23},{"hierarchy":{"lvl1":"What is GitHub?","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/what-is-github#whats-next","position":24},{"hierarchy":{"lvl1":"What is GitHub?","lvl3":"What’s Next?","lvl2":"Summary"},"content":"In the next lesson, we will explore some GitHub repositories.","type":"content","url":"/what-is-github#whats-next","position":25},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"References"},"type":"lvl2","url":"/what-is-github#references","position":26},{"hierarchy":{"lvl1":"What is GitHub?","lvl2":"References"},"content":"GitHub (Wikipedia)","type":"content","url":"/what-is-github#references","position":27},{"hierarchy":{"lvl1":"Installing and Running Python"},"type":"lvl1","url":"/how-to-run-python","position":0},{"hierarchy":{"lvl1":"Installing and Running Python"},"content":"","type":"content","url":"/how-to-run-python","position":1},{"hierarchy":{"lvl1":"Installing and Running Python","lvl2":"Overview"},"type":"lvl2","url":"/how-to-run-python#overview","position":2},{"hierarchy":{"lvl1":"Installing and Running Python","lvl2":"Overview"},"content":"This section provides an overview of different ways to run Python code, and quickstart guides for:\n\nChoosing a Python platform\n\nInstalling and managing Python with Conda","type":"content","url":"/how-to-run-python#overview","position":3},{"hierarchy":{"lvl1":"Installing and Running Python","lvl2":"Prerequisites"},"type":"lvl2","url":"/how-to-run-python#prerequisites","position":4},{"hierarchy":{"lvl1":"Installing and Running Python","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nWhy Python?\n\nHelpful\n\n\n\nTime to learn: 20 minutes","type":"content","url":"/how-to-run-python#prerequisites","position":5},{"hierarchy":{"lvl1":"Installing and Running Python","lvl2":"Choosing a Python Platform"},"type":"lvl2","url":"/how-to-run-python#choosing-a-python-platform","position":6},{"hierarchy":{"lvl1":"Installing and Running Python","lvl2":"Choosing a Python Platform"},"content":"There is no single official platform for the Python language. Here we provide a brief rundown of 3 popular platforms:\n\nThe terminal,\n\nJupyter notebooks, and\n\nIDEs (integrated development environments).\n\nHere we hope to provide you with enough information to understand the differences and similarities between each platform, so that you can make the best choice for your work environment and learn along effectively, regardless of your Python platform preference.\n\nIn general, it is always best to test your programs in the same environment in which they will be run. The biggest factors to consider when choosing your platform are:\n\nWhat are you already comfortable with?\n\nWhat are the people around you using (peers, coworkers, instructors, etc.)?","type":"content","url":"/how-to-run-python#choosing-a-python-platform","position":7},{"hierarchy":{"lvl1":"Installing and Running Python","lvl3":"Terminal","lvl2":"Choosing a Python Platform"},"type":"lvl3","url":"/how-to-run-python#terminal","position":8},{"hierarchy":{"lvl1":"Installing and Running Python","lvl3":"Terminal","lvl2":"Choosing a Python Platform"},"content":"For learners who are familiar with basic \n\nLinux commands and text editors (such as Vim or Nano), running Python in the terminal is the quickest route straight to learning Python syntax without the covering the bells and whistles of a new platform. If you are running Python on a supercomputer, through an HTTP request or SSH tunneling, you might want to consider learning in the terminal.\n\nHow to Run Python in the Terminal","type":"content","url":"/how-to-run-python#terminal","position":9},{"hierarchy":{"lvl1":"Installing and Running Python","lvl3":"Jupyter Notebooks","lvl2":"Choosing a Python Platform"},"type":"lvl3","url":"/how-to-run-python#jupyter-notebooks","position":10},{"hierarchy":{"lvl1":"Installing and Running Python","lvl3":"Jupyter Notebooks","lvl2":"Choosing a Python Platform"},"content":"We highly encourage the use of Jupyter notebooks: a free, open-source, interactive tool running inside a web browser that allows you to run Python code in “cells.” This means that your workflow can alternate between code, output, and even Markdown-formatted explanatory sections that create an easy-to-follow analysis or “computational narrative” from start to finish. Jupyter notebooks are a great option for presentations or learning tools. For these reasons, Jupyter is very popular among scientists. Most lessons in this book will be taught via Jupyter notebooks.\n\nHow to Run Python in a Jupyter Session","type":"content","url":"/how-to-run-python#jupyter-notebooks","position":11},{"hierarchy":{"lvl1":"Installing and Running Python","lvl3":"Other IDEs","lvl2":"Choosing a Python Platform"},"type":"lvl3","url":"/how-to-run-python#other-ides","position":12},{"hierarchy":{"lvl1":"Installing and Running Python","lvl3":"Other IDEs","lvl2":"Choosing a Python Platform"},"content":"If you code in other languages, you might already have a favorite IDE that will work just as well in Python. \n\nSpyder is a Python specific IDE that comes with the \n\nAnaconda download. It is perhaps the most familiar IDE if you are coming from languages such as Matlab that have a language specific platform and display a list of variables. \n\nPyCharm and \n\nVisual Studio Code are also popular IDEs. Many IDEs offer support for terminal execution, scripts, and Jupyter display. To learn about your specific IDE, visit its official documentation.\n\nWe recommend eventually learning how to develop and run Python code in each of these platforms.","type":"content","url":"/how-to-run-python#other-ides","position":13},{"hierarchy":{"lvl1":"Installing and Running Python","lvl2":"Installing and managing Python with Conda"},"type":"lvl2","url":"/how-to-run-python#installing-and-managing-python-with-conda","position":14},{"hierarchy":{"lvl1":"Installing and Running Python","lvl2":"Installing and managing Python with Conda"},"content":"Conda is an open-source, cross-platform, language-agnostic package manager and environment management system that allows you to quickly install, run, and update packages within your work environment(s). Conda is a vital component of the Python ecosystem. Understanding it is important, regardless of the platform you chose to run your Python code.\n\nLearn more about Conda here","type":"content","url":"/how-to-run-python#installing-and-managing-python-with-conda","position":15},{"hierarchy":{"lvl1":"Installing and Running Python","lvl2":"Summary"},"type":"lvl2","url":"/how-to-run-python#summary","position":16},{"hierarchy":{"lvl1":"Installing and Running Python","lvl2":"Summary"},"content":"Python can be run on many different platforms. You may choose where to run Python based on a number of factors. The tutorials in this book will be formatted as Jupyter Notebooks.","type":"content","url":"/how-to-run-python#summary","position":17},{"hierarchy":{"lvl1":"Installing and Running Python","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/how-to-run-python#whats-next","position":18},{"hierarchy":{"lvl1":"Installing and Running Python","lvl3":"What’s Next?","lvl2":"Summary"},"content":"How to Run Python in the Terminal\n\nHow to Run Python in a Jupyter Session\n\nLearn more about Conda here","type":"content","url":"/how-to-run-python#whats-next","position":19},{"hierarchy":{"lvl1":"Installing and Running Python","lvl2":"Resources and References"},"type":"lvl2","url":"/how-to-run-python#resources-and-references","position":20},{"hierarchy":{"lvl1":"Installing and Running Python","lvl2":"Resources and References"},"content":"Linux commands\n\nSpyder\n\nAnaconda\n\nPyCharm\n\nVisual Studio Code","type":"content","url":"/how-to-run-python#resources-and-references","position":21},{"hierarchy":{"lvl1":"Python in Jupyter"},"type":"lvl1","url":"/jupyter","position":0},{"hierarchy":{"lvl1":"Python in Jupyter"},"content":"","type":"content","url":"/jupyter","position":1},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Overview"},"type":"lvl2","url":"/jupyter#overview","position":2},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Overview"},"content":"You’d like to learn to run Python in a Jupyter session. Here we will cover:\n\nInstalling Python in Jupyter\n\nRunning Python code in Jupyter\n\nSaving your notebook and exiting","type":"content","url":"/jupyter#overview","position":3},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Prerequisites"},"type":"lvl2","url":"/jupyter#prerequisites","position":4},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nInstalling and Running Python\n\nHelpful\n\n\n\nTime to learn: 20 minutes","type":"content","url":"/jupyter#prerequisites","position":5},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Installing Python in Jupyter"},"type":"lvl2","url":"/jupyter#installing-python-in-jupyter","position":6},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Installing Python in Jupyter"},"content":"To run a Jupyter session, you will need to install some necessary packages into your \n\nConda environment.\n\nInstall miniforge by following the \n\ninstructions for your machine.\n\nLearn more about Conda here\n\nNext, create a \n\nConda environment with \n\nJupyter Lab installed. In the terminal, type:$ conda create --name pythia_foundations_env jupyterlab\n\nTest that you have installed everything correctly by first activating your environment and then launching a \n\nJupyter Lab session:$ conda activate pythia_foundations_env\n$ jupyter lab\n\nA new window should open automatically in your default browser. You can change the browser when launching from the terminal with (for example):jupyter lab —browser=chrome","type":"content","url":"/jupyter#installing-python-in-jupyter","position":7},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Running Python in Jupyter"},"type":"lvl2","url":"/jupyter#running-python-in-jupyter","position":8},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Running Python in Jupyter"},"content":"With your Conda environment activated and Jupyter session launched (see above), create a directory to store our work. Let’s call it pythia-foundations.\n\nYou can do this in the GUI left sidebar by clicking the new-folder icon. If you prefer to use the command line, you can access a terminal by clicking the icon under the “Other” heading in the Launcher.\n\nCreate a new mysci.ipynb file within the pythia-foundations folder:\n\nDo this in the GUI on the left sidebar by clicking the “+” icon.\n\nThis will open a new launcher window where you can select a Python kernel under the “Notebooks” heading for your project. You should see “Python 3” as in the screenshot above. Depending on the details of your system, you might see some additional buttons with different kernels.\n\nSelecting a kernel will open a Jupyter notebook instance and add an untitled file to the left sidebar navigator, which you can then rename to mysci.ipynb.\n\nSelect “Python 3” to use the Python version you just installed in the pythia_foundations_env conda environment.\n\nChange the first notebook cell to include the classic first command: printing, “Hello, world!”.print(\"Hello, world!\")\n\nRun your cell with Shift+Enter and see that the results are printed below the cell.\n\nCongratulations! You have just set up your first Python environment and run your first Python code in a Jupyter notebook.\n\nInfoThere are a few code-syntax differences between running Python in a Jupyter notebook and a script:\n\nIn a Python script, to print a variable to the terminal, you need to call print([THING YOU WANT TO PRINT]), whereas in Jupyter, you can simply have the last line of a code cell be [THING YOU WANT TO PRINT].\n\nSimilarly with plots, in Python, you have to call plt.show() to display your plot, but plots are shown automatically in Jupyter.","type":"content","url":"/jupyter#running-python-in-jupyter","position":9},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Saving your notebook and exiting"},"type":"lvl2","url":"/jupyter#saving-your-notebook-and-exiting","position":10},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Saving your notebook and exiting"},"content":"When you are done with your work, it is time to save and exit.\n\nTo save your file, you can click the disc icon in the upper left Jupyter toolbar or use keyboard shortcuts.\n\nJupyter allows you to close the browser tab without shutting down the server. When you’re done working on your notebook, it’s important to click the “Shutdown” button on the dashboard to free up memory, especially on a shared system.\n\nThen you can quit Jupyter by:\n\nclicking the “Quit” button on the top right, or\n\ntyping exit into the terminal\n\nAlternatively you can simultaneously shutdown and exit the Jupyter session by typing\nCtrl+C in the terminal and confirming that you do want to\n“shutdown this notebook server.”","type":"content","url":"/jupyter#saving-your-notebook-and-exiting","position":11},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Summary"},"type":"lvl2","url":"/jupyter#summary","position":12},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Summary"},"content":"Jupyter notebooks are a free, open-source, interactive tool running inside a web browser that allows you to run Python code in “cells.” To run a Jupyter session you will need to install jupyterlab into your Conda environment. Jupyter sessions need to be shutdown, not just exited.","type":"content","url":"/jupyter#summary","position":13},{"hierarchy":{"lvl1":"Python in Jupyter","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/jupyter#whats-next","position":14},{"hierarchy":{"lvl1":"Python in Jupyter","lvl3":"What’s Next?","lvl2":"Summary"},"content":"How to Run Python in the Terminal\n\nLearn more about Conda here\n\nGetting Started with Jupyter","type":"content","url":"/jupyter#whats-next","position":15},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Resources and References"},"type":"lvl2","url":"/jupyter#resources-and-references","position":16},{"hierarchy":{"lvl1":"Python in Jupyter","lvl2":"Resources and References"},"content":"conda-forge\n\nMiniforge Releases","type":"content","url":"/jupyter#resources-and-references","position":17},{"hierarchy":{"lvl1":"JupyterLab"},"type":"lvl1","url":"/jupyterlab","position":0},{"hierarchy":{"lvl1":"JupyterLab"},"content":"\n\n","type":"content","url":"/jupyterlab","position":1},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Overview"},"type":"lvl2","url":"/jupyterlab#overview","position":2},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Overview"},"content":"JupyterLab is a popular web application on which users can create and write their Jupyter Notebooks, as well as explore data, install software, etc. This section will introduce the JupyterLab interface and cover details of JupyterLab Notebooks.\n\nSet Up\n\nThe JupyterLab Interface\n\nRunning JupyterLab Notebooks\n\n","type":"content","url":"/jupyterlab#overview","position":3},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Prerequisites"},"type":"lvl2","url":"/jupyterlab#prerequisites","position":4},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nGetting Started with Jupyter\n\nHelpful\n\n\n\nInstalling and Running Python: Python in Jupyter\n\nHelpful\n\n\n\nTime to learn: 50 minutes\n\n\n\n","type":"content","url":"/jupyterlab#prerequisites","position":5},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Set Up"},"type":"lvl2","url":"/jupyterlab#set-up","position":6},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Set Up"},"content":"To launch the JupyterLab interface in your browser, follow the instructions in \n\nInstalling and Running Python: Python in Jupyter.\n\nIf, instead, you want to follow along using a provided remote JupyterLab instance, launch this notebook via \n\nBinder using the launch icon at the top of this page,\n\nand follow along from there! If launching Binder, take note of the Launcher tab in the upper-left (see interface below). Click there to find yourself in the same interface moving forward, and feel free to refer back to this tab to follow along.\n\n","type":"content","url":"/jupyterlab#set-up","position":7},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"The JupyterLab Interface"},"type":"lvl2","url":"/jupyterlab#the-jupyterlab-interface","position":8},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"The JupyterLab Interface"},"content":"Go to your browser and take a look at the JupyterLab interface.\n\nWith a base installation of JupyterLab your screen should look similar to the image below.\n\nNotice:\n\nThe Menu Bar at the top of the screen, containing the typical dropdown menus: “File”, “Edit”, “View”, etc.\n\nBelow that is the Workspace Area (currently contains the Launcher).\n\nThe Launcher is a quick shortcut for accessing the Console/Terminal, for creating new Notebooks, or for creating new Text or Markdown files.\n\nOn the left is a Collapsible Sidebar. It currently contains the File Browser, but you can also select the Running Tabs and Kernels, the Table of Contents, and the Extensions Manager.\n\nBelow everything is the Information Bar, which is context sensitive. We will touch on this more.\n\nWe will now take a closer look at certain aspects and features of the JupyterLab Interface.\n\n","type":"content","url":"/jupyterlab#the-jupyterlab-interface","position":9},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Left Sidebar","lvl2":"The JupyterLab Interface"},"type":"lvl3","url":"/jupyterlab#left-sidebar","position":10},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Left Sidebar","lvl2":"The JupyterLab Interface"},"content":"The Collapsible Left Sidebar is open to the File Browser Tab at launch. Clicking the File Browser Tab will collapse the sidebar or reopen it to this tab.\n\nWithin this tab, you will see the “+” button, which allows you to create a new launcher.\n\nNext to that is the “+ folder” button which allows you to create a new folder that then appears below “Name” in the contents of your directory. Double click the folder to enter it, right click the folder for options, or press the “root folder” icon to return to the root directory. The root directory is the directory from which JupyterLab was launched. You cannot go above the root directory.\n\nThe “upload” button (looks like an arrow pointing up) allows you to upload files to the current folder.\n\nThe “refresh” button refreshes the File Browser.\n\nBelow the File Browser Tab is the Running Tabs and Kernels Tab. Currently, this tab doesn’t have much in it. We will revisit this when we have running kernels. Remember that Kernels are background processes, so closing a tab (Terminal or Notebook) doesn’t shut down the kernel. You have to do that manually.\n\nThe Table of Contents Tab is auto-populated based on the headings and subheadings used in the Markdown cells of your notebook. It allows you to quickly jump between sections of the document.\n\nLast is the Extensions Manager Tab where you can customize or enhance any part of JupyterLab. These customizations could pertain to themes or keyboard shortcuts, for example. We will not be covering JupyterLab extensions, but you can read more about them \n\nhere.\n\n","type":"content","url":"/jupyterlab#left-sidebar","position":11},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Terminals","lvl2":"The JupyterLab Interface"},"type":"lvl3","url":"/jupyterlab#terminals","position":12},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Terminals","lvl2":"The JupyterLab Interface"},"content":"Let’s select the Running Tabs and Kernels Tab in the Left Sidebar and see how it changes when we’ve used the Launcher.\n\nOpen a Terminal in the Launcher. It should look very similar to the desktop terminal that you initially launched JupyterLab from, but is running from within JupyterLab, within your existing Conda environment, and within the directory you launched JupyterLab from (the same root folder shown in the File Browser Tab). Notice that there is now a Terminal listed in the Running Terminals Tab.\n\nIn the terminal you can use your usual terminal commands. For example, in the terminal window, run:$ mkdir test\n\nSelect the File Browser Tab, refresh it, and see that your new folder is there.\n\nIn the Terminal Window run:$ rmdir test\n\nHit refresh in the File Browser again to see that the directory is gone.\n\nBack with the Running Terminals and Kernels Tab open, click the “X” in your workspace to close the Terminal window. Notice that the Terminal is still running in the background!  Click on the terminal in the Running Terminals and Kernels Tab to reopen it (and hit enter or return to get your prompt back). To truly close it, execute in the Terminal window:$ exit\n\nOR click the “X” shut down button in the Running Terminals tab.\n\nDoing so will return you to the Launcher.\n\nInfoThe terminal is running on the local host when JupyterLab is launched locally, and remote host when invoked through Jupyter Hub.\n\n","type":"content","url":"/jupyterlab#terminals","position":13},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Consoles","lvl2":"The JupyterLab Interface"},"type":"lvl3","url":"/jupyterlab#consoles","position":14},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Consoles","lvl2":"The JupyterLab Interface"},"content":"Back in the Launcher, click the “Python 3” Console button. There is only one console option right now, but you could install more kernels into your Conda environment.\n\nThere will be three dots while the kernel starts, then what loads looks like an IPython console. This is a place to execute Python commands in a stand alone workspace which is good for testing. Notice that the kernel started in the Running Terminals and Kernels tab!\n\nStart in a “cell” at the bottom of the Console window. Type:i = 5\nprint(i)\n\nTo execute the cell, type Shift+Enter. Notice that the console redisplays the code you wrote, labels it with a number, and displays (prints) the output to the screen.\n\nIn the next cell, enter:s = 'Hello, World!'\nprint(f's = {s}')\ns\n\nThe first line of this code designates a string s with the value “Hello, World!”, the second line uses f-formatting to print the string, and the final line just calls up s. The last line in the cell will always be returned (its value displayed) regardless of whether you called print. Type Shift+Enter to execute the cell. Again the output is labeled (this time with a 2), and we see the input code, the printed standard-out statement, and the return statement. The “return value” and the values “printed to screen” are different!\n\nClose the window and shut down the Console in the Running Kernels tab. We’re back to the Launcher again.\n\n","type":"content","url":"/jupyterlab#consoles","position":15},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Text Editor","lvl2":"The JupyterLab Interface"},"type":"lvl3","url":"/jupyterlab#text-editor","position":16},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Text Editor","lvl2":"The JupyterLab Interface"},"content":"Click on the “Text File” button in the Launcher.\nSelect the File Browser tab to see the new file untitled.txt you created.\n\nEnter this Python code into the new text file:s = 'Hello, World!'\nprint(s)\n\nYou may notice that the file has a dot instead of an “X” where you’d close it. This indicates that the file hasn’t been saved or has unsaved changes. Save the file (“command+s” on Mac, “control+s” on Windows, or “File▶Save Text”).\n\nGo to the File Browser tab, right-click the new file we created and “Rename” it to hello.py. Once the extension changes to .py, Jupyter recognizes that this is a Python file, and the text editor highlights the code based on Python syntax.\n\nNow, click the “+” button in the File Browser to create a new Launcher. In the Launcher tab, click on the “Terminal” button again to create a terminal. Now you have 2 tabs open: a text editor tab and a terminal tab. Drag the Terminal tab to the right side of the main work area to view both windows simultaneously. Click the File Browser tab to collapse the left sidebar and get more real estate! Alternatively, you could stack the windows one on top of the other.\n\nRun ls in the Terminal window to see the text file we just created. Execute python hello.py in the Terminal window. See the output in the Terminal window.\n\nNow, let’s close the Terminal tab and shut down the Terminal in the Running Kernels tab (or execute “exit” in the Terminal itself). You should just have the Text editor window open; now we’re ready to look at Jupyter Notebooks.\n\n","type":"content","url":"/jupyterlab#text-editor","position":17},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Running JupyterLab Notebooks"},"type":"lvl2","url":"/jupyterlab#running-jupyterlab-notebooks","position":18},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Running JupyterLab Notebooks"},"content":"There are two ways to open a Jupyter Notebook. One way is to select the File Browser Tab, click the “New Launcher” button, and select a Python 3 Notebook from the Launcher. Another way is to go to the top Menu Bar and select “File▶New▶Notebook”. JupyterLab will prompt you with a dialogue box to select the Kernel you want to use in your Notebook. Select the “Python 3” kernel.\n\nIf you have the File Browser Tab open, notice you just created a file called Untitled.ipynb. You will also have a new window open in the main work area for your new Notebook.\n\nLet’s explore the Notebook interface:\n\nThere is a Toolbar at the top with buttons that allow you to Save, Create New Cells, Cut/Paste/Copy Cells, Run the Cell, Stop the Kernel, and Refresh the Kernel. There is also a dropdown menu to select the kind of cell (Markdown, Raw, or Code). All the way to the right is the name of your Kernel (which you can click to change Kernels) and a Kernel Status Icon that indicates if something is being computed by the Kernel (by a dark circle) or not (by an empty circle).\n\nBelow the Toolbar is the Notebook itself. You should see an empty cell at the top of the Notebook. This should look similar to the layout of the Console.\n\nThe cell can be in 1 of 2 modes:  command mode or edit mode.\nIf your cell is grayed out and you can’t see a blinking cursor in the cell, then the cell is in command mode. We’ll talk about command mode more later. Click inside the box, and the cell will turn white with a blinking cursor inside it; the cell is now in edit mode. The mode is also listed on the info bar at the bottom of the page. The cell is selected if the blue bar is on the left side of the cell.\n\nYou may move the Notebook over so you can see your text file at the same time to compare, resizing the Notebook window as needed.\n\n","type":"content","url":"/jupyterlab#running-jupyterlab-notebooks","position":19},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Code Cells","lvl2":"Running JupyterLab Notebooks"},"type":"lvl3","url":"/jupyterlab#code-cells","position":20},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Code Cells","lvl2":"Running JupyterLab Notebooks"},"content":"Click inside the first cell of the Notebook to switch the cell to edit mode.\nEnter the following into the cell:print(2+2)\n\nThen type Shift+Enter to execute the cell.\n\nYou’ll see the output, 4, printed directly below your code cell. Executing the cell automatically creates a new cell in edit mode below the first.\n\nIn this new cell, enter:for i in range(4):\n    print(i) \n\nExecute the cell. A Jupyter code cell can run multiple lines of code; each Jupyter code cell can even contain a complete Python program!\n\nTo demonstrate how to import code that you have written in a .py file, enter the following into the next cell:import hello\n\nThen type Shift+Enter.\n\nThis single-line import statement runs the contents of your hello.py script file, and would do the same for any file regardless of length.\n\nWarningIt is generally considered bad practice to include any output in a “.py” file meant to be imported and used within different Python scripts. Such a file should contain only function and class definitions.\n\nYou've executed the cell with the Python 3 kernel, and it spit out the output, “Hello, World!” Since you've imported the `hello.py` module into the Notebook’s kernel runtime, you can now directly look at the variable “s” in this second cell. Enter the following in the next cell:hello.s\n\nHit Shift+Enter to execute.\n\nAgain, it displays the value of the variable s from the “hello” module we just created. One difference is that this time the output is given its own label [2] matching the input label of the cell (whereas the output from cell [1] is not labelled).  This is the difference between output sent to the screen vs. the return value of the cell.\n\nLet’s now import a module from the Python standard library:import time\ntime.sleep(10)\n\nAgain, hit Shift+Enter.\n\nThe time.sleep(10) function causes code to wait for 10 seconds, which is plenty of time to notice how the cell changes in time:\n\nThe label of the cell is [*], indicating that the kernel is running that cell\n\nIn the top right corner of the Notebook, the status icon is a filled-in circle, indicating that the kernel is running\n\nAfter 10 seconds, the cell completes running, the label is updated to [3], and the status icon returns to the “empty circle” state. If you rerun the cell, the label will update to [4]`.\n\n","type":"content","url":"/jupyterlab#code-cells","position":21},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Markdown Cells","lvl2":"Running JupyterLab Notebooks"},"type":"lvl3","url":"/jupyterlab#markdown-cells","position":22},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Markdown Cells","lvl2":"Running JupyterLab Notebooks"},"content":"Now, with the next cell selected (i.e., the blue bar appears to the left of the cell), whether in edit or command mode, go up to the “cell type” dropdown menu above and select “Markdown”.\nNotice that the [ ] label goes away.\n\nMarkdown is a markup language that allows you to format text in a plain-text editor. Here we will demonstrate some common Markdown syntax. You can learn more at \n\nthe Markdown Guide site or in our \n\nGetting Started with Jupyter: Markdown content.\nClick on the cell and enter edit mode; we can now type in some markdown text like so:# This is a heading!\nAnd this is some text.\n\n## And this is a subheading\nwith a bulleted list in it:\n\n - one\n - two\n - three\n\nThen press Shift+Enter to render the markdown to HTML.\n\nAgain, in the next cell, change the cell type to “Markdown”. To demonstrate displaying equations, enter:## Some math\n\nAnd Jupyter’s version of markdown can display LaTeX:\n\n$$\ne^x=\\sum_{i=0}^{\\infty} \\frac{1}{i!}x^i\n$$\n\nWhen you are done, type Shift+Enter to render the markdown document.\n\nYou can also do inline equations with a single “$”, for exampleThis is an equation: $i^4$.\n\nNote that the “markdown” source code is rendered into much prettier text, which we can take advantage of for narrating our work in the Notebook!\n\n","type":"content","url":"/jupyterlab#markdown-cells","position":23},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Raw Cells","lvl2":"Running JupyterLab Notebooks"},"type":"lvl3","url":"/jupyterlab#raw-cells","position":24},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Raw Cells","lvl2":"Running JupyterLab Notebooks"},"content":"Now in a new cell selected, select “raw” from the “cell type” dropdown menu. Again, the [ ] label goes away, and you can enter the following in the cell:i = 8\nprint(i)\n\nWhen you Shift+Enter the text isn’t rendered.\n\nThis is a way of entering text/source that you do not want the Notebook to do anything with (i.e., no rendering).\n\n","type":"content","url":"/jupyterlab#raw-cells","position":25},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Command Mode Shortcuts","lvl2":"Running JupyterLab Notebooks"},"type":"lvl3","url":"/jupyterlab#command-mode-shortcuts","position":26},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Command Mode Shortcuts","lvl2":"Running JupyterLab Notebooks"},"content":"Now, select the “raw” cell you just created by clicking on the far left of the cell.\n\nYou are now in “command mode”. The up and down arrows move to different cells. Don’t hit “enter” which would switch the cell to “edit mode.\" Let’s explore command mode.\n\nYou can change the cell type with y for code, m for markdown, or r for raw.\n\nYou can add a new cell above the selected cell with a (or below the selected cell with b).\n\nYou can cut (x), copy (c), and paste (v).\n\nYou can move a cell up or down by clicking and dragging.\n\nWarningCells can be executed in any order you want. You just have to select the cell and Shift+Enter, and select the cells in any order you want. However, if you share your notebook, there is an implicit expectation to execute the cells in the order in which they are presented in the notebook. Be careful with this! If variables are reused or redefined between cells, reordering them could have unintended consequences!\n\n","type":"content","url":"/jupyterlab#command-mode-shortcuts","position":27},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Special Variables","lvl2":"Running JupyterLab Notebooks"},"type":"lvl3","url":"/jupyterlab#special-variables","position":28},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Special Variables","lvl2":"Running JupyterLab Notebooks"},"content":"Now, in the empty cell at the end, enter one underscore:_\n\nThis is a special character that means the last cell output.  Two underscores means the second to last cell output, and three underscores means the third to last output. You can also refer to the output by label with:_2\n\nDangerIf the cell you to refer to does not have a return value, this will raise an error.\n\nYou can equivalently use the variables Out[2] or In[2] to retrieve the output and input (as a string).\n\n","type":"content","url":"/jupyterlab#special-variables","position":29},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Shell Commands","lvl2":"Running JupyterLab Notebooks"},"type":"lvl3","url":"/jupyterlab#shell-commands","position":30},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Shell Commands","lvl2":"Running JupyterLab Notebooks"},"content":"In the next code cell, enter the following:!pwd\n\nThe ! allows you to write shell commands. A shell command is a command that is run by the host operating system, not the Python kernel. Executing this cell will “print the working directory” (i.e. your current directory).\n\nYou can even use the output of shell commands as input to Python code. For example:files = !ls\nprint(files)\n\n","type":"content","url":"/jupyterlab#shell-commands","position":31},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Stopping & Restarting the Kernel","lvl2":"Running JupyterLab Notebooks"},"type":"lvl3","url":"/jupyterlab#stopping-restarting-the-kernel","position":32},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Stopping & Restarting the Kernel","lvl2":"Running JupyterLab Notebooks"},"content":"All of your commands and their output have been remembered by the kernel. However, sometimes you may get code that takes too long to execute, and you need to stop it. For example, in the next code cell, run:time.sleep(1000)\n\nYou can stop the kernel with the square “stop” button at the top Notebook toolbar.  This results in a “KeyboardInterrupt” error.\n\nIf you execute a notebook out of order, you can end up in a corrupted state (redefined variables, for example). To start fresh, you should restart the kernel with the circle-arrow button in the toolbar at the top. Now the kernel has forgotten everything, and you’ll need to rerun each cell.\n\n","type":"content","url":"/jupyterlab#stopping-restarting-the-kernel","position":33},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Magics","lvl2":"Running JupyterLab Notebooks"},"type":"lvl3","url":"/jupyterlab#magics","position":34},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"Magics","lvl2":"Running JupyterLab Notebooks"},"content":"A “magic” is a Jupyter Notebook command proceded by a % symbol. In the next code cell, enter the following:%timeit time.sleep(1)\n\nThe “%timeit” magic is a timer that runs the command multiple times, measuring how long it takes and gathering timing statistics. Hit Shift+Enter to see it work.\n\nMultiline magics work on entire cells, and these have a double-%.  For example, here is a multiline version of the timeit magic:%%timeit\n\ntime.sleep(0.5)\ntime.sleep(0.5)\n\nThen press Shift+Enter to run it.  This will time the entire cell.\n\n","type":"content","url":"/jupyterlab#magics","position":35},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Shutting Down"},"type":"lvl2","url":"/jupyterlab#shutting-down","position":36},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Shutting Down"},"content":"Before shutting down, save your notebook with the disc icon in the Notebook toolbar. Now, close both tabs (the notebook and the text editor). You’re back to the Launcher.\n\nThe notebook kernel is still running, though, so go to the Running Kernels tab and shut it down.\n\nNow we’re done.  Go to “File▶Shut Down” to close both your browser tab and JupyterLab itself.\n\n","type":"content","url":"/jupyterlab#shutting-down","position":37},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Summary"},"type":"lvl2","url":"/jupyterlab#summary","position":38},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Summary"},"content":"You are now familiar with the JupyterLab interface and running Jupyter Notebooks. Jupyter is popular for allowing you to intersperse Markdown text or equations between code cells. Jupyter offers some functionality that a Python script does not: certain keyboard shortcuts, special variables, shell scripting, and magics.","type":"content","url":"/jupyterlab#summary","position":39},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/jupyterlab#whats-next","position":40},{"hierarchy":{"lvl1":"JupyterLab","lvl3":"What’s next?","lvl2":"Summary"},"content":"Markdown\n\n","type":"content","url":"/jupyterlab#whats-next","position":41},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Resources and references"},"type":"lvl2","url":"/jupyterlab#resources-and-references","position":42},{"hierarchy":{"lvl1":"JupyterLab","lvl2":"Resources and references"},"content":"Jupyter Documentation\n\nJupyterLab Documentation\n\nJupyterLab Extensions\n\nMarkdown Guide\n\nXdev Python Tutorial Seminar Series - Jupyter Notebooks","type":"content","url":"/jupyterlab#resources-and-references","position":43},{"hierarchy":{"lvl1":"Formatted Text in the Notebook with Markdown"},"type":"lvl1","url":"/markdown","position":0},{"hierarchy":{"lvl1":"Formatted Text in the Notebook with Markdown"},"content":"Note\n\nThis content is under construction!\n\nThis section will give a tutorial on formatting text with Markdown: the simple, human-readable text language used extensively in Jupyter notebooks, GitHub Discussions, and elsewhere.\n\nWe will show how this is useful both in notebooks and other places like GitHub Issues.","type":"content","url":"/markdown","position":1},{"hierarchy":{"lvl1":"Overview"},"type":"lvl1","url":"/overview","position":0},{"hierarchy":{"lvl1":"Overview"},"content":"\n\nThis Foundational Skills section of the book contains cross-referenced tutorial material for computing skills that one needs in order to work effectively with the open-source Scientific Python stack.\n\nFamiliarizing yourself with these topics first will allow you to get the most out the Python-specific material in the \n\nCore Scientific Python Packages section of the book!","type":"content","url":"/overview","position":1},{"hierarchy":{"lvl1":"Overview","lvl2":"Topics"},"type":"lvl2","url":"/overview#topics","position":2},{"hierarchy":{"lvl1":"Overview","lvl2":"Topics"},"content":"Why Python?: A brief preamble about Python’s distinguishing features.\n\nGetting started with Python: A quickstart Python example, followed by detailed tutorials on how to install and run Python on your own system.\n\nGetting started with Jupyter: All about the Jupyter ecosystem, which provides tools and environments for interactive, reproducible computing with Python.\n\nGetting started with GitHub: Learn about the collaboration tools (GitHub) and version control software (git) that enables the open-source community.","type":"content","url":"/overview#topics","position":3},{"hierarchy":{"lvl1":"Quickstart: Zero to Python"},"type":"lvl1","url":"/quickstart","position":0},{"hierarchy":{"lvl1":"Quickstart: Zero to Python"},"content":"Brand new to Python? Here are some quick examples of what Python code looks like.\n\nThis is not meant to be a comprehensive Python tutorial, just something to whet your appetite.\n\n","type":"content","url":"/quickstart","position":1},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Run this code from your browser!"},"type":"lvl2","url":"/quickstart#run-this-code-from-your-browser","position":2},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Run this code from your browser!"},"content":"Of course you can simply read through these examples, but it’s more fun to run them yourself:\n\nFind the “Rocket Ship” icon, located near the top-right of this page. Hover over this icon to see the drop-down menu.\n\nClick the Binder link from the drop-down menu.\n\nThis page will open up as a \n\nJupyter notebook in a working Python environment in the cloud.\n\nPress Shift+Enter to execute each code cell\n\nFeel free to make changes and play around!\n\n","type":"content","url":"/quickstart#run-this-code-from-your-browser","position":3},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"A very first Python program"},"type":"lvl2","url":"/quickstart#a-very-first-python-program","position":4},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"A very first Python program"},"content":"A Python program can be a single line:\n\nprint(\"Hello interweb\")\n\n","type":"content","url":"/quickstart#a-very-first-python-program","position":5},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Loops in Python"},"type":"lvl2","url":"/quickstart#loops-in-python","position":6},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Loops in Python"},"content":"\n\nLet’s start by making a for loop with some formatted output:\n\nfor n in range(3):\n    print(f\"Hello interweb, this is iteration number {n}\")\n\nA few things to note:\n\nPython defaults to counting from 0 (like C) rather than from 1 (like Fortran).\n\nFunction calls in Python always use parentheses: print()\n\nThe colon : denotes the beginning of a definition (here of the repeated code under the for loop).\n\nCode blocks are identified through indentations.\n\nTo emphasize this last point, here is an example with a two-line repeated block:\n\nfor n in range(3):\n    print(\"Hello interweb!\")\n    print(f\"This is iteration number {n}.\")\nprint('And now we are done.')\n\n","type":"content","url":"/quickstart#loops-in-python","position":7},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Basic flow control"},"type":"lvl2","url":"/quickstart#basic-flow-control","position":8},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Basic flow control"},"content":"Like most languages, Python has an if statement for logical decisions:\n\nif n > 2:\n    print(\"n is greater than 2!\")\nelse:\n    print(\"n is not greater than 2!\")\n\nPython also defines the True and False logical constants:\n\nn > 2\n\nThere’s also a while statement for conditional looping:\n\nm = 0\nwhile m < 3:\n    print(f\"This is iteration number {m}.\")\n    m += 1\nprint(m < 3)\n\n","type":"content","url":"/quickstart#basic-flow-control","position":9},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Basic Python data types"},"type":"lvl2","url":"/quickstart#basic-python-data-types","position":10},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Basic Python data types"},"content":"Python is a very flexible language, and many advanced data types are introduced through packages (more on this below). But some of the basic types include:\n\n","type":"content","url":"/quickstart#basic-python-data-types","position":11},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl3":"Integers (int)","lvl2":"Basic Python data types"},"type":"lvl3","url":"/quickstart#integers-int","position":12},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl3":"Integers (int)","lvl2":"Basic Python data types"},"content":"The number m above is a good example. We can use the built-in function type() to inspect what we’ve got in memory:\n\nprint(type(m))\n\n","type":"content","url":"/quickstart#integers-int","position":13},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl3":"Floating point numbers (float)","lvl2":"Basic Python data types"},"type":"lvl3","url":"/quickstart#floating-point-numbers-float","position":14},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl3":"Floating point numbers (float)","lvl2":"Basic Python data types"},"content":"Floats can be entered in decimal notation:\n\nprint(type(0.1))\n\nor in scientific notation:\n\nprint(type(4e7))\n\nwhere 4e7 is the Pythonic representation of the number  4 \\times 10^7 .\n\n","type":"content","url":"/quickstart#floating-point-numbers-float","position":15},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl3":"Character strings (str)","lvl2":"Basic Python data types"},"type":"lvl3","url":"/quickstart#character-strings-str","position":16},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl3":"Character strings (str)","lvl2":"Basic Python data types"},"content":"You can use either single quotes '' or double quotes \" \" to denote a string:\n\nprint(type(\"orange\"))\n\nprint(type('orange'))\n\n","type":"content","url":"/quickstart#character-strings-str","position":17},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl3":"Lists","lvl2":"Basic Python data types"},"type":"lvl3","url":"/quickstart#lists","position":18},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl3":"Lists","lvl2":"Basic Python data types"},"content":"A list is an ordered container of objects denoted by square brackets:\n\nmylist = [0, 1, 1, 2, 3, 5, 8]\n\nLists are useful for lots of reasons including iteration:\n\nfor number in mylist:\n    print(number)\n\nLists do not have to contain all identical types:\n\nmyweirdlist = [0, 1, 1, \"apple\", 4e7]\nfor item in myweirdlist:\n    print(type(item))\n\nThis list contains a mix of int (integer), float (floating point number), and str (character string).\n\nBecause a list is ordered, we can access items by integer index:\n\nmyweirdlist[3]\n\nremembering that we start counting from zero!\n\nPython also allows lists to be created dynamically through list comprehension like this:\n\nsquares = [i**2 for i in range(11)]\nsquares\n\n","type":"content","url":"/quickstart#lists","position":19},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl3":"Dictionaries (dict)","lvl2":"Basic Python data types"},"type":"lvl3","url":"/quickstart#dictionaries-dict","position":20},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl3":"Dictionaries (dict)","lvl2":"Basic Python data types"},"content":"A dictionary is a collection of labeled objects. Python uses curly braces {} to create dictionaries:\n\nmypet = {\n    \"name\": \"Fluffy\",\n    \"species\": \"cat\",\n    \"age\": 4,\n}\ntype(mypet)\n\nWe can then access items in the dictionary by label using square brackets:\n\nmypet[\"species\"]\n\nWe can iterate through the keys (or labels) of a dict:\n\nfor key in mypet:\n    print(\"The key is:\", key)\n    print(\"The value is:\", mypet[key])\n\n","type":"content","url":"/quickstart#dictionaries-dict","position":21},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Arrays of numbers with NumPy"},"type":"lvl2","url":"/quickstart#arrays-of-numbers-with-numpy","position":22},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Arrays of numbers with NumPy"},"content":"The vast majority of scientific Python code makes use of packages that extend the base language in many useful ways.\n\nAlmost all scientific computing requires ordered arrays of numbers, and fast methods for manipulating them. That’s what \n\nNumPy does in the Python world.\n\nUsing any package requires an import statement, and (optionally) a nickname to be used locally, denoted by the keyword as:\n\nimport numpy as np\n\nNow all our calls to numpy functions will be preceeded by np.\n\nCreate a linearly space array of numbers:\n\n# linspace() takes 3 arguments: start, end, total number of points\nnumbers = np.linspace(0.0, 1.0, 11)\nnumbers\n\nWe’ve just created a new type of object defined by \n\nNumPy:\n\ntype(numbers)\n\nDo some arithmetic on that array:\n\nnumbers + 1\n\nSum up all the numbers:\n\nnp.sum(numbers)\n\n","type":"content","url":"/quickstart#arrays-of-numbers-with-numpy","position":23},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Some basic graphics with Matplotlib"},"type":"lvl2","url":"/quickstart#some-basic-graphics-with-matplotlib","position":24},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Some basic graphics with Matplotlib"},"content":"Matplotlib is the standard package for producing publication-quality graphics, and works hand-in-hand with \n\nNumPy arrays.\n\nWe usually use the pyplot submodule for day-to-day plotting commands:\n\nimport matplotlib.pyplot as plt\n\nDefine some data and make a line plot:\n\ntheta = np.linspace(0.0, 360.0)\nsintheta = np.sin(np.deg2rad(theta))\n\nplt.plot(theta, sintheta, label='y = sin(x)', color='purple')\nplt.grid()\nplt.legend()\nplt.xlabel('Degrees')\nplt.title('Our first Pythonic plot', fontsize=14)\n\n","type":"content","url":"/quickstart#some-basic-graphics-with-matplotlib","position":25},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"What now?"},"type":"lvl2","url":"/quickstart#what-now","position":26},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"What now?"},"content":"That was a whirlwind tour of some basic Python usage.\n\nRead on for more details on how to install and run Python and necessary packages on your own laptop.\n\n","type":"content","url":"/quickstart#what-now","position":27},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Resources and references"},"type":"lvl2","url":"/quickstart#resources-and-references","position":28},{"hierarchy":{"lvl1":"Quickstart: Zero to Python","lvl2":"Resources and references"},"content":"Official Python tutorial (Python Docs)","type":"content","url":"/quickstart#resources-and-references","position":29},{"hierarchy":{"lvl1":"Python in the Terminal"},"type":"lvl1","url":"/terminal","position":0},{"hierarchy":{"lvl1":"Python in the Terminal"},"content":"","type":"content","url":"/terminal","position":1},{"hierarchy":{"lvl1":"Python in the Terminal","lvl2":"Overview"},"type":"lvl2","url":"/terminal#overview","position":2},{"hierarchy":{"lvl1":"Python in the Terminal","lvl2":"Overview"},"content":"You’d like to learn to run Python in the terminal. Here we will cover:\n\nInstalling Python in the terminal\n\nRunning Python code in the terminal","type":"content","url":"/terminal#overview","position":3},{"hierarchy":{"lvl1":"Python in the Terminal","lvl2":"Prerequisites"},"type":"lvl2","url":"/terminal#prerequisites","position":4},{"hierarchy":{"lvl1":"Python in the Terminal","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nInstalling and Running Python\n\nHelpful\n\n\n\nTime to learn: 20 minutes","type":"content","url":"/terminal#prerequisites","position":5},{"hierarchy":{"lvl1":"Python in the Terminal","lvl2":"Installing Python in the Terminal"},"type":"lvl2","url":"/terminal#installing-python-in-the-terminal","position":6},{"hierarchy":{"lvl1":"Python in the Terminal","lvl2":"Installing Python in the Terminal"},"content":"If you are running Python in the terminal, it is best to install Miniforge. You can do that by following the \n\ninstructions for your machine.\n\nLearn more about Conda here\n\nThen create a Conda environment with Python installed by typing the following into your terminal:$ conda create --name pythia_foundations_env python\n\nYou can test this by running python in the command line.","type":"content","url":"/terminal#installing-python-in-the-terminal","position":7},{"hierarchy":{"lvl1":"Python in the Terminal","lvl2":"Running Python in the Terminal"},"type":"lvl2","url":"/terminal#running-python-in-the-terminal","position":8},{"hierarchy":{"lvl1":"Python in the Terminal","lvl2":"Running Python in the Terminal"},"content":"On Windows, open Anaconda Prompt. On a Mac or Linux machine, simply open Terminal.\n\nActivate your Conda environment:$ conda activate pythia_foundations_env\n\nCreate a directory to store our work. Let’s call it pythia-foundations.$ mkdir pythia-foundations\n\nGo into the directory:$ cd pythia-foundations\n\nCreate a new Python file:$ touch mysci.py\n\nAnd now that you’ve set up our workspace, edit the mysci.py script using your favorite text editor (e.g., nano):$ nano mysci.py\n\nChange the script to include the classic first command: printing, “Hello, world!”.print(\"Hello, world!\")\n\nSave your file and exit the editor. How to do this is dependent on your chosen text editor.\n\nIn Vim, revert to command mode by pressing esc. Then, the command is :wq.\n\nIn Nano it is Ctrl+O to save and Ctrl+X to exit (where you will be prompted if you want to save it, if modified).\n\nIn the terminal, execute your script:$ python mysci.py\n\nCongratulations! You have just set up your first Python environment and run your first Python script in the terminal.","type":"content","url":"/terminal#running-python-in-the-terminal","position":9},{"hierarchy":{"lvl1":"Python in the Terminal","lvl2":"Summary"},"type":"lvl2","url":"/terminal#summary","position":10},{"hierarchy":{"lvl1":"Python in the Terminal","lvl2":"Summary"},"content":"Running Python in the terminal is a good option if you are familiar with Linux commands or scripting on a supercomputer. It requires the use of a text editor.","type":"content","url":"/terminal#summary","position":11},{"hierarchy":{"lvl1":"Python in the Terminal","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/terminal#whats-next","position":12},{"hierarchy":{"lvl1":"Python in the Terminal","lvl3":"What’s Next?","lvl2":"Summary"},"content":"How to Run Python in a Jupyter Session\n\nLearn more about Conda here","type":"content","url":"/terminal#whats-next","position":13},{"hierarchy":{"lvl1":"Python in the Terminal","lvl2":"Resources and References"},"type":"lvl2","url":"/terminal#resources-and-references","position":14},{"hierarchy":{"lvl1":"Python in the Terminal","lvl2":"Resources and References"},"content":"Linux commands","type":"content","url":"/terminal#resources-and-references","position":15},{"hierarchy":{"lvl1":"Why Python?"},"type":"lvl1","url":"/why-python","position":0},{"hierarchy":{"lvl1":"Why Python?"},"content":"You’re already here because you want to learn to use Python for your data analysis and visualizations.\n\nPerhaps the #1 reason to use Python is because it is so widely used in the scientific community!\n\nPython can be compared to other high-level, interpreted, object-oriented languages, but is especially great because it is free and open source!\n\nWant to know what these terms mean for you and your work? Read on!","type":"content","url":"/why-python","position":1},{"hierarchy":{"lvl1":"Why Python?","lvl2":"High level languages"},"type":"lvl2","url":"/why-python#high-level-languages","position":2},{"hierarchy":{"lvl1":"Why Python?","lvl2":"High level languages"},"content":"Other high level languages include MatLab, IDL, and NCL. The advantage of high level languages is that they provide built-in functions, data structures, and other utilities that are commonly used, which means it takes less code to get real work done. The disadvantage of high level languages is that they tend to obscure the low level aspects of the machine such as memory use, how many floating point operations are happening, and other information related to performance. C, C++, and Fortran are all examples of lower level languages. The “higher” the level of language, the more computing fundamentals are abstracted.","type":"content","url":"/why-python#high-level-languages","position":3},{"hierarchy":{"lvl1":"Why Python?","lvl2":"Interpreted languages"},"type":"lvl2","url":"/why-python#interpreted-languages","position":4},{"hierarchy":{"lvl1":"Why Python?","lvl2":"Interpreted languages"},"content":"Most of your work is probably already in interpreted languages if you’ve ever used IDL, NCL, or MatLab (interpreted languages are typically also high level). So you are already familiar with the advantages of this: you don’t have to worry about compiling or machine compatibility (it is portable). And you are probably familiar with their deficiencies: sometimes they can be slower than compiled languages and potentially more memory intensive.","type":"content","url":"/why-python#interpreted-languages","position":5},{"hierarchy":{"lvl1":"Why Python?","lvl2":"Object Oriented languages"},"type":"lvl2","url":"/why-python#object-oriented-languages","position":6},{"hierarchy":{"lvl1":"Why Python?","lvl2":"Object Oriented languages"},"content":"Objects are custom datatypes. For every custom datatype, you usually have a set of operations you might want to conduct. For example, if you have an object that is a list of numbers, you might want to apply a mathematical operation, such as sum, onto this list object in bulk. Not every function can be applied to every datatype; it wouldn’t make sense to apply a logarithm to a string of letters or to capitalize a list of numbers. Data and the operations applied to them are grouped together into one object.","type":"content","url":"/why-python#object-oriented-languages","position":7},{"hierarchy":{"lvl1":"Why Python?","lvl2":"Open source"},"type":"lvl2","url":"/why-python#open-source","position":8},{"hierarchy":{"lvl1":"Why Python?","lvl2":"Open source"},"content":"Python as a language is open source, which means that there is a community of developers behind its codebase. Anyone can join the developer community and contribute to deciding the future of the language. When someone identifies gaps in Python’s abilities, they can write up the code to fill these gaps. The open source nature of Python means that Python as a language is very adaptable to the shifting needs of the user community. This harkens back to the idea that the widespread use of Python within the scientific community is a benefit to you! The large Python user base within your field has established high level community Python packages that are available to you in your workflow.\n\nPython is a language designed for rapid prototyping and efficient programming. It is easy to write new code quickly with less typing.","type":"content","url":"/why-python#open-source","position":9},{"hierarchy":{"lvl1":"Pythia Foundations"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Pythia Foundations"},"content":"","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Pythia Foundations","lvl2":"A community learning resource for Python-based computing in the geosciences"},"type":"lvl2","url":"/#a-community-learning-resource-for-python-based-computing-in-the-geosciences","position":2},{"hierarchy":{"lvl1":"Pythia Foundations","lvl2":"A community learning resource for Python-based computing in the geosciences"},"content":"\n\nThis collection covers the foundational skills everyone needs to get started with scientific computing in the open-source Python ecosystem.\n\n Brought to you by \n\nProject Pythia, the education working group for \n\nPangeo \n\n","type":"content","url":"/#a-community-learning-resource-for-python-based-computing-in-the-geosciences","position":3},{"hierarchy":{"lvl1":"How to Cite This Book"},"type":"lvl1","url":"/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Book"},"content":"The material in Pythia Foundations is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest version of the book source:\n\n\nRose et al. (2025)\n\nIf material in Pythia Foundations is useful in published work, you can cite a specific version of the book as:\n\nRose, B. E. J., Kent, J., Tyle, K., Clyne, J., Banihirwe, A., Camron, D., May, R., Grover, M., Ford, R. R., Paul, K., Morley, J., Eroglu, O., Kailyn, L., & Zacharias, A. (2023). Pythia Foundations (Version v2023.05.01) \n\nRose et al. (2023)","type":"content","url":"/how-to-cite","position":1},{"hierarchy":{"lvl1":"How to Use This Book"},"type":"lvl1","url":"/how-to-use","position":0},{"hierarchy":{"lvl1":"How to Use This Book"},"content":"","type":"content","url":"/how-to-use","position":1},{"hierarchy":{"lvl1":"How to Use This Book","lvl2":"Overview"},"type":"lvl2","url":"/how-to-use#overview","position":2},{"hierarchy":{"lvl1":"How to Use This Book","lvl2":"Overview"},"content":"Pythia Foundations is a geoscience-flavored introduction to essential tools in the Scientific Python Ecosystem (SPE) and \n\nPangeo stack. It covers the foundational knowledge that’s needed to get started with Python in the computational geosciences, as well as to become an effective citizen-practitioner in key open geoscience software ecosystems. The intended audience is anyone from undergraduate students through established geoscientists who are relatively new to working in Python. The tutorials in this book also serve as references and prerequisites for the more advanced and domain-specific content in the \n\nPythia Cookbook Gallery.","type":"content","url":"/how-to-use#overview","position":3},{"hierarchy":{"lvl1":"How to Use This Book","lvl2":"What’s included"},"type":"lvl2","url":"/how-to-use#whats-included","position":4},{"hierarchy":{"lvl1":"How to Use This Book","lvl2":"What’s included"},"content":"The Scientific Python Ecosystem (SPE) is a collection of\nopen source Python packages that support analysis, manipulation,\nand visualization of scientific data. While Project Pythia is focused\non the geoscience communities, the material contained in Pythia\nFoundations applies broadly, and may be useful to scientists, or\naspiring scientists, working in any number of disciplines. Pythia\nFoundations makes very few assumptions about the experience level\nof the reader other than having a background in math or science,\nand being comfortable using a computer, including the command line\nterminal (i.e. the \n\nUnix shell).\nPrior programming experience is not required.\n\nLastly, in addition to the Python language and a number of fundamental\nscientific Python packages, Pythia Foundations covers two topics\nthat we believe are essential\nto effectively using the SPE: GitHub, for sharing workflows and\nmanaging code; and Jupyter Notebooks, the technology by which all\nPythia Foundations material is presented and which is quickly\nbecoming a standard format for scientific communication of computational\nresults.","type":"content","url":"/how-to-use#whats-included","position":5},{"hierarchy":{"lvl1":"How to Use This Book","lvl2":"Organization of Pythia Foundations"},"type":"lvl2","url":"/how-to-use#organization-of-pythia-foundations","position":6},{"hierarchy":{"lvl1":"How to Use This Book","lvl2":"Organization of Pythia Foundations"},"content":"Pythia Foundations is organized into two main sections as seen in\nthe sidebar on the left: Foundational Skills, and Core Scientific\nPython Packages. The first, Foundational Skills, covers essential\nmaterial that all users of Project Pythia are expected to feel\ncomfortable with in order to make the most of the rest of the Project\nPythia content. The second, Core Scientific Python Packages, covers\nwhat we believe are the most important and fundamental packages\nin the Scientific Python Ecosystem. These packages serve as the\nbuilding blocks for many of the more geoscience focused components\nof the Scientific Python Ecosystem.","type":"content","url":"/how-to-use#organization-of-pythia-foundations","position":7},{"hierarchy":{"lvl1":"How to Use This Book","lvl2":"Running Pythia Foundations examples"},"type":"lvl2","url":"/how-to-use#running-pythia-foundations-examples","position":8},{"hierarchy":{"lvl1":"How to Use This Book","lvl2":"Running Pythia Foundations examples"},"content":"All of the content in Pythia Foundations is authored in Markdown\nand presented in the form of \n\nJupyter\nNotebook “chapters”. The power\nof Jupyter Notebooks is that they can contain both static text and\nexecutable code that you can interact with. When you navigate to a\nbook chapter such as \n\nMatplotlib\nBasics\nyou will see static text, Python code, and the rendered output of\nthat code in the form of the many figures that appear. In the case\nof Matplotlib Basics these figures are produced by Matplotlib itself.\nViewing content in this manner is not much different than reading\na hardbound textbook. To get the full benefit of Jupyter Books you\ncan run, and even modify, the example code in real time! This\ninteraction allows you to experiment with different parameters and\nobserve instantly how results change.\n\nThere are two ways that you can execute the Pythia Foundations book\nchapters. Both are described below.","type":"content","url":"/how-to-use#running-pythia-foundations-examples","position":9},{"hierarchy":{"lvl1":"How to Use This Book","lvl3":"Interacting with Jupyter Notebooks in the cloud via Binder","lvl2":"Running Pythia Foundations examples"},"type":"lvl3","url":"/how-to-use#interacting-with-jupyter-notebooks-in-the-cloud-via-binder","position":10},{"hierarchy":{"lvl1":"How to Use This Book","lvl3":"Interacting with Jupyter Notebooks in the cloud via Binder","lvl2":"Running Pythia Foundations examples"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\nJupyter Notebook in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nFoundations book chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“Launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. You’ll be able to execute code\nand even change the example programs. At first the code cells\nhave no output, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.","type":"content","url":"/how-to-use#interacting-with-jupyter-notebooks-in-the-cloud-via-binder","position":11},{"hierarchy":{"lvl1":"How to Use This Book","lvl3":"Interacting with Jupyter Books locally","lvl2":"Running Pythia Foundations examples"},"type":"lvl3","url":"/how-to-use#interacting-with-jupyter-books-locally","position":12},{"hierarchy":{"lvl1":"How to Use This Book","lvl3":"Interacting with Jupyter Books locally","lvl2":"Running Pythia Foundations examples"},"content":"Sometimes it may make more sense to download a book chapter and run\nit on your local laptop or PC. Perhaps you want to co-opt a book\nfor your own purposes, or load your own local data. Downloading an\nindividual chapter is trivial: click on the download icon, also\nlocated in the top right corner of the book chapter you are viewing,\nand select “.ipynb”.\n\nThat was the easy part. Getting the notebook to execute locally may\ntake a little more work. The book was created to run in a particular\nPython environment, managed with Conda. If you don’t have a up-to-date\nversion of Conda on your machine, you’ll want to install one. A brief\nintroduction to installing Conda is available \n\nhere.\n\nOnce you’ve installed Conda you will need to create and activate a Conda environment\nthat is compatible with Pythia Foundation’s notebooks. This\ncan be done with two commands from the terminal, one to create the\nenvironment and one to activate it:conda env create --yes -f https://raw.githubusercontent.com/ProjectPythia/pythia-foundations/main/environment.yml\nconda activate pythia-book-dev\n\nYou should only need to create the environment once (run the first\ncommand above). But if you download another notebook later, you will\nneed to activate pythia-book-dev if\nit is not currently active, for example if you open up a new\nterminal window, or deactivate pythia-book-dev explicitly with\nthe conda command. Again, more information on Conda can be\nfound \n\nhere.\n\nNow that your pythia-book-dev environment is activated,\nchange your working directory to the\nlocation where you downloaded the notebook (.ipynb file) and start\nthe Jupyter Notebook server. For example if you downloaded the\nnotebook file to your home directory you would do:cd ~\njupyter lab\n\nA local Jupyter Notebook server should open in your web browser.\nSimply open the .ipynb file using the Notebook server’s file browser\nand you are good to go. If you want to work with many Pythia Foundations\nnotebooks, you might want to “clone the site”\nand download all of the notebooks. First click on the Pythia\nFoundations GitHub icon (see figure below) and select repository.\nThen follow the instructions in our Getting Started with GitHub\n\n\nguide\nfor cloning a repository. The steps used above for configuring your\nConda environment should work for this method as well.","type":"content","url":"/how-to-use#interacting-with-jupyter-books-locally","position":13}]}