{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59e6a58-b50e-4015-bbd8-b48608d44b26",
   "metadata": {},
   "source": [
    "<img src=\"images/dask_horizontal.svg\" align=\"left\" width=\"30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013dde55-1cea-4fd8-b980-0fa06bdd5568",
   "metadata": {},
   "source": [
    "# Dask Arrays with Xarray\n",
    "\n",
    "Dask Array provides a parallel, larger-than-memory, n-dimensional array using blocked algorithms. Simply put: distributed Numpy.\n",
    "\n",
    "*  **Parallel**: Uses all of the cores on your computer\n",
    "*  **Larger-than-memory**:  Lets you work on datasets that are larger than your available memory by breaking up your array into many small pieces, operating on those pieces in an order that minimizes the memory footprint of your computation, and effectively streaming data from disk.\n",
    "*  **Blocked Algorithms**:  Perform large computations by performing many smaller computations\n",
    "\n",
    "This notebook demonstrates one of Xarray's most powerful features: the ability to wrap dask arrays and allow users to seamlessly execute analysis code in parallel.\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Learn the distinction between *eager* and *lazy* execution, and how Xarray can work either way\n",
    "- Understand key features of dask arrays\n",
    "- Work with Dask Arrays in much the same way you would work with a NumPy array\n",
    "- Learn that xarray DataArrays and Datasets are \"dask collections\" i.e. you can execute top-level dask functions such as dask.visualize(xarray_object)\n",
    "- Learn that all xarray built-in operations can transparently use dask\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Introduction to NumPy](../numpy/numpy-basics) | Necessary | Familiarity with Data Arrays |\n",
    "| [Introduction to Xarray](xarray-intro) | Necessary | Familiarity with Xarray Data Structures |\n",
    "\n",
    "\n",
    "- **Time to learn**: *30-40 minutes*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027ccc87-420b-45dd-830a-38766dd6248f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa666b9-4af2-41b5-8e77-e28f9cecddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.utils import format_bytes\n",
    "from pythia_datasets import DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259bdc60-6e96-4258-8d71-e733ce2d9aca",
   "metadata": {},
   "source": [
    "## Blocked algorithms\n",
    "\n",
    "A *blocked algorithm* executes on a large dataset by breaking it up into many small blocks.\n",
    "\n",
    "For example, consider taking the sum of a billion numbers, in a single computation. This would take a while. We might instead break up the array into 1,000 chunks, each of size 1,000,000, take the sum of each chunk, and then take the sum of the intermediate sums.\n",
    "\n",
    "We achieve the intended result (one sum on one billion numbers) by performing many smaller results (one thousand sums on one million numbers each, followed by another sum of a thousand numbers.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b69958-355f-4121-a644-227adc1b14ef",
   "metadata": {},
   "source": [
    "### `dask.array` contains these algorithms\n",
    "\n",
    "`dask.array` implements a subset of the NumPy ndarray interface using blocked algorithms, cutting up the large array into many small arrays. This lets us compute on arrays larger than memory using multiple cores. Dask coordinates these blocked algorithms using Dask graphs. Dask Arrays are also **lazy**, meaning that they do not evaluate until you explicitly ask for a result using the compute method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aef9368-240b-423b-a3c7-0ab7baa8fa13",
   "metadata": {},
   "source": [
    "### Create a `dask.array` object\n",
    "\n",
    "If we want to create a 3D NumPy array of random values, we do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690bc749-976e-4b78-a801-8d01ee363ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape = (600, 200, 200)\n",
    "arr = np.random.random(shape)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36032d1-0fb6-43d2-a188-87e8e00bd5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_bytes(arr.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e54dc-342c-4d31-902a-ece54a813e7e",
   "metadata": {},
   "source": [
    "This array contains `~183 MB` of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905dffb1-0879-4842-8b76-2538592f6156",
   "metadata": {},
   "source": [
    "Now let's create the same array using Dask's array interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be84728a-7953-4561-aa7d-326f4a45e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "darr = da.random.random(shape, chunks=(300, 100, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e9f08-3142-46d7-b457-e9bde0d1dce9",
   "metadata": {},
   "source": [
    "A chunk size to tell us how to block up our array, like `(300, 100, 200)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbafe88-bb79-436c-aa3b-a9c5f31ff1ec",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Specifying Chunks</p>\n",
    "    There are <a href=\"https://docs.dask.org/en/latest/array-chunks.html\">several ways to specify chunks</a>. In this tutorial, we will use a block shape.\n",
    "\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c13417-a5a2-4fd2-8610-a3cd70f4b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "darr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75988622-8ec1-45b0-a069-29ca74f53836",
   "metadata": {},
   "source": [
    "Notice that we just see a symbolic representation of the array, including its `shape`, `dtype`, and `chunksize`. No data has been generated yet. Let's visualize the constructed task graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7a6e4-bcfc-40c1-a095-8fa315bfef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "darr.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f4038c-f2b2-40c3-91cd-af2713dd23df",
   "metadata": {},
   "source": [
    "Our array has four chunks. To generate it, Dask calls `np.random.random` four times and then concatenates this together into one array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b29134-62af-4a0b-8e44-9f99b5072b45",
   "metadata": {},
   "source": [
    "### Manipulate a `dask.array` object as you would a numpy array\n",
    "\n",
    "\n",
    "Now that we have an `Array` we perform standard numpy-style computations like arithmetic, mathematics, slicing, reductions, etc..\n",
    "\n",
    "The interface is familiar, but the actual work is different. `dask_array.sum()` does not do the same thing as `numpy_array.sum()`.\n",
    "\n",
    "#### What's the difference?\n",
    "\n",
    "`dask_array.sum()` builds an expression of the computation. It does not do the computation yet, also known as **lazy execution**. `numpy_array.sum()` computes the sum immediately (**eager execution**).\n",
    "\n",
    "#### Why the difference?\n",
    "\n",
    "A `dask.array` is split into chunks. Each chunk must have computations run on that chunk explicitly. If the desired answer comes from a small slice of the entire dataset, running the computation over all data would be wasteful of CPU and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14f2f0-a66e-4578-8a8d-f0c7701beb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = darr.sum()\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36724be4-63ec-4b1c-9a9e-1a605a12a5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09186a60-51fc-49c1-91ac-3614af0202cc",
   "metadata": {},
   "source": [
    "#### Compute the result\n",
    "\n",
    "`dask.array` objects are lazily evaluated.  Operations like `.sum` build up a graph of blocked tasks to execute.  \n",
    "\n",
    "We ask for the final result with a call to `.compute()`.  This triggers the actual computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aff31f-2f06-4703-a2a6-cf692ab5eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "total.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af09c610-0e66-4ce8-a53a-fdd50471271d",
   "metadata": {},
   "source": [
    "### Exercise with `dask.arrays`\n",
    "Modify the chunk size (or shape) in the random dask array, call `.sum()` on the new array, and visualize how the task graph changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11922e84-f13e-4db6-a8a0-cf75a5727cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.random.random(shape, chunks=(50, 200, 400)).sum().visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b275b5cc-51a6-48ff-a0a4-62bdc43e6530",
   "metadata": {},
   "source": [
    "Here we see Dask's strategy for finding the sum. This simple example illustrates the beauty of Dask: it automatically designs an algorithm appropriate for custom operations with big data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7dcaaa-6a6e-4f58-aa80-2890136158fd",
   "metadata": {},
   "source": [
    "If we make our operation more complex, the graph gets more complex:\n",
    "\n",
    "For an example, we use an arbitrarily complex calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74a6817-8d06-4dd1-afec-98c53a8ae52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = darr.dot(darr.T).mean(axis=0)[::2, :].std(axis=1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ccffad-5bda-4108-a6c8-6628510f8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c59c2f-3e5c-443b-908f-4f14535d2802",
   "metadata": {},
   "source": [
    "### Testing a bigger calculation\n",
    "\n",
    "The examples above were toy examples; the data (180 MB) is probably not big enough to warrant the use of Dask.\n",
    "\n",
    "We can make it a lot bigger! Let's create a new, big array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482fb0fe-87d4-46fa-bb9d-ed38cc71d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "darr = da.random.random((4000, 100, 4000), chunks=(1000, 100, 500)).astype('float32')\n",
    "darr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0f8b73-41c1-49fb-9fa4-97cb10ae6f4d",
   "metadata": {},
   "source": [
    "This dataset is `~6 GB`, rather than 32 MB! This is probably close to or greater than the amount of available RAM than you have in your computer. Nevertheless, Dask has no problem working on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9addb-cc13-46f5-b542-827f8bdd94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (darr + darr.T)[::2, :].mean(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44ed57c-2a31-4df1-897b-02b614279755",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf25c1-7384-4953-bbb8-be0c3c4e02e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    computed_ds = z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116996d8-cc8a-4201-94d9-8152f4b6aa42",
   "metadata": {},
   "source": [
    "## Dask Arrays with Xarray\n",
    "\n",
    "Often times, you won't be directly interacting with `dask.arrays` directly; odds are you will be interacting with them via [`Xarray`!](http://xarray.pydata.org/en/stable/\n",
    ") Xarray wraps NumPy arrays similar to how we showed in the previous section, helping the user jump right into the dask array interface!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d12474-e71a-400f-b103-824f0de7288b",
   "metadata": {},
   "source": [
    "### Reading data with `Dask` and `Xarray`\n",
    "\n",
    "Recall that a Dask's array consists of many chunked arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e932e0-ff01-412b-9629-1fb5590ffb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "darr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7e0c25-3baa-45aa-bb4d-940480b2fbe9",
   "metadata": {},
   "source": [
    "To read data as Dask arrays with Xarray, we need to specify the `chunks` argument to `open_dataset()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3396e4e6-911b-4c40-a3f8-cdccf034a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(DATASETS.fetch('CESM2_sst_data.nc'), chunks={})\n",
    "ds.tos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7333413-63ba-41f6-bf6c-8f2046402931",
   "metadata": {},
   "source": [
    "Passing `chunks={}` to `open_dataset()` works, but since we didn't tell dask how to split up (or chunk) the array, Dask will create a single chunk for our array.\n",
    "\n",
    "The `chunks` here indicate how values should go into each chunk - for example, `chunks={'time':90}` will tell `Xarray` + `Dask` to place 90 time slices into a single chunk.\n",
    "\n",
    "Notice how `tos` (sea surface temperature) is now split in the time dimension, with two chunks (since there are a total of 180 time slices in this dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ac6b2-500f-4371-98ca-dc28dfe27648",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\n",
    "    DATASETS.fetch('CESM2_sst_data.nc'),\n",
    "    engine=\"netcdf4\",\n",
    "    chunks={\"time\": 90, \"lat\": 180, \"lon\": 360},\n",
    ")\n",
    "ds.tos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e175e4d-9950-48fb-b81c-4e67fa00b106",
   "metadata": {},
   "source": [
    "Calling `.chunks` on the `tos` `xarray.DataArray` displays the number of slices in each dimension within each chunk, with (`time`, `lat`, `lon`). Notice how there are now **two** chunks each with 90 time slices for the time dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4265a298-275c-4f93-992f-6fe8de9a311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.tos.chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54853249-beec-4d74-8881-82d9d253c3b7",
   "metadata": {},
   "source": [
    "### Xarray data structures are first-class dask collections\n",
    "\n",
    "This means you can call the following functions \n",
    "\n",
    "- `dask.visualize(...)`\n",
    "- `dask.compute(...)`\n",
    "\n",
    "on both `xarray.DataArray` and `xarray.Dataset` objects backed by `dask.array`.\n",
    "\n",
    "Let's visualize our dataset using Dask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333de4bb-db42-42e8-95f9-5db108962ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d827f1b1-7d13-4707-93c2-45c2f99a7e60",
   "metadata": {},
   "source": [
    "### Parallel and lazy computation using `dask.array` with Xarray\n",
    "\n",
    "\n",
    "Xarray seamlessly wraps Dask so all computation is deferred until explicitly requested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc7961-d43e-4dca-84f2-d3f82631e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = ds.tos.mean(['lat', 'lon']).dot(ds.tos.T)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764537d7-b8e2-4f92-9b5e-cf81a1d8baa7",
   "metadata": {},
   "source": [
    "As you can see, `z` contains a Dask array. This is true for all Xarray built-in operations including subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631fb768-f900-448a-a605-a93bea26bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.isel(lat=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34679cf2-4907-44d7-b386-0c3cbc7ce6d2",
   "metadata": {},
   "source": [
    "We can visualize this subset too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf0c9e-ac35-4841-9294-2d9e1b6dbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bf9674-57f2-4b49-a5d5-95a4eafac587",
   "metadata": {},
   "source": [
    "Now that we have prepared our calculation, we can go ahead and call `.compute()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30082ac8-694a-4a48-bf03-840720aaa9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    computed_ds = z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf5002f-ed03-4318-935a-b5ce6e57434e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58e6da5-1492-4778-8821-aa03721e3db4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We saw that we can use `Xarray` to access `dask.arrays`, which required passing a `chunks` argument to upon opening the dataset. Once the data were loaded into Xarray, we could interact with the `xarray.Datasets` and `xarray.DataArrays` as we would if we were working with `dask.arrays`. This can be a powerful tool for working with larger-than-memory datasets!\n",
    "\n",
    "### Dask Shortcomings\n",
    "\n",
    "Dask Array does not implement the entire Numpy interface.  Users expecting this\n",
    "will be disappointed.  Notably Dask Array has the following failings:\n",
    "\n",
    "1.  Dask Array does not support some operations where the resulting shape\n",
    "    depends on the values of the array. For those that it does support\n",
    "    (for example, masking one Dask Array with another boolean mask),\n",
    "    the chunk sizes will be unknown, which may cause issues with other\n",
    "    operations that need to know the chunk sizes.\n",
    "2.  Dask Array does not attempt operations like ``sort`` which are notoriously\n",
    "    difficult to do in parallel and are of somewhat diminished value on very\n",
    "    large data (you rarely actually need a full sort).\n",
    "    Often we include parallel-friendly alternatives like [``topk``](https://pytorch.org/docs/stable/generated/torch.topk.html).\n",
    "3.  Dask development is driven by immediate need, and so many lesser used\n",
    "    functions, like ``np.sometrue`` have simply not been implemented yet.  These would make excellent community contributions.\n",
    "\n",
    "## Learn More\n",
    "\n",
    "Visit the [Dask Array documentation](https://docs.dask.org/en/latest/array.html). In particular, this [array screencast](https://youtu.be/9h_61hXCDuI) will reinforce the concepts you learned here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbe02b-6bee-447b-bbc8-2ba8a0b96c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo(id=\"9h_61hXCDuI\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282d878-a11f-41a2-9737-caee406ad5c3",
   "metadata": {},
   "source": [
    "## Resources and references\n",
    "\n",
    "* Reference\n",
    "    *  [Dask Docs](https://dask.org/)\n",
    "    *  [Dask Examples](https://examples.dask.org/)\n",
    "    *  [Dask Code](https://github.com/dask/dask/)\n",
    "    *  [Dask Blog](https://blog.dask.org/)\n",
    "    \n",
    "    *  [Xarray Docs](https://xarray.pydata.org/)\n",
    "  \n",
    "*  Ask for help\n",
    "    *   [`dask`](http://stackoverflow.com/questions/tagged/dask) tag on Stack Overflow, for usage questions\n",
    "    *   [github discussions: dask](https://github.com/dask/dask/discussions) for general, non-bug, discussion, and usage questions\n",
    "    *   [github issues: dask](https://github.com/dask/dask/issues/new) for bug reports and feature requests\n",
    "     *   [github discussions: xarray](https://github.com/pydata/xarray/discussions) for general, non-bug, discussion, and usage questions\n",
    "    *   [github issues: xarray](https://github.com/pydata/xarray/issues/new) for bug reports and feature requests\n",
    "    \n",
    "* Pieces of this notebook are adapted from the following sources\n",
    "  * [Dask Array Tutorial](https://tutorial.dask.org/02_array.html)\n",
    "  * [Parallel Computing with Xarray and Dask](https://tutorial.xarray.dev/intermediate/xarray_and_dask.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7013ef8-33c4-4bd8-8acc-63cce238acb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
