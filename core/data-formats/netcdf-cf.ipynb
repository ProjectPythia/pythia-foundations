{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NetCDF Logo](https://www.unidata.ucar.edu/images/logos/netcdf-400x400.png \"NetCDF Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetCDF and CF: The Basics\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook will introduce you to the basics of Climate and Forecasting (CF) metadata for netCDF data files. Along with an introduction to netCDF, we will introduce the CF data model and discuss some netCDF implementation details to consider when deciding how to write data with CF and netCDF. We will cover the following,\n",
    "\n",
    "1. Demonstrating gridded data\n",
    "1. Demonstrating observational data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Numpy Basics](../numpy/numpy-basics) | Necessary | |\n",
    "| [Datetime](../datetime) | Necessary | |\n",
    "\n",
    "- **Time to learn**: 50 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "from cftime import date2num\n",
    "from netCDF4 import Dataset\n",
    "from pyproj import Proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"gridded\"></a>\n",
    "## Gridded Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we're working with some numerical weather forecast model output. Let's walk through the steps necessary to store this data in netCDF, using the Climate and Forecasting metadata conventions to ensure that our data are available to as many tools as possible.\n",
    "\n",
    "To start, let's assume the following about our data:\n",
    "* There are three spatial dimensions (`x`, `y`, and `press`) and one temporal dimension (`times`)\n",
    "* The native coordinate system of the model is on a regular 3km x 3km grid (`x` and `y`) that represents the Earth on a Lambert conformal projection.\n",
    "* The vertical dimension (`press`) consists of several discrete pressure levels in units of hPa.\n",
    "* The time dimension consists of twelve consecutive hours (`times`), beginning at 2200 UTC on the current day.\n",
    "\n",
    "We'll also go ahead and generate our dimensional arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.utcnow().replace(hour=22, minute=0, second=0, microsecond=0)\n",
    "times = np.array([start + timedelta(hours=h) for h in range(13)])\n",
    "\n",
    "x = np.arange(-150, 153, 3)\n",
    "y = np.arange(-100, 100, 3)\n",
    "\n",
    "press = np.array([1000, 925, 850, 700, 500, 300, 250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a multidimensional array of random values to hold our variable of interest ... in this case, temperature (`temps`). Note that the dimensions correspond to the ones we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = np.random.randn(times.size, press.size, y.size, x.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the file and dimensions\n",
    "\n",
    "The first step is to create a new file in netCDF format and set up the shared dimensions we'll be using in the file. We'll be using the `netCDF4` library to do all of the requisite netCDF API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = Dataset('forecast_model.nc', 'w', format='NETCDF4_CLASSIC', diskless=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='admonition alert alert-info'>\n",
    "    <p class='admonition-title' style='font-weight:bold;'>Info</p>\n",
    "    <p>This creates the netCDF file in memory. If you wish to write the file to disk you can add the <code>persist=True</code> argument or remove the <code>diskless=True</code> argument.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='admonition alert alert-danger'>\n",
    "    <p class='admonition-title' style='font-weight:bold;'>Danger</p>\n",
    "    <p>If you open an existing file with <code>'w'</code> as the second argument, any data already in the file will be overwritten. If you would like to edit or add to the file, open it using <code>'a'</code> as the second argument.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to start by adding some global attribute metadata. These are recommendations from the standard (not required), but they're easy to add and help users keep the data straight, so let's go ahead and do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.Conventions = 'CF-1.7'\n",
    "nc.title = 'Forecast model run'\n",
    "nc.institution = 'Unidata'\n",
    "nc.source = 'WRF-1.5'\n",
    "nc.history = str(datetime.utcnow()) + ' Python'\n",
    "nc.references = ''\n",
    "nc.comment = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, this is the plain-text representation of this netCDF dataset:\n",
    "```\n",
    "netcdf forecast_model {\n",
    "  attributes:\n",
    "    :Conventions = \"CF-1.7\" ;\n",
    "    :title = \"Forecast model run\" ;\n",
    "    :institution = \"Unidata\" ;\n",
    "    :source = \"WRF-1.5\" ;\n",
    "    :history = \"2019-07-16 02:21:52.005718 Python\" ;\n",
    "    :references = \"\" ;\n",
    "    :comment = \"\" ;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Info</p>\n",
    "    This plain-text representation is known as netCDF Common Data Format Language, or <strong>CDL</strong>.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, before adding variables to the file to define each of the data fields in this file, we need to define the dimensions that exist in this data set. We set each of `x`, `y`, and `pressure` to the size of the corresponding array. We set `forecast_time` to be an \"unlimited\" dimension, which allows the dataset to grow along that dimension if we write additional data to it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.createDimension('forecast_time', None)\n",
    "nc.createDimension('x', x.size)\n",
    "nc.createDimension('y', y.size)\n",
    "nc.createDimension('pressure', press.size)\n",
    "nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CDL representation now shows our dimensions:\n",
    "```\n",
    "netcdf forecast_model {\n",
    "  dimensions:\n",
    "    forecast_time = UNLIMITED (currently 13) ;\n",
    "    x = 101 ;\n",
    "    y = 67 ;\n",
    "    pressure = 7 ;\n",
    "  attributes:\n",
    "    :Conventions = \"CF-1.7\" ;\n",
    "    :title = \"Forecast model run\" ;\n",
    "    :institution = \"Unidata\" ;\n",
    "    :source = \"WRF-1.5\" ;\n",
    "    :history = \"2019-07-16 02:21:52.005718 Python\" ;\n",
    "    :references = \"\" ;\n",
    "    :comment = \"\" ;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and filling a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, all we've done is outlined basic information about our dataset: broad metadata and the dimensions of our dataset. Now we create a `netCDF4 variable` to hold one particular data field for our dataset, in this case the forecast air temperature. When defining this variable, we specify the datatype for the values being stored, the relevant dimensions, as well as enable optional `zlib`-based compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_var = nc.createVariable(\n",
    "    'Temperature',\n",
    "    datatype=np.float32,\n",
    "    dimensions=('forecast_time', 'pressure', 'y', 'x'),\n",
    "    zlib=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the variable, we tell Python to write our array of data to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_var[:] = temps\n",
    "temps_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead we wanted to write data sporadically, like once per time step, we could do that instead (though the `for` loop below might actually be at a higher level in the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_slice = 0\n",
    "for temp_slice in temps:\n",
    "    temps_var[next_slice] = temp_slice\n",
    "    next_slice += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, this is the CDL representation of our dataset:\n",
    "```\n",
    "netcdf forecast_model {\n",
    "  dimensions:\n",
    "    forecast_time = UNLIMITED (currently 13) ;\n",
    "    x = 101 ;\n",
    "    y = 67 ;\n",
    "    pressure = 7 ;\n",
    "  variables:\n",
    "    float Temperature(forecast_time, pressure, y, x) ;\n",
    "  attributes:\n",
    "    :Conventions = \"CF-1.7\" ;\n",
    "    :title = \"Forecast model run\" ;\n",
    "    :institution = \"Unidata\" ;\n",
    "    :source = \"WRF-1.5\" ;\n",
    "    :history = \"2019-07-16 02:21:52.005718 Python\" ;\n",
    "    :references = \"\" ;\n",
    "    :comment = \"\" ;\n",
    "}\n",
    "```\n",
    "We can also add attributes to this variable to define metadata. The CF conventions require a `units` attribute to be set for all variables that represent a dimensional quantity. The value of this attribute needs to be parsable by the [UDUNITS](https://www.unidata.ucar.edu/software/udunits/) library. Here we set it to a value of `'Kelvin'`. We also set the standard (optional) attributes of `long_name` and `standard_name`. The former contains a longer description of the variable, while the latter comes from a controlled vocabulary in the CF conventions. This allows users of data to understand, in a standard fashion, what a variable represents. If we had missing values, we could also set the `missing_value` attribute to an appropriate value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NASA Dataset Interoperability Recommendations:**\n",
    ">\n",
    "> Section 2.2 - Include Basic CF Attributes\n",
    ">\n",
    "> Include where applicable: `units`, `long_name`, `standard_name`, `valid_min` / `valid_max`, `scale_factor` / `add_offset` and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_var.units = 'Kelvin'\n",
    "temps_var.standard_name = 'air_temperature'\n",
    "temps_var.long_name = 'Forecast air temperature'\n",
    "temps_var.missing_value = -9999\n",
    "temps_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting CDL (truncated to the variables only) looks like:\n",
    "```\n",
    "  variables:\n",
    "    float Temperature(forecast_time, pressure, y, x) ;\n",
    "      Temperature:units = \"Kelvin\" ;\n",
    "      Temperature:standard_name = \"air_temperature\" ;\n",
    "      Temperature:long_name = \"Forecast air temperature\" ;\n",
    "      Temperature:missing_value = -9999.0 ;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly orient our data in time and space, we need to go beyond dimensions (which define common sizes and alignment) and include values along these dimensions, which are called \"Coordinate Variables\". Generally, these are defined by creating a one dimensional variable with the same name as the respective dimension.\n",
    "\n",
    "To start, we define variables which define our `x` and `y` coordinate values. These variables include `standard_name`s which allow associating them with projections (more on this later) as well as an optional `axis` attribute to make clear what standard direction this coordinate refers to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = nc.createVariable('x', np.float32, ('x',))\n",
    "x_var[:] = x\n",
    "x_var.units = 'km'\n",
    "x_var.axis = 'X'  # Optional\n",
    "x_var.standard_name = 'projection_x_coordinate'\n",
    "x_var.long_name = 'x-coordinate in projected coordinate system'\n",
    "\n",
    "y_var = nc.createVariable('y', np.float32, ('y',))\n",
    "y_var[:] = y\n",
    "y_var.units = 'km'\n",
    "y_var.axis = 'Y'  # Optional\n",
    "y_var.standard_name = 'projection_y_coordinate'\n",
    "y_var.long_name = 'y-coordinate in projected coordinate system'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a coordinate variable `pressure` to reference our data in the vertical dimension. The `standard_name` of `'air_pressure'` is sufficient to identify this coordinate variable as the vertical axis, but let's go ahead and specify the `axis` as well. We also specify the attribute `positive` to indicate whether the variable increases when going up or down. In the case of pressure, this is technically optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "press_var = nc.createVariable('pressure', np.float32, ('pressure',))\n",
    "press_var[:] = press\n",
    "press_var.units = 'hPa'\n",
    "press_var.axis = 'Z'  # Optional\n",
    "press_var.standard_name = 'air_pressure'\n",
    "press_var.positive = 'down'  # Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time coordinates must contain a `units` attribute with a string value with a form similar to `'seconds since 2019-01-06 12:00:00.00'`. 'seconds', 'minutes', 'hours', and 'days' are the most commonly used units for time. Due to the variable length of months and years, they are not recommended.\n",
    "\n",
    "Before we can write data, we need to first convert our list of Python `datetime` instances to numeric values. We can use the `date2num` method from the `cftime` library to make this easy to convert using the unit string as defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_units = f'hours since {times[0]:%Y-%m-%d 00:00}'\n",
    "time_vals = date2num(times, time_units)\n",
    "time_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the `forecast_time` variable just as we did before for the other coordinate variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_var = nc.createVariable('forecast_time', np.int32, ('forecast_time',))\n",
    "time_var[:] = time_vals\n",
    "time_var.units = time_units\n",
    "time_var.axis = 'T'  # Optional\n",
    "time_var.standard_name = 'time'  # Optional\n",
    "time_var.long_name = 'time'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CDL representation of the variables now contains much more information:\n",
    "```\n",
    "  dimensions:\n",
    "    forecast_time = UNLIMITED (currently 13) ;\n",
    "    x = 101 ;\n",
    "    y = 67 ;\n",
    "    pressure = 7 ;\n",
    "  variables:\n",
    "    float x(x) ;\n",
    "      x:units = \"km\" ;\n",
    "      x:axis = \"X\" ;\n",
    "      x:standard_name = \"projection_x_coordinate\" ;\n",
    "      x:long_name = \"x-coordinate in projected coordinate system\" ;\n",
    "    float y(y) ;\n",
    "      y:units = \"km\" ;\n",
    "      y:axis = \"Y\" ;\n",
    "      y:standard_name = \"projection_y_coordinate\" ;\n",
    "      y:long_name = \"y-coordinate in projected coordinate system\" ;\n",
    "    float pressure(pressure) ;\n",
    "      pressure:units = \"hPa\" ;\n",
    "      pressure:axis = \"Z\" ;\n",
    "      pressure:standard_name = \"air_pressure\" ;\n",
    "      pressure:positive = \"down\" ;\n",
    "    float forecast_time(forecast_time) ;\n",
    "      forecast_time:units = \"hours since 2019-07-16 00:00\" ;\n",
    "      forecast_time:axis = \"T\" ;\n",
    "      forecast_time:standard_name = \"time\" ;\n",
    "      forecast_time:long_name = \"time\" ;\n",
    "    float Temperature(forecast_time, pressure, y, x) ;\n",
    "      Temperature:units = \"Kelvin\" ;\n",
    "      Temperature:standard_name = \"air_temperature\" ;\n",
    "      Temperature:long_name = \"Forecast air temperature\" ;\n",
    "      Temperature:missing_value = -9999.0 ;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxilliary Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data are still not CF-compliant because they do not contain latitude and longitude information, which is needed to properly locate the data. To solve this, we need to add variables with latitude and longitude. These are called \"auxillary coordinate variables\", not because they are extra, but because they are not simple one-dimensional variables.\n",
    "\n",
    "Below, we first generate longitude and latitude values from our projected coordinates using the `pyproj` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(x, y)\n",
    "lcc = Proj({'proj': 'lcc', 'lon_0': -105, 'lat_0': 40, 'a': 6371000.0, 'lat_1': 25})\n",
    "lon, lat = lcc(X * 1000, Y * 1000, inverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the needed variables. Both are dimensioned on `y` and `x` and are two-dimensional. The longitude variable is identified as actually containing such information by its required units of `'degrees_east'`, as well as the optional `'longitude'` `standard_name` attribute. The case is the same for latitude, except the units are `'degrees_north'` and the `standard_name` is `'latitude'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_var = nc.createVariable('lon', np.float64, ('y', 'x'))\n",
    "lon_var[:] = lon\n",
    "lon_var.units = 'degrees_east'\n",
    "lon_var.standard_name = 'longitude'  # Optional\n",
    "lon_var.long_name = 'longitude'\n",
    "\n",
    "lat_var = nc.createVariable('lat', np.float64, ('y', 'x'))\n",
    "lat_var[:] = lat\n",
    "lat_var.units = 'degrees_north'\n",
    "lat_var.standard_name = 'latitude'  # Optional\n",
    "lat_var.long_name = 'latitude'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the variables created, we identify these variables as containing coordinates for the `Temperature` variable by setting the `coordinates` value to a space-separated list of the names of the auxilliary coordinate variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_var.coordinates = 'lon lat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yields the following CDL:\n",
    "```\n",
    "  double lon(y, x);\n",
    "    lon:units = \"degrees_east\";\n",
    "    lon:long_name = \"longitude coordinate\";\n",
    "    lon:standard_name = \"longitude\";\n",
    "  double lat(y, x);\n",
    "    lat:units = \"degrees_north\";\n",
    "    lat:long_name = \"latitude coordinate\";\n",
    "    lat:standard_name = \"latitude\";\n",
    "  float Temperature(time, y, x);\n",
    "    Temperature:units = \"Kelvin\" ;\n",
    "    Temperature:standard_name = \"air_temperature\" ;\n",
    "    Temperature:long_name = \"Forecast air temperature\" ;\n",
    "    Temperature:missing_value = -9999.0 ;\n",
    "    Temperature:coordinates = \"lon lat\";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate System Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our data specified on a Lambert conformal projected grid, it would be good to include this information in our metadata. We can do this using a \"grid mapping\" variable. This uses a dummy scalar variable as a namespace for holding all of the required information. Relevant variables then reference the dummy variable with their `grid_mapping` attribute.\n",
    "\n",
    "Below we create a variable and set it up for a Lambert conformal conic projection on a spherical earth. The `grid_mapping_name` attribute describes which of the CF-supported grid mappings we are specifying. The names of additional attributes vary between the mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_var = nc.createVariable('lambert_projection', np.int32, ())\n",
    "proj_var.grid_mapping_name = 'lambert_conformal_conic'\n",
    "proj_var.standard_parallel = 25.0\n",
    "proj_var.latitude_of_projection_origin = 40.0\n",
    "proj_var.longitude_of_central_meridian = -105.0\n",
    "proj_var.semi_major_axis = 6371000.0\n",
    "proj_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we created the variable, all that's left is to set the `grid_mapping` attribute on our `Temperature` variable to the name of our dummy variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps_var.grid_mapping = 'lambert_projection'  # or proj_var.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yields the CDL:\n",
    "```\n",
    "  variables:\n",
    "    int lambert_projection ;\n",
    "      lambert_projection:grid_mapping_name = \"lambert_conformal_conic ;\n",
    "      lambert_projection:standard_parallel = 25.0 ;\n",
    "      lambert_projection:latitude_of_projection_origin = 40.0 ;\n",
    "      lambert_projection:longitude_of_central_meridian = -105.0 ;\n",
    "      lambert_projection:semi_major_axis = 6371000.0 ;\n",
    "    float Temperature(forecast_time, pressure, y, x) ;\n",
    "      Temperature:units = \"Kelvin\" ;\n",
    "      Temperature:standard_name = \"air_temperature\" ;\n",
    "      Temperature:long_name = \"Forecast air temperature\" ;\n",
    "      Temperature:missing_value = -9999.0 ;\n",
    "      Temperature:coordinates = \"lon lat\" ;\n",
    "      Temperature:grid_mapping = \"lambert_projection\" ;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell Bounds\n",
    "\n",
    "> **NASA Dataset Interoperability Recommendations:**\n",
    ">\n",
    "> Section 2.3 - Use CF “bounds” attributes\n",
    ">\n",
    "> CF conventions state: “When gridded data does not represent the point values of a field but instead represents some characteristic of the field within cells of finite ‘volume,’ a complete description of the variable should include metadata that describes the domain or extent of each cell, and the characteristic of the field that the cell values represent.”\n",
    "\n",
    "For example, if a rain guage is read every 3 hours but only dumped every six hours, it might look like this\n",
    "  \n",
    "```\n",
    "netcdf precip_bucket_bounds {\n",
    "  dimensions:\n",
    "      lat = 12 ;\n",
    "      lon = 19 ;\n",
    "      time = 8 ;\n",
    "      tbv = 2;\n",
    "  variables:\n",
    "      float lat(lat) ;\n",
    "      float lon(lon) ;\n",
    "      float time(time) ;\n",
    "        time:units = \"hours since 2019-07-12 00:00:00.00\";\n",
    "        time:bounds = \"time_bounds\" ;\n",
    "      float time_bounds(time,tbv)\n",
    "      float precip(time, lat, lon) ;\n",
    "        precip:units = \"inches\" ;\n",
    "  data:\n",
    "    time = 3, 6, 9, 12, 15, 18, 21, 24;\n",
    "    time_bounds = 0, 3, 0, 6, 6, 9, 6, 12, 12, 15, 12, 18, 18, 21, 18, 24;\n",
    "}\n",
    "```\n",
    "\n",
    "So the time coordinate looks like\n",
    "```\n",
    "|---X\n",
    "|-------X\n",
    "        |---X\n",
    "        |-------X\n",
    "                |---X\n",
    "                |-------X\n",
    "                        |---X\n",
    "                        |-------X\n",
    "0   3   6   9  12  15  18  21  24\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"obs\"></a>\n",
    "## Observational Data\n",
    "\n",
    "So far we've focused on how to handle storing data that are arranged in a grid. What about in-situ data, often termed \"observational\" data? CF describes this as *Conventions for Discrete Sampling Geometeries (DSG)*.\n",
    "\n",
    "For data that are regularly sampled (e.g., from a vertical profiler site), this is straightforward. First, let's define some sample profile data for three hypothetical profilers located at Boulder, Norman, and Albany. We'll assume that the profiler reports data every 10m, from 10 m up to (but not including) 1000 m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = np.array([-97.1, -105, -73.8])\n",
    "lats = np.array([35.25, 40, 42.75])\n",
    "heights = np.linspace(10, 1000, 10)\n",
    "temps = np.random.randn(lats.size, heights.size)\n",
    "stids = ['KBOU', 'KOUN', 'KALB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation and basic setup\n",
    "First we create a new file and define some dimensions. Since this is profile data, heights will be one dimension. We use station as our other dimension. We also set the global `featureType` attribute to `'profile'` to indicate that this file holds \"an ordered set of data points along a vertical line at a fixed horizontal position and fixed time\". We also add a dimension to assist in storing our string station ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.close()\n",
    "nc = Dataset('obs_data.nc', 'w', format='NETCDF4_CLASSIC', diskless=True)\n",
    "nc.createDimension('station', lats.size)\n",
    "nc.createDimension('heights', heights.size)\n",
    "nc.createDimension('str_len', 4)\n",
    "nc.Conventions = 'CF-1.7'\n",
    "nc.featureType = 'profile'\n",
    "nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which gives this CDL:\n",
    "```\n",
    "netcdf obs_data {\n",
    "  dimensions:\n",
    "    station = 3 ;\n",
    "    heights = 10 ;\n",
    "    str_len = 4 ;\n",
    "  attributes:\n",
    "    :Conventions = \"CF-1.7\" ;\n",
    "    :featureType = \"profile\" ;\n",
    "}\n",
    "```\n",
    "We can create our coordinates with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_var = nc.createVariable('lon', np.float64, ('station',))\n",
    "lon_var.units = 'degrees_east'\n",
    "lon_var.standard_name = 'longitude'\n",
    "\n",
    "lat_var = nc.createVariable('lat', np.float64, ('station',))\n",
    "lat_var.units = 'degrees_north'\n",
    "lat_var.standard_name = 'latitude'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard refers to these as \"instance variables\" because each one refers to an instance of a feature. From here we can create our `height` coordinate variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_var = nc.createVariable('heights', np.float32, ('heights',))\n",
    "heights_var.units = 'meters'\n",
    "heights_var.standard_name = 'altitude'\n",
    "heights_var.positive = 'up'\n",
    "heights_var[:] = heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Station IDs\n",
    "Now we can also write our station IDs to a variable. This is a 2D variable, but one of the dimensions is simply there to facilitate treating strings as character arrays. We also assign this an attribute `cf_role` with a value of `'profile_id'` to facilitate software to identify individual profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stid_var = nc.createVariable('stid', 'c', ('station', 'str_len'))\n",
    "stid_var.cf_role = 'profile_id'\n",
    "stid_var.long_name = 'Station identifier'\n",
    "stid_var[:] = stids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our CDL looks like:\n",
    "```\n",
    "netcdf obs_data {\n",
    "  dimensions:\n",
    "    station = 3 ;\n",
    "    heights = 10 ;\n",
    "    str_len = 4 ;\n",
    "  variables:\n",
    "    double lon(station) ;\n",
    "      lon:units = \"degrees_east\" ;\n",
    "      lon:standard_name = \"longitude\" ;\n",
    "    double lat(station) ;\n",
    "      lat:units = \"degrees_north\" ;\n",
    "      lat:standard_name = \"latitude\" ;\n",
    "    float heights(heights) ;\n",
    "      heights:units = \"meters\" ;\n",
    "      heights:standard_name = \"altitude\";\n",
    "      heights:positive = \"up\" ;\n",
    "    char stid(station, str_len) ;\n",
    "      stid:cf_role = \"profile_id\" ;\n",
    "      stid:long_name = \"Station identifier\" ;\n",
    "  attributes:\n",
    "    :Conventions = \"CF-1.7\" ;\n",
    "    :featureType = \"profile\" ;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the field\n",
    "Now all that's left is to write our profile data, which looks fairly standard. We also add a scalar variable for the time at which these profiles were captured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_var = nc.createVariable('time', np.float32, ())\n",
    "time_var.units = 'minutes since 2019-07-16 17:00'\n",
    "time_var.standard_name = 'time'\n",
    "time_var[:] = [5.0]\n",
    "\n",
    "temp_var = nc.createVariable('temperature', np.float32, ('station', 'heights'))\n",
    "temp_var.units = 'celsius'\n",
    "temp_var.standard_name = 'air_temperature'\n",
    "temp_var.coordinates = 'lon lat heights time'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the use of the `coordinates` attribute to store the names of the auxilliary coordinate variables since they're all dimensioned on `station` and not proper coordinate variables. This yields the CDL for the variables:\n",
    "```\n",
    "  variables:\n",
    "    double lon(station) ;\n",
    "      lon:units = \"degrees_east\" ;\n",
    "      lon:standard_name = \"longitude\" ;\n",
    "    double lat(station) ;\n",
    "      lat:units = \"degrees_north\" ;\n",
    "      lat:standard_name = \"latitude\" ;\n",
    "    float heights(heights) ;\n",
    "      heights:units = \"meters\" ;\n",
    "      heights:standard_name = \"altitude\";\n",
    "      heights:positive = \"up\" ;\n",
    "    char stid(station, str_len) ;\n",
    "      stid:cf_role = \"profile_id\" ;\n",
    "      stid:long_name = \"Station identifier\" ;\n",
    "    float time ;\n",
    "      time:units = \"minutes since 2019-07-16 17:00\" ;\n",
    "      time:standard_name = \"time\" ;\n",
    "    float temperature(station, heights) ;\n",
    "      temperature:units = \"celsius\" ;\n",
    "      temperature:standard_name = \"air_temperature\" ;\n",
    "      temperature:coordinates = \"lon lat heights time\" ;\n",
    "```\n",
    "\n",
    "These standards for storing DSG extend to time series, trajectories, and combinations of them. They also can extend for differing amounts of data  per feature using ragged arrays. For more information see the [main document](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.7/cf-conventions.html#discrete-sampling-geometries) or the [annotated DSG examples](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.7/cf-conventions.html#appendix-examples-discrete-geometries)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "We have discussed and created examples of **netCDF** `Dataset`s, both gridded and in-situ, that follow the Climate and Forecast (**CF**) Conventions. These `Dataset`s are *self-describing*, in that their attributes, or *metadata*, are included. Other libraries in the Python scientific software ecosystem, such as `xarray` and `MetPy` can thus easily read in (and write to) and analyze these `Dataset`s.\n",
    "\n",
    "### What's Next?\n",
    "In subsequent notebooks, we will work with netCDF `Dataset`s culled from \"real-life\" model and in-situ sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"references\"></a>\n",
    "## Resources and References\n",
    "\n",
    "- [CF Conventions doc (1.7)](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.7/cf-conventions.html)\n",
    "- [Jonathan Gregory's old CF presentation](http://cfconventions.org/Data/cf-documents/overview/viewgraphs.pdf)\n",
    "- [NASA ESDS “Dataset Interoperability Recommendations for Earth Science”](https://earthdata.nasa.gov/user-resources/standards-and-references/dataset-interoperability-recommendations-for-earth-science)\n",
    "- [CF Data Model (cfdm) python package tutorial](https://ncas-cms.github.io/cfdm/tutorial.html)\n",
    "- [Tim Whiteaker's cfgeom python package (GitHub repo)](https://github.com/twhiteaker/CFGeom) and [(tutorial)]( https://twhiteaker.github.io/CFGeom/tutorial.html)\n",
    "- [netCDF4 Documentation](https://unidata.github.io/netcdf4-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
